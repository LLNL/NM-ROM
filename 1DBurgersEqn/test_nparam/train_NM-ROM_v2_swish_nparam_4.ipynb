{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.prune as prune\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "from scipy import sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import sys,time\n",
    "import os\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nparam=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug 21 17:19:13 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.74       Driver Version: 418.74       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro M6000        On   | 00000000:02:00.0 Off |                  Off |\n",
      "| 25%   31C    P8    14W / 250W |      1MiB / 12212MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Quadro M6000        On   | 00000000:03:00.0 Off |                  Off |\n",
      "| 25%   26C    P8    14W / 250W |      1MiB / 12212MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Quadro M6000        On   | 00000000:81:00.0 Off |                  Off |\n",
      "| 25%   27C    P8    14W / 250W |      1MiB / 12212MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Quadro M6000        On   | 00000000:82:00.0 Off |                  Off |\n",
      "| 25%   27C    P8    14W / 250W |      1MiB / 12212MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose device that is not being used\n",
    "gpu_ids = \"0\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=gpu_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_v2(m,b,db):\n",
    "    '''\n",
    "    mask=create_mask_v2(m,b,db)  \n",
    "    '''\n",
    "    \n",
    "    M2 = b + db*(m-1)\n",
    "    mask = np.zeros((m,M2),dtype='int')\n",
    "    \n",
    "    block = np.ones(b,dtype='int')\n",
    "    ind = np.arange(b)\n",
    "    for row in range(m):\n",
    "        col = ind + row*db\n",
    "        mask[row,col] = block\n",
    "    \n",
    "    print(\n",
    "        \"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "            m, M2, (1.0-np.count_nonzero(mask)/mask.size)*100\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.spy(mask)\n",
    "    plt.show()\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silu(input):\n",
    "    return input * torch.sigmoid(input)\n",
    "class SiLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return silu(input)\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,m,M1,f):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.full = nn.Sequential(\n",
    "            nn.Linear(m,M1),\n",
    "            SiLU(),\n",
    "            nn.Linear(M1,f,bias=False)\n",
    "        )\n",
    "                \n",
    "    def forward(self, y):     \n",
    "        y = y.view(-1,m)\n",
    "        T = self.full(y)\n",
    "        T = T.squeeze()\n",
    "        \n",
    "        return T\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,f,M2,m):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.full = nn.Sequential(\n",
    "            nn.Linear(f,M2,bias=False),\n",
    "            SiLU(),\n",
    "            nn.Linear(M2,m,bias=False)\n",
    "        )\n",
    "             \n",
    "    def forward(self,T):\n",
    "        T = T.view(-1,f)\n",
    "        y = self.full(T)\n",
    "        y = y.squeeze()\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1800, 1000]) torch.Size([200, 1000])\n"
     ]
    }
   ],
   "source": [
    "# load solution snapshot\n",
    "solution_snapshot_orig = pickle.load(open(\"./data/snapshot_full_nparam_{}.p\".format(nparam), \"rb\"))\n",
    "nx=1001\n",
    "nt=500\n",
    "\n",
    "# substract IC -> centered on IC\n",
    "ndata=solution_snapshot_orig.shape[0]\n",
    "nset= round(ndata/(nt+1))\n",
    "\n",
    "solution_snapshot=np.array([])\n",
    "for foo in range(nset):\n",
    "    solution_snapshot=np.append(solution_snapshot,solution_snapshot_orig[foo*(nt+1)+1:(foo+1)*(nt+1)]\\\n",
    "    -solution_snapshot_orig[foo*(nt+1)])\n",
    "\n",
    "solution_snapshot=np.reshape(solution_snapshot,(-1,nx))\n",
    "\n",
    "# remove BC\n",
    "solution_snapshot = solution_snapshot[:,:-1].astype('float32')\n",
    "\n",
    "# define testset and trainset indices\n",
    "test_ind = np.random.permutation(np.arange(solution_snapshot.shape[0]))[:int(0.1*solution_snapshot.shape[0])]\n",
    "train_ind = np.setdiff1d(np.arange(solution_snapshot.shape[0]),test_ind)\n",
    "\n",
    "# set trainset and testset\n",
    "trainset = solution_snapshot[train_ind]\n",
    "testset = solution_snapshot[test_ind] \n",
    "\n",
    "# set dataset\n",
    "dataset = {'train':data_utils.TensorDataset(torch.tensor(trainset)),\n",
    "           'test':data_utils.TensorDataset(torch.tensor(testset))}\n",
    "print(dataset['train'].tensors[0].shape, dataset['test'].tensors[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 1000) (200, 1000)\n"
     ]
    }
   ],
   "source": [
    "# compute dataset shapes\n",
    "dataset_shapes = {'train':trainset.shape,\n",
    "                 'test':testset.shape}\n",
    "\n",
    "print(dataset_shapes['train'],dataset_shapes['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # when inputs and targets are different e.g. Kernel PCA + Decoder\n",
    "# mapped_solution_snapshot = loadmat('./data/mapped_solution_snaphost.mat')['mapped_solution_snapshot']\n",
    "\n",
    "# mapped_trainset = mapped_solution_snapshot[train_ind]\n",
    "# mapped_testset = mapped_solution_snapshot[test_ind]\n",
    "\n",
    "# inputs = {'train':mapped_trainset,'test':mapped_testset}\n",
    "# outputs = {'train':trainset,'test':testset}\n",
    "\n",
    "# dataset = {'train':data_utils.TensorDataset(inputs['train'], targets['train']),\n",
    "#            'test':data_utils.TensorDataset(inputs['test'], targets['test'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set batch_size, number of epochs, paitience for early stop\n",
    "batch_size = 20*nparam\n",
    "num_epochs = 10000//5\n",
    "num_epochs_print = num_epochs*5//100\n",
    "early_stop_patience = num_epochs*5//50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data loaders\n",
    "train_loader = DataLoader(dataset=dataset['train'], \n",
    "                          batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(dataset=dataset['test'], \n",
    "                         batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "data_loaders = {'train':train_loader, 'test':test_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # copy trainset to cpu (if inputs~=targets, replace 0 to 1 for targets)\n",
    "# trainset_inputs = data_loaders['train'].dataset.tensors[0].to('cpu')\n",
    "# trainset_targets = data_loaders['train'].dataset.tensors[0].to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set checkpoint\n",
    "PATH = './checkpoint_v2_nparam_{}.tar'.format(nparam)\n",
    "\n",
    "# set file name for AE\n",
    "file_name_AE_pkl=\"./model/AE_v2_swish_nparam_{}.pkl\".format(nparam)\n",
    "file_name_AE=\"./model/AE_v2_swish_nparam_{}.p\".format(nparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the number of nodes in each layer\n",
    "m = 1000\n",
    "f = 5\n",
    "b = 36\n",
    "db = 12\n",
    "M2 = b + (m-1)*db\n",
    "M1 = 2*m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in 1000 by 12024 mask: 99.70%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------checkpoint not restored--------\n",
      "\n",
      "Sparsity in 1000 by 12024 mask: 99.70%\n",
      "\n",
      "Start first training... m=1000, f=5, M1=2000, M2=12024, b=36, db=12\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "try:\n",
    "    checkpoint = torch.load(PATH, map_location=device)\n",
    "    \n",
    "    encoder = Encoder(m,M1,f).to(device)\n",
    "    decoder = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    mask = create_mask_v2(m,b,db)\n",
    "    prune.custom_from_mask(decoder.full[2], name='weight', mask=torch.tensor(mask).to(device))    \n",
    "    \n",
    "#     optimizer = torch.optim.LBFGS(list(encoder.parameters()) + list(decoder.parameters()), lr=1)\n",
    "#     scheduler = None     \n",
    "    optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "    decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    last_epoch = checkpoint['epoch']\n",
    "    loss_hist = checkpoint['loss_hist']\n",
    "    best_loss = checkpoint['best_loss']\n",
    "    early_stop_counter = checkpoint['early_stop_counter']\n",
    "    best_encoder_wts = checkpoint['best_encoder_wts']\n",
    "    best_decoder_wts = checkpoint['best_decoder_wts']\n",
    "    \n",
    "    print(\"\\n--------checkpoint restored--------\\n\")\n",
    "    \n",
    "    # compute sparsity in mask\n",
    "    mask = decoder.state_dict()['full.2.weight_mask']\n",
    "    print(\"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "        mask.shape[0], mask.shape[1], 100. * float(torch.sum(mask == 0))/ float(mask.nelement())))\n",
    "\n",
    "    # resume training\n",
    "    print(\"\")\n",
    "    print('Re-start {}th training... m={}, f={}, M1={}, M2={}, b={}, db={}'.format(\n",
    "        last_epoch+1, m, f, M1, M2, b, db))\n",
    "except:\n",
    "    encoder = Encoder(m,M1,f).to(device)\n",
    "    decoder = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    mask = create_mask_v2(m,b,db)\n",
    "    prune.custom_from_mask(decoder.full[2], name='weight', mask=torch.tensor(mask).to(device))\n",
    "\n",
    "#     optimizer = torch.optim.LBFGS(list(encoder.parameters()) + list(decoder.parameters()), lr=1)\n",
    "#     scheduler = None \n",
    "    optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    last_epoch = 0\n",
    "    loss_hist = {'train':[],'test':[]}\n",
    "    best_loss = float(\"inf\")\n",
    "    early_stop_counter = 1\n",
    "    best_encoder_wts = copy.deepcopy(encoder.state_dict())\n",
    "    best_decoder_wts = copy.deepcopy(decoder.state_dict())\n",
    "    \n",
    "    print(\"\\n--------checkpoint not restored--------\\n\")\n",
    "    \n",
    "    # compute sparsity in mask\n",
    "    mask = decoder.state_dict()['full.2.weight_mask']\n",
    "    print(\"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "        mask.shape[0], mask.shape[1], 100. * float(torch.sum(mask == 0))/ float(mask.nelement())))\n",
    "\n",
    "    # start training\n",
    "    print(\"\")\n",
    "    print('Start first training... m={}, f={}, M1={}, M2={}, b={}, db={}'.format(\n",
    "        m, f, M1, M2, b, db))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100/2000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 1.911857685222963e-05\n",
      "test MSELoss: 1.727469643810764e-05\n",
      "\n",
      "Epoch 200/2000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 1.5147297522667536e-05\n",
      "test MSELoss: 1.3955798203824088e-05\n",
      "\n",
      "Epoch 300/2000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 1.2079481024961246e-05\n",
      "test MSELoss: 1.081548962247325e-05\n",
      "\n",
      "Epoch 400/2000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 7.935383635210907e-06\n",
      "test MSELoss: 7.320408894884167e-06\n",
      "\n",
      "Epoch 500/2000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 7.659596910040516e-06\n",
      "test MSELoss: 7.098092828528024e-06\n",
      "\n",
      "Epoch 600/2000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 7.235458855979636e-06\n",
      "test MSELoss: 6.727136769768549e-06\n",
      "\n",
      "Epoch 700/2000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 6.875102957969324e-06\n",
      "test MSELoss: 6.364885848597623e-06\n",
      "\n",
      "Epoch 800/2000, Learning rate 1.0000000000000002e-07\n",
      "----------\n",
      "train MSELoss: 6.588998753108576e-06\n",
      "test MSELoss: 6.195318746904377e-06\n",
      "\n",
      "Epoch 900/2000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 6.586788084758963e-06\n",
      "test MSELoss: 6.194122488523135e-06\n",
      "\n",
      "Epoch 997/2000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 6.586373203592504e-06\n",
      "test MSELoss: 6.193780245666858e-06\n",
      "\n",
      "Early stopping: 997th training complete in 0h 3m 40s\n",
      "----------\n",
      "Best train MSELoss: 6.587599273188971e-06\n",
      "Best test MSELoss: 6.193479021021631e-06\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "since = time.time()\n",
    "\n",
    "for epoch in range(last_epoch+1,num_epochs+1):   \n",
    "\n",
    "    if epoch%num_epochs_print == 0:\n",
    "        print()\n",
    "        if scheduler !=None:\n",
    "            print('Epoch {}/{}, Learning rate {}'.format(\n",
    "                epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "        else:\n",
    "            print('Epoch {}/{}'.format(\n",
    "                epoch, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and test phase\n",
    "    for phase in ['train', 'test']:\n",
    "        if phase == 'train':\n",
    "            encoder.train()  # Set model to training mode\n",
    "            decoder.train()  # Set model to training mode\n",
    "        else:\n",
    "            encoder.eval()   # Set model to evaluation mode\n",
    "            decoder.eval()   # Set model to evaluation mode\n",
    "            \n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Iterate over data\n",
    "        for data, in data_loaders[phase]:\n",
    "            inputs = data.to(device)\n",
    "            targets = data.to(device)\n",
    "\n",
    "            if phase == 'train':\n",
    "                if scheduler != None:\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    outputs = decoder(encoder(inputs))\n",
    "                    loss = loss_func(outputs, targets)\n",
    "\n",
    "                    # backward\n",
    "                    loss.backward()\n",
    "\n",
    "                    # optimize\n",
    "                    optimizer.step()  \n",
    "                    \n",
    "                    # add running loss\n",
    "                    running_loss += loss.item()*inputs.shape[0]\n",
    "                else:\n",
    "                    def closure():\n",
    "                        # zero the parameter gradients\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                        # forward\n",
    "                        outputs = decoder(encoder(inputs))\n",
    "                        loss = loss_func(outputs,targets)\n",
    "\n",
    "                        # backward\n",
    "                        loss.backward()\n",
    "                        return loss\n",
    "\n",
    "                    # optimize\n",
    "                    optimizer.step(closure)\n",
    "                    \n",
    "                    # add running loss\n",
    "                    with torch.set_grad_enabled(False):\n",
    "                        outputs = decoder(encoder(inputs))\n",
    "                        running_loss += loss_func(outputs,targets).item()*inputs.shape[0]\n",
    "                    \n",
    "            else:\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    outputs = decoder(encoder(inputs))\n",
    "                    running_loss += loss_func(outputs,targets).item()*inputs.shape[0]\n",
    "\n",
    "        # compute epoch loss\n",
    "        epoch_loss = running_loss / dataset_shapes[phase][0]\n",
    "        loss_hist[phase].append(epoch_loss)\n",
    "            \n",
    "        # update learning rate\n",
    "        if phase == 'train' and scheduler != None:\n",
    "            scheduler.step(epoch_loss)\n",
    "\n",
    "        if epoch%num_epochs_print == 0:\n",
    "            print('{} MSELoss: {}'.format(\n",
    "                phase, epoch_loss))\n",
    "\n",
    "    # deep copy the model\n",
    "    if loss_hist['test'][-1] < best_loss:\n",
    "        best_loss = loss_hist['test'][-1]\n",
    "        early_stop_counter = 1\n",
    "        best_encoder_wts = copy.deepcopy(encoder.state_dict())\n",
    "        best_decoder_wts = copy.deepcopy(decoder.state_dict())\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= early_stop_patience:  \n",
    "            break\n",
    "    \n",
    "    # save checkpoint every num_epoch_print\n",
    "    if epoch%num_epochs_print== 0:\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'encoder_state_dict': encoder.state_dict(),\n",
    "                    'decoder_state_dict': decoder.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss_hist': loss_hist,\n",
    "                    'best_loss': best_loss,\n",
    "                    'early_stop_counter': early_stop_counter,\n",
    "                    'best_encoder_wts': best_encoder_wts,\n",
    "                    'best_decoder_wts': best_decoder_wts,\n",
    "                    }, PATH)        \n",
    "\n",
    "print()\n",
    "print('Epoch {}/{}, Learning rate {}'\\\n",
    "      .format(epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "print('-' * 10)\n",
    "print('train MSELoss: {}'.format(loss_hist['train'][-1]))\n",
    "print('test MSELoss: {}'.format(loss_hist['test'][-1]))\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "\n",
    "# load best model weights\n",
    "encoder.load_state_dict(best_encoder_wts)\n",
    "decoder.load_state_dict(best_decoder_wts)\n",
    "\n",
    "# compute best train MSELoss\n",
    "encoder.to('cpu').eval()\n",
    "decoder.to('cpu').eval()\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    train_inputs = torch.tensor(trainset)\n",
    "    train_targets = torch.tensor(trainset)\n",
    "    train_outputs = decoder(encoder(train_inputs))\n",
    "    train_loss = loss_func(train_outputs,train_targets).item()\n",
    "\n",
    "# print out training time and best results\n",
    "print()\n",
    "if epoch < num_epochs:\n",
    "    print('Early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "else:\n",
    "    print('No early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "print('-' * 10)\n",
    "print('Best train MSELoss: {}'.format(train_loss))\n",
    "print('Best test MSELoss: {}'.format(best_loss))\n",
    "\n",
    "# save models\n",
    "# print()\n",
    "# print(\"Saving after {}th training to\".format(epoch),\n",
    "#       file_name_AE_pkl)\n",
    "# torch.save((encoder,decoder),file_name_AE_pkl) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "checkpoint removed\n"
     ]
    }
   ],
   "source": [
    "# delete checkpoint\n",
    "try:\n",
    "    os.remove(PATH)\n",
    "    print()\n",
    "    print(\"checkpoint removed\")\n",
    "except:\n",
    "    print(\"no checkpoint exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and test loss\n",
    "plt.figure()\n",
    "plt.semilogy(loss_hist['train'])\n",
    "plt.semilogy(loss_hist['test'])\n",
    "plt.legend(['train','test'])\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load models\n",
    "# try:\n",
    "#     encoder,decoder = torch.load(file_name_AE_pkl,map_location='cpu')\n",
    "#     print(\"\\n--------model restored--------\\n\")\n",
    "# except:\n",
    "#     print(\"\\n--------model not restored--------\\n\")\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights and bias\n",
    "en_w1=encoder.full[0].weight.cpu().detach().numpy().astype('float32')\n",
    "en_b1=encoder.full[0].bias.cpu().detach().numpy().astype('float32')\n",
    "en_w2=encoder.full[2].weight.cpu().detach().numpy().astype('float32')\n",
    "\n",
    "de_w1=decoder.full[0].weight.cpu().detach().numpy().astype('float32')\n",
    "de_w2=decoder.full[2].weight.cpu().detach().numpy().astype('float32')\n",
    "\n",
    "de_w2_sp=sp.csr_matrix(de_w2,dtype='float32')\n",
    "\n",
    "de_w1T=de_w1.T\n",
    "de_w2T=de_w2.T\n",
    "\n",
    "de_w2T_sp=de_w2_sp.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy version of AE\n",
    "def sigmoid_np(input):\n",
    "    return (1.0/(1.0+np.exp(-input))).astype('float32')\n",
    "\n",
    "def encoder_np_forward(x):\n",
    "    z1 = en_w1.dot(x) + en_b1\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = en_w2.dot(a1)   \n",
    "    return y\n",
    "\n",
    "def decoder_np_forward(x):\n",
    "    z1 = de_w1.dot(x)\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = de_w2.dot(a1)  \n",
    "    return y\n",
    "\n",
    "def decoder_sp_forward(x):\n",
    "    z1 = de_w1.dot(x)\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = sp.csr_matrix.dot(de_w2_sp,a1)\n",
    "    return y\n",
    "\n",
    "def decoder_np_forward_backward(x):\n",
    "    z1 = de_w1.dot(x)\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = de_w2.dot(a1)\n",
    "\n",
    "    dout = de_w1T\n",
    "    dout = (s1 + a1*(1-s1))*dout\n",
    "    dydxT = dout.dot(de_w2T)   \n",
    "    return y,dydxT.T\n",
    "\n",
    "def decoder_sp_forward_backward(x):\n",
    "    z1 = de_w1.dot(x) \n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = sp.csr_matrix.dot(de_w2_sp,a1)\n",
    "\n",
    "    dout = de_w1T\n",
    "    dout = (s1 + a1*(1-s1))*dout\n",
    "    dydxT = sp.csr_matrix.dot(dout,de_w2T_sp)\n",
    "    return y,dydxT.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE: 6.54819304e-06\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (numpy version)\n",
    "comp_orig_data=np.zeros((nset*nt,f))\n",
    "rest_orig_data=np.zeros(solution_snapshot.shape)\n",
    "\n",
    "for k in range(nset*nt):\n",
    "    comp_orig_data[k]=encoder_np_forward(solution_snapshot[k])\n",
    "    rest_orig_data[k]=decoder_sp_forward(comp_orig_data[k])\n",
    "    \n",
    "print(\"MSELoss of AE: {:.8e}\".format(np.linalg.norm(solution_snapshot-rest_orig_data)**2/np.prod(solution_snapshot.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE: 6.54818541e-06\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (PyTorch model)\n",
    "input_data=torch.tensor(solution_snapshot)\n",
    "target_data=decoder(encoder(input_data))\n",
    "\n",
    "print(\"MSELoss of AE: {:.8e}\".format(torch.nn.functional.mse_loss(input_data,target_data).detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE (predictive case): 1.33886954e-06\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (predictive case)\n",
    "FOM_solution=pickle.load(open('./data/FOM.p','rb'))\n",
    "FOM_solution=FOM_solution.astype('float32')\n",
    "\n",
    "orig_data_FOM = FOM_solution[1:,:-1]\n",
    "ref=FOM_solution[0,:-1]\n",
    "\n",
    "input_FOM=torch.tensor(orig_data_FOM-ref)\n",
    "target_FOM=decoder(encoder(input_FOM))\n",
    "\n",
    "print(\"MSELoss of AE (predictive case): {:.8e}\"\\\n",
    "      .format(torch.nn.functional.mse_loss(input_FOM,target_FOM).detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights and bias   \n",
    "AE={'en_w1':en_w1,'en_b1':en_b1,'en_w2':en_w2,\n",
    "    'de_w1':de_w1,'de_w2':de_w2,\n",
    "    'de_w1T':de_w1T,'de_w2T':de_w2T,'de_w2_sp':de_w2_sp,'de_w2T_sp':de_w2T_sp}\n",
    "\n",
    "pickle.dump(AE,open(file_name_AE,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
