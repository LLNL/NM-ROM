{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.prune as prune\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "from scipy import sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import sys,time\n",
    "import os\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "redDim=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug 21 13:39:15 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.74       Driver Version: 418.74       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro M6000        On   | 00000000:02:00.0 Off |                  Off |\n",
      "| 25%   32C    P0   138W / 250W |   1145MiB / 12212MiB |     94%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Quadro M6000        On   | 00000000:03:00.0 Off |                  Off |\n",
      "| 25%   26C    P0    62W / 250W |    277MiB / 12212MiB |      7%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Quadro M6000        On   | 00000000:81:00.0 Off |                  Off |\n",
      "| 25%   26C    P8    14W / 250W |      1MiB / 12212MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Quadro M6000        On   | 00000000:82:00.0 Off |                  Off |\n",
      "| 25%   27C    P8    14W / 250W |      1MiB / 12212MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     14995      C   /home/kim101/anaconda3/bin/python           1133MiB |\n",
      "|    1     15022      C   /home/kim101/anaconda3/bin/python            267MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose device that is not being used\n",
    "gpu_ids = \"2\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=gpu_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_v2(m,b,db):\n",
    "    '''\n",
    "    mask=create_mask_v2(m,b,db)  \n",
    "    '''\n",
    "    \n",
    "    M2 = b + db*(m-1)\n",
    "    mask = np.zeros((m,M2),dtype='int')\n",
    "    \n",
    "    block = np.ones(b,dtype='int')\n",
    "    ind = np.arange(b)\n",
    "    for row in range(m):\n",
    "        col = ind + row*db\n",
    "        mask[row,col] = block\n",
    "    \n",
    "    print(\n",
    "        \"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "            m, M2, (1.0-np.count_nonzero(mask)/mask.size)*100\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.spy(mask)\n",
    "    plt.show()\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silu(input):\n",
    "    return input * torch.sigmoid(input)\n",
    "class SiLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return silu(input)\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,m,M1,f):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.full = nn.Sequential(\n",
    "            nn.Linear(m,M1),\n",
    "            SiLU(),\n",
    "            nn.Linear(M1,f,bias=False)\n",
    "        )\n",
    "                \n",
    "    def forward(self, y):     \n",
    "        y = y.view(-1,m)\n",
    "        T = self.full(y)\n",
    "        T = T.squeeze()\n",
    "        \n",
    "        return T\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,f,M2,m):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.full = nn.Sequential(\n",
    "            nn.Linear(f,M2,bias=False),\n",
    "            SiLU(),\n",
    "            nn.Linear(M2,m,bias=False)\n",
    "        )\n",
    "             \n",
    "    def forward(self,T):\n",
    "        T = T.view(-1,f)\n",
    "        y = self.full(T)\n",
    "        y = y.squeeze()\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([900, 1000]) torch.Size([100, 1000])\n"
     ]
    }
   ],
   "source": [
    "# load solution snapshot\n",
    "solution_snapshot_orig = pickle.load(open(\"./data/snapshot_full.p\", \"rb\"))\n",
    "nx=1001\n",
    "nt=500\n",
    "\n",
    "# substract IC -> centered on IC\n",
    "ndata=solution_snapshot_orig.shape[0]\n",
    "nset= round(ndata/(nt+1))\n",
    "\n",
    "solution_snapshot=np.array([])\n",
    "for foo in range(nset):\n",
    "    solution_snapshot=np.append(solution_snapshot,solution_snapshot_orig[foo*(nt+1)+1:(foo+1)*(nt+1)]\\\n",
    "    -solution_snapshot_orig[foo*(nt+1)])\n",
    "\n",
    "solution_snapshot=np.reshape(solution_snapshot,(-1,nx))\n",
    "\n",
    "# solution_snapshot_tmp1 = solution_snapshot[:501]-solution_snapshot[0]\n",
    "# solution_snapshot_tmp2 = solution_snapshot[501:]-solution_snapshot[501]\n",
    "# solution_snapshot = np.vstack((solution_snapshot_tmp1[1:],solution_snapshot_tmp2[1:]))\n",
    "\n",
    "# remove BC\n",
    "solution_snapshot = solution_snapshot[:,:-1].astype('float32')\n",
    "\n",
    "# define testset and trainset indices\n",
    "test_ind = np.random.permutation(np.arange(solution_snapshot.shape[0]))[:int(0.1*solution_snapshot.shape[0])]\n",
    "train_ind = np.setdiff1d(np.arange(solution_snapshot.shape[0]),test_ind)\n",
    "\n",
    "# set trainset and testset\n",
    "trainset = solution_snapshot[train_ind]\n",
    "testset = solution_snapshot[test_ind] \n",
    "\n",
    "# set dataset\n",
    "dataset = {'train':data_utils.TensorDataset(torch.tensor(trainset)),\n",
    "           'test':data_utils.TensorDataset(torch.tensor(testset))}\n",
    "print(dataset['train'].tensors[0].shape, dataset['test'].tensors[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 1000) (100, 1000)\n"
     ]
    }
   ],
   "source": [
    "# compute dataset shapes\n",
    "dataset_shapes = {'train':trainset.shape,\n",
    "                 'test':testset.shape}\n",
    "\n",
    "print(dataset_shapes['train'],dataset_shapes['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # when inputs and targets are different e.g. Kernel PCA + Decoder\n",
    "# mapped_solution_snapshot = loadmat('./data/mapped_solution_snaphost.mat')['mapped_solution_snapshot']\n",
    "\n",
    "# mapped_trainset = mapped_solution_snapshot[train_ind]\n",
    "# mapped_testset = mapped_solution_snapshot[test_ind]\n",
    "\n",
    "# inputs = {'train':mapped_trainset,'test':mapped_testset}\n",
    "# outputs = {'train':trainset,'test':testset}\n",
    "\n",
    "# dataset = {'train':data_utils.TensorDataset(inputs['train'], targets['train']),\n",
    "#            'test':data_utils.TensorDataset(inputs['test'], targets['test'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set batch_size, number of epochs, paitience for early stop\n",
    "batch_size = 20\n",
    "num_epochs = 10000//5\n",
    "num_epochs_print = num_epochs*5//100\n",
    "early_stop_patience = num_epochs*5//50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data loaders\n",
    "train_loader = DataLoader(dataset=dataset['train'], \n",
    "                          batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(dataset=dataset['test'], \n",
    "                         batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "data_loaders = {'train':train_loader, 'test':test_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # copy trainset to cpu (if inputs~=targets, replace 0 to 1 for targets)\n",
    "# trainset_inputs = data_loaders['train'].dataset.tensors[0].to('cpu')\n",
    "# trainset_targets = data_loaders['train'].dataset.tensors[0].to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set checkpoint\n",
    "PATH = './checkpoint_v2_red-dim_{}.tar'.format(redDim)\n",
    "\n",
    "# set file name for AE\n",
    "file_name_AE_pkl=\"./model/AE_v2_swish_red-dim_{}.pkl\".format(redDim)\n",
    "file_name_AE=\"./model/AE_v2_swish_red-dim_{}.p\".format(redDim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the number of nodes in each layer\n",
    "m = 1000\n",
    "f = redDim\n",
    "b = 36\n",
    "db = 12\n",
    "M2 = b + (m-1)*db\n",
    "M1 = 2*m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in 1000 by 12024 mask: 99.70%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAA+CAYAAAAvbrxJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAJa0lEQVR4nO3db4wdVR3G8e9jV4oUkRYqWQpJW9MQm0aFbrSAICkoUAjViKaNhRIhvBDj30Tb8EZfEdQYJRqwqZAGkL9WaIgKpghoYopbwFooK+WPpVjoJSpUSKTgzxfnLL132e7OtvfemTv7fJJm5547c3ue7HZ/nTlnzigiMDMzG/ausjtgZmbV4sJgZmYtXBjMzKyFC4OZmbVwYTAzsxYuDGZm1qL0wiDpHElDkrZLWlV2f4qQdLyk30vaJulxSV/N7TMk/U7SU/nr9KZjVueMQ5LObmpfKOmv+b1rJKmMTCNJmiLpUUn35Nd1ynakpDslPZm/hyfXLN/X88/lVkm3SDq0l/NJul7Sbklbm9ralkfSVEm35fZNkmZXIN/388/nFkm/knRkV/NFRGl/gCnA08Bc4BDgL8D8MvtUsN/9wEl5+73A34D5wPeAVbl9FXB13p6fs00F5uTMU/J7DwMnAwJ+A5xbdr7cr28AvwDuya/rlG0dcFnePgQ4si75gFnAs8B78uvbgUt6OR9wOnASsLWprW15gC8B1+XtZcBtFcj3KaAvb1/d7Xxl/xCfDNzb9Ho1sLrMPh1gjruBTwJDQH9u6weGRssF3Juz9wNPNrUvB35WgTzHARuBxewrDHXJdgTpF6dGtNcl3yzgeWAG0Afck3/J9HQ+YPaIX5xtyzO8T97uA14e+fPR7Xwj3vsMcHM385V9KWn4h3jYztzWM/Jp2YnAJuCYiNgFkL++P++2v5yz8vbI9rL9CPgW8L+mtrpkmws0gBvypbK1kqZRk3wR8QLwA2AHsAt4JSLuoyb5mrQzz9vHRMSbwCvAUR3r+cR9kXQGAF3KV3ZhGO2aZc+s0SHpcOCXwNci4tWxdh2lLcZoL42k84HdEbG56CGjtFUyW9ZHOm2/NiJOBF4jXYrYn57Kl6+1LyVdZjgWmCZpxViHjNJW2XwFHEieymaVdCXwJnDzcNMou7U9X9mFYSdwfNPr44B/lNSXCZH0blJRuDki1ufmlyT15/f7gd25fX85d+btke1lOhW4QNJzwK3AYkk3UY9skPq1MyI25dd3kgpFXfKdBTwbEY2I2AusB06hPvmGtTPP28dI6gPeB/yzYz0vSNJK4HzgC5GvA9GlfGUXhj8D8yTNkXQIaWBkQ8l9Glce7f85sC0iftj01gZgZd5eSRp7GG5flmcHzAHmAQ/nU+A9khblz7y46ZhSRMTqiDguImaTvh/3R8QKapANICJeBJ6XdEJuOhN4gprkI11CWiTpsNyvM4Ft1CffsHbmaf6sC0k/82WfuZ8DfBu4ICJeb3qrO/nKGkxqGiRZQprV8zRwZdn9Kdjnj5NOxbYAj+U/S0jX7TYCT+WvM5qOuTJnHKJpdgcwAGzN7/2ELg96jZPzDPYNPtcmG/ARYDB//+4Cptcs33eBJ3PfbiTNYOnZfMAtpPGSvaT//V7azjzAocAdwHbSzJ65Fci3nTQuMPz75bpu5hs+0MzMDCj/UpKZmVWMC4OZmbVwYTAzsxYuDGZm1qJjhUETWBxP0uWd6kcVOF/vqnM2cL5e1slsHSkMkqYAPwXOJS36tFzS/DEOqe03L3O+3lXnbOB8vay3CgPwUWB7RDwTEW+Q7qBd2qG/y8zM2qgj9zFIuhA4JyIuy68vAj4WEV9u2udycsWbOnXqwgULFrzjczZv3szChQvb3r9uazQazJw5s+xudEyd89U5GzhfL2s0GuzYsePliGh7wL52f2A27qJNEbEGWAMwMDAQg4ODB/+XSviGPTObLCT9vROf26lLSaUsjjfRoqBqPHDLzKxSxi0MOoDHWJIe8LJY0jOSzqOii+O5kJiZvVORM4Y3gW9GxAeBRcAVeYbRKmBjRMwjLWK1CiC/93ngs/n4u4A7IuLxdne+2yZSSFxEzKxXjVsYImJXRDySt/eQlvCdRZpltC7vtg74dN5eCtwaERsiYi5wP6lwTCoHMtbhYmJmVTChMYaDfIzlyM+6XNKgpMFGozHxnteQL22ZWRUULgxteIxla0PEmogYiIiBuk4n6zRf2jKzTihUGJoeY3kM6cHUAA1JD+bB5weBl3P7TmBFXgpjCPgw1Xok4KTksxEzK6rIrKThx1geCjzU9Na/gNfz4PPr7HuG6FbgE6RLTpeRCsPB36RgXeVCYjZ5FbnB7VTgIuA/pLGCmZKWkB6H+F9JTwEvAjPy/gtIBeQx0oymLaRHzv2pvV23KjmQQuKbEc2qqcispD+SLiOdQToD+ENE/BqYGRGnRcS8iDgNODofMgu4MSI+EBEnkArEOwafbXLzGYlZdRW5lHQ+sDsiNhf8zEKDz56VZBPhQmLWPUUGn08FLpD0HGmV1MWSbgJektQPkL/uzvsXWg7Ds5Ksk1xIzA5ckUtJq0njBoPAG8BbpGct3Ac8lMcYHgJ+mw/ZAHwlz0p6BvgQ8HAH+m7WNi4kZvsUvY/hx6Rf/BeTisA20uWh4X8dzf9KYkSbRxitdlxIrM7GnZUk6QjgdOCSSP8aHsjtZwOnRcSufCnpgXzIUuCaiLgq73cv6cE9npVkk5ZnbVkvKXLGMBdoADdIelTSWknT8JIYZh3jMxIrU5HC0AecBFwbEScCr5FXUt0PL4lh1mUuJNZORW5w2wm8ClwvKUg3s+0lL4kBHEuadTRySYzvkAaq9wBr29xvMzsIvrRlYylyxjAFOAxYHhELgH7SGYCXxDCbJHxGMrkUnZX0b2CdpC3AUaQzgOnA4Xm66uGMviTGWvYtiWFmk4RX/u1tRe5jeAG4CphHOlvYGBHr8ZIYZtYGPhupniJLYkwnTUGdQxpPmCZpxViHjNLmJTHMrC38dMTOK3Ip6Szg2YhoRMReYD1wCl4Sw8x6hM9KJqZIYdgBLJJ0WH42w5mkO583ACvzPiuBu/P2BmCZpKmS5pAuQXlJDDPrGZN9jGTc6aoRsUnSncAjpOcrPAqsIQ043y7pUlLx+Fze/3FJtwNP5P2viIi3OtR/M7NS1XHqr6rQwYGBgRgc9IxWM7ORxiokkjZHRNtnfVaiMEjaAwyV3Y8OOpp9NwDWUZ3z1TkbOF8vOxqYFhFtH6QtcudzNwx1oupVhaRB5+tNdc4GztfLcrbZnfjsoje4mZnZJOHCYGZmLapSGNaU3YEOc77eVeds4Hy9rGPZKjH4bGZm1VGVMwYzM6sIFwYzM2vhwmBmZi1cGMzMrIULg5mZtfg/q2Ps8+mTzXwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------checkpoint not restored--------\n",
      "\n",
      "Sparsity in 1000 by 12024 mask: 99.70%\n",
      "\n",
      "Start first training... m=1000, f=20, M1=2000, M2=12024, b=36, db=12\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "try:\n",
    "    checkpoint = torch.load(PATH, map_location=device)\n",
    "    \n",
    "    encoder = Encoder(m,M1,f).to(device)\n",
    "    decoder = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    mask = create_mask_v2(m,b,db)\n",
    "    prune.custom_from_mask(decoder.full[2], name='weight', mask=torch.tensor(mask).to(device))    \n",
    "    \n",
    "#     optimizer = torch.optim.LBFGS(list(encoder.parameters()) + list(decoder.parameters()), lr=1)\n",
    "#     scheduler = None     \n",
    "    optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "    decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    last_epoch = checkpoint['epoch']\n",
    "    loss_hist = checkpoint['loss_hist']\n",
    "    best_loss = checkpoint['best_loss']\n",
    "    early_stop_counter = checkpoint['early_stop_counter']\n",
    "    best_encoder_wts = checkpoint['best_encoder_wts']\n",
    "    best_decoder_wts = checkpoint['best_decoder_wts']\n",
    "    \n",
    "    print(\"\\n--------checkpoint restored--------\\n\")\n",
    "    \n",
    "    # compute sparsity in mask\n",
    "    mask = decoder.state_dict()['full.2.weight_mask']\n",
    "    print(\"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "        mask.shape[0], mask.shape[1], 100. * float(torch.sum(mask == 0))/ float(mask.nelement())))\n",
    "\n",
    "    # resume training\n",
    "    print(\"\")\n",
    "    print('Re-start {}th training... m={}, f={}, M1={}, M2={}, b={}, db={}'.format(\n",
    "        last_epoch+1, m, f, M1, M2, b, db))\n",
    "except:\n",
    "    encoder = Encoder(m,M1,f).to(device)\n",
    "    decoder = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    mask = create_mask_v2(m,b,db)\n",
    "    prune.custom_from_mask(decoder.full[2], name='weight', mask=torch.tensor(mask).to(device))\n",
    "\n",
    "#     optimizer = torch.optim.LBFGS(list(encoder.parameters()) + list(decoder.parameters()), lr=1)\n",
    "#     scheduler = None \n",
    "    optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    last_epoch = 0\n",
    "    loss_hist = {'train':[],'test':[]}\n",
    "    best_loss = float(\"inf\")\n",
    "    early_stop_counter = 1\n",
    "    best_encoder_wts = copy.deepcopy(encoder.state_dict())\n",
    "    best_decoder_wts = copy.deepcopy(decoder.state_dict())\n",
    "    \n",
    "    print(\"\\n--------checkpoint not restored--------\\n\")\n",
    "    \n",
    "    # compute sparsity in mask\n",
    "    mask = decoder.state_dict()['full.2.weight_mask']\n",
    "    print(\"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "        mask.shape[0], mask.shape[1], 100. * float(torch.sum(mask == 0))/ float(mask.nelement())))\n",
    "\n",
    "    # start training\n",
    "    print(\"\")\n",
    "    print('Start first training... m={}, f={}, M1={}, M2={}, b={}, db={}'.format(\n",
    "        m, f, M1, M2, b, db))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 1.6618103755819094e-05\n",
      "test MSELoss: 1.575398346176371e-05\n",
      "\n",
      "Epoch 200/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 9.953338879616544e-06\n",
      "test MSELoss: 8.573792456445517e-06\n",
      "\n",
      "Epoch 300/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.63786243471663e-06\n",
      "test MSELoss: 2.8903258680657017e-06\n",
      "\n",
      "Epoch 400/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.168677492085812e-06\n",
      "test MSELoss: 2.4434514216409298e-06\n",
      "\n",
      "Epoch 500/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.7997330107593572e-06\n",
      "test MSELoss: 2.0217624978613458e-06\n",
      "\n",
      "Epoch 600/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.5013091645717698e-06\n",
      "test MSELoss: 1.6728776017771452e-06\n",
      "\n",
      "Epoch 700/10000, Learning rate 1.0000000000000002e-07\n",
      "----------\n",
      "train MSELoss: 1.262171573065037e-06\n",
      "test MSELoss: 1.4530636462950497e-06\n",
      "\n",
      "Epoch 800/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 1.2600270066640303e-06\n",
      "test MSELoss: 1.4509414995700354e-06\n",
      "\n",
      "Epoch 879/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 1.2598932408359866e-06\n",
      "test MSELoss: 1.4506713114315063e-06\n",
      "\n",
      "Early stopping: 879th training complete in 0h 5m 7s\n",
      "----------\n",
      "Best train MSELoss: 1.266614958694845e-06\n",
      "Best test MSELoss: 1.4463073512160918e-06\n",
      "\n",
      "Saving after 879th training to ./model/AE_v2_swish_red-dim_20.pkl\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "since = time.time()\n",
    "\n",
    "for epoch in range(last_epoch+1,num_epochs+1):   \n",
    "\n",
    "    if epoch%num_epochs_print == 0:\n",
    "        print()\n",
    "        if scheduler !=None:\n",
    "            print('Epoch {}/{}, Learning rate {}'.format(\n",
    "                epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "        else:\n",
    "            print('Epoch {}/{}'.format(\n",
    "                epoch, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and test phase\n",
    "    for phase in ['train', 'test']:\n",
    "        if phase == 'train':\n",
    "            encoder.train()  # Set model to training mode\n",
    "            decoder.train()  # Set model to training mode\n",
    "        else:\n",
    "            encoder.eval()   # Set model to evaluation mode\n",
    "            decoder.eval()   # Set model to evaluation mode\n",
    "            \n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Iterate over data\n",
    "        for data, in data_loaders[phase]:\n",
    "            inputs = data.to(device)\n",
    "            targets = data.to(device)\n",
    "\n",
    "            if phase == 'train':\n",
    "                if scheduler != None:\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    outputs = decoder(encoder(inputs))\n",
    "                    loss = loss_func(outputs, targets)\n",
    "\n",
    "                    # backward\n",
    "                    loss.backward()\n",
    "\n",
    "                    # optimize\n",
    "                    optimizer.step()  \n",
    "                    \n",
    "                    # add running loss\n",
    "                    running_loss += loss.item()*inputs.shape[0]\n",
    "                else:\n",
    "                    def closure():\n",
    "                        # zero the parameter gradients\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                        # forward\n",
    "                        outputs = decoder(encoder(inputs))\n",
    "                        loss = loss_func(outputs,targets)\n",
    "\n",
    "                        # backward\n",
    "                        loss.backward()\n",
    "                        return loss\n",
    "\n",
    "                    # optimize\n",
    "                    optimizer.step(closure)\n",
    "                    \n",
    "                    # add running loss\n",
    "                    with torch.set_grad_enabled(False):\n",
    "                        outputs = decoder(encoder(inputs))\n",
    "                        running_loss += loss_func(outputs,targets).item()*inputs.shape[0]\n",
    "                    \n",
    "            else:\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    outputs = decoder(encoder(inputs))\n",
    "                    running_loss += loss_func(outputs,targets).item()*inputs.shape[0]\n",
    "\n",
    "        # compute epoch loss\n",
    "        epoch_loss = running_loss / dataset_shapes[phase][0]\n",
    "        loss_hist[phase].append(epoch_loss)\n",
    "            \n",
    "        # update learning rate\n",
    "        if phase == 'train' and scheduler != None:\n",
    "            scheduler.step(epoch_loss)\n",
    "\n",
    "        if epoch%num_epochs_print == 0:\n",
    "            print('{} MSELoss: {}'.format(\n",
    "                phase, epoch_loss))\n",
    "\n",
    "    # deep copy the model\n",
    "    if loss_hist['test'][-1] < best_loss:\n",
    "        best_loss = loss_hist['test'][-1]\n",
    "        early_stop_counter = 1\n",
    "        best_encoder_wts = copy.deepcopy(encoder.state_dict())\n",
    "        best_decoder_wts = copy.deepcopy(decoder.state_dict())\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= early_stop_patience:  \n",
    "            break\n",
    "    \n",
    "    # save checkpoint every num_epoch_print\n",
    "    if epoch%num_epochs_print== 0:\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'encoder_state_dict': encoder.state_dict(),\n",
    "                    'decoder_state_dict': decoder.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss_hist': loss_hist,\n",
    "                    'best_loss': best_loss,\n",
    "                    'early_stop_counter': early_stop_counter,\n",
    "                    'best_encoder_wts': best_encoder_wts,\n",
    "                    'best_decoder_wts': best_decoder_wts,\n",
    "                    }, PATH)        \n",
    "\n",
    "print()\n",
    "print('Epoch {}/{}, Learning rate {}'\\\n",
    "      .format(epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "print('-' * 10)\n",
    "print('train MSELoss: {}'.format(loss_hist['train'][-1]))\n",
    "print('test MSELoss: {}'.format(loss_hist['test'][-1]))\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "\n",
    "# load best model weights\n",
    "encoder.load_state_dict(best_encoder_wts)\n",
    "decoder.load_state_dict(best_decoder_wts)\n",
    "\n",
    "# compute best train MSELoss\n",
    "encoder.to('cpu').eval()\n",
    "decoder.to('cpu').eval()\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    train_inputs = torch.tensor(trainset)\n",
    "    train_targets = torch.tensor(trainset)\n",
    "    train_outputs = decoder(encoder(train_inputs))\n",
    "    train_loss = loss_func(train_outputs,train_targets).item()\n",
    "\n",
    "# print out training time and best results\n",
    "print()\n",
    "if epoch < num_epochs:\n",
    "    print('Early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "else:\n",
    "    print('No early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "print('-' * 10)\n",
    "print('Best train MSELoss: {}'.format(train_loss))\n",
    "print('Best test MSELoss: {}'.format(best_loss))\n",
    "\n",
    "# save models\n",
    "print()\n",
    "print(\"Saving after {}th training to\".format(epoch),\n",
    "      file_name_AE_pkl)\n",
    "# torch.save((encoder,decoder),file_name_AE_pkl) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "checkpoint removed\n"
     ]
    }
   ],
   "source": [
    "# delete checkpoint\n",
    "try:\n",
    "    os.remove(PATH)\n",
    "    print()\n",
    "    print(\"checkpoint removed\")\n",
    "except:\n",
    "    print(\"no checkpoint exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and test loss\n",
    "plt.figure()\n",
    "plt.semilogy(loss_hist['train'])\n",
    "plt.semilogy(loss_hist['test'])\n",
    "plt.legend(['train','test'])\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load models\n",
    "# try:\n",
    "#     encoder,decoder = torch.load(file_name_AE_pkl,map_location='cpu')\n",
    "#     print(\"\\n--------model restored--------\\n\")\n",
    "# except:\n",
    "#     print(\"\\n--------model not restored--------\\n\")\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights and bias\n",
    "en_w1=encoder.full[0].weight.cpu().detach().numpy().astype('float32')\n",
    "en_b1=encoder.full[0].bias.cpu().detach().numpy().astype('float32')\n",
    "en_w2=encoder.full[2].weight.cpu().detach().numpy().astype('float32')\n",
    "\n",
    "de_w1=decoder.full[0].weight.cpu().detach().numpy().astype('float32')\n",
    "de_w2=decoder.full[2].weight.cpu().detach().numpy().astype('float32')\n",
    "\n",
    "de_w2_sp=sp.csr_matrix(de_w2,dtype='float32')\n",
    "\n",
    "de_w1T=de_w1.T\n",
    "de_w2T=de_w2.T\n",
    "\n",
    "de_w2T_sp=de_w2_sp.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy version of AE\n",
    "def sigmoid_np(input):\n",
    "    return (1.0/(1.0+np.exp(-input))).astype('float32')\n",
    "\n",
    "def encoder_np_forward(x):\n",
    "    z1 = en_w1.dot(x) + en_b1\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = en_w2.dot(a1)   \n",
    "    return y\n",
    "\n",
    "def decoder_np_forward(x):\n",
    "    z1 = de_w1.dot(x)\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = de_w2.dot(a1)  \n",
    "    return y\n",
    "\n",
    "def decoder_sp_forward(x):\n",
    "    z1 = de_w1.dot(x)\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = sp.csr_matrix.dot(de_w2_sp,a1)\n",
    "    return y\n",
    "\n",
    "def decoder_np_forward_backward(x):\n",
    "    z1 = de_w1.dot(x)\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = de_w2.dot(a1)\n",
    "\n",
    "    dout = de_w1T\n",
    "    dout = (s1 + a1*(1-s1))*dout\n",
    "    dydxT = dout.dot(de_w2T)   \n",
    "    return y,dydxT.T\n",
    "\n",
    "def decoder_sp_forward_backward(x):\n",
    "    z1 = de_w1.dot(x) \n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = sp.csr_matrix.dot(de_w2_sp,a1)\n",
    "\n",
    "    dout = de_w1T\n",
    "    dout = (s1 + a1*(1-s1))*dout\n",
    "    dydxT = sp.csr_matrix.dot(dout,de_w2T_sp)\n",
    "    return y,dydxT.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE: 1.28458533e-06\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (numpy version)\n",
    "comp_orig_data=np.zeros((nset*nt,f))\n",
    "rest_orig_data=np.zeros(solution_snapshot.shape)\n",
    "\n",
    "for k in range(nset*nt):\n",
    "    comp_orig_data[k]=encoder_np_forward(solution_snapshot[k])\n",
    "    rest_orig_data[k]=decoder_sp_forward(comp_orig_data[k])\n",
    "    \n",
    "print(\"MSELoss of AE: {:.8e}\".format(np.linalg.norm(solution_snapshot-rest_orig_data)**2/np.prod(solution_snapshot.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE: 1.28458407e-06\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (PyTorch model)\n",
    "input_data=torch.tensor(solution_snapshot)\n",
    "target_data=decoder(encoder(input_data))\n",
    "\n",
    "print(\"MSELoss of AE: {:.8e}\".format(torch.nn.functional.mse_loss(input_data,target_data).detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE (predictive case): 1.00127409e-06\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (predictive case)\n",
    "FOM_solution=pickle.load(open('./data/FOM.p','rb'))\n",
    "FOM_solution=FOM_solution.astype('float32')\n",
    "\n",
    "orig_data_FOM = FOM_solution[1:,:-1]\n",
    "ref=FOM_solution[0,:-1]\n",
    "\n",
    "input_FOM=torch.tensor(orig_data_FOM-ref)\n",
    "target_FOM=decoder(encoder(input_FOM))\n",
    "\n",
    "print(\"MSELoss of AE (predictive case): {:.8e}\"\\\n",
    "      .format(torch.nn.functional.mse_loss(input_FOM,target_FOM).detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights and bias   \n",
    "AE={'en_w1':en_w1,'en_b1':en_b1,'en_w2':en_w2,\n",
    "    'de_w1':de_w1,'de_w2':de_w2,\n",
    "    'de_w1T':de_w1T,'de_w2T':de_w2T,'de_w2_sp':de_w2_sp,'de_w2T_sp':de_w2T_sp}\n",
    "\n",
    "pickle.dump(AE,open(file_name_AE,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
