{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.prune as prune\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "from scipy import sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import sys,time\n",
    "import os\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "redDim=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug 21 13:39:17 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.74       Driver Version: 418.74       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro M6000        On   | 00000000:02:00.0 Off |                  Off |\n",
      "| 24%   33C    P0   139W / 250W |   1145MiB / 12212MiB |     96%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Quadro M6000        On   | 00000000:03:00.0 Off |                  Off |\n",
      "| 24%   30C    P0   134W / 250W |   1147MiB / 12212MiB |     94%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Quadro M6000        On   | 00000000:81:00.0 Off |                  Off |\n",
      "| 24%   28C    P0    62W / 250W |    324MiB / 12212MiB |      7%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Quadro M6000        On   | 00000000:82:00.0 Off |                  Off |\n",
      "| 25%   27C    P8    14W / 250W |      1MiB / 12212MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     14995      C   /home/kim101/anaconda3/bin/python           1133MiB |\n",
      "|    1     15022      C   /home/kim101/anaconda3/bin/python           1135MiB |\n",
      "|    2     15041      C   /home/kim101/anaconda3/bin/python            311MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose device that is not being used\n",
    "gpu_ids = \"3\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=gpu_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_v2(m,b,db):\n",
    "    '''\n",
    "    mask=create_mask_v2(m,b,db)  \n",
    "    '''\n",
    "    \n",
    "    M2 = b + db*(m-1)\n",
    "    mask = np.zeros((m,M2),dtype='int')\n",
    "    \n",
    "    block = np.ones(b,dtype='int')\n",
    "    ind = np.arange(b)\n",
    "    for row in range(m):\n",
    "        col = ind + row*db\n",
    "        mask[row,col] = block\n",
    "    \n",
    "    print(\n",
    "        \"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "            m, M2, (1.0-np.count_nonzero(mask)/mask.size)*100\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.spy(mask)\n",
    "    plt.show()\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silu(input):\n",
    "    return input * torch.sigmoid(input)\n",
    "class SiLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return silu(input)\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,m,M1,f):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.full = nn.Sequential(\n",
    "            nn.Linear(m,M1),\n",
    "            SiLU(),\n",
    "            nn.Linear(M1,f,bias=False)\n",
    "        )\n",
    "                \n",
    "    def forward(self, y):     \n",
    "        y = y.view(-1,m)\n",
    "        T = self.full(y)\n",
    "        T = T.squeeze()\n",
    "        \n",
    "        return T\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,f,M2,m):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.full = nn.Sequential(\n",
    "            nn.Linear(f,M2,bias=False),\n",
    "            SiLU(),\n",
    "            nn.Linear(M2,m,bias=False)\n",
    "        )\n",
    "             \n",
    "    def forward(self,T):\n",
    "        T = T.view(-1,f)\n",
    "        y = self.full(T)\n",
    "        y = y.squeeze()\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([900, 1000]) torch.Size([100, 1000])\n"
     ]
    }
   ],
   "source": [
    "# load solution snapshot\n",
    "solution_snapshot_orig = pickle.load(open(\"./data/snapshot_full.p\", \"rb\"))\n",
    "nx=1001\n",
    "nt=500\n",
    "\n",
    "# substract IC -> centered on IC\n",
    "ndata=solution_snapshot_orig.shape[0]\n",
    "nset= round(ndata/(nt+1))\n",
    "\n",
    "solution_snapshot=np.array([])\n",
    "for foo in range(nset):\n",
    "    solution_snapshot=np.append(solution_snapshot,solution_snapshot_orig[foo*(nt+1)+1:(foo+1)*(nt+1)]\\\n",
    "    -solution_snapshot_orig[foo*(nt+1)])\n",
    "\n",
    "solution_snapshot=np.reshape(solution_snapshot,(-1,nx))\n",
    "\n",
    "# solution_snapshot_tmp1 = solution_snapshot[:501]-solution_snapshot[0]\n",
    "# solution_snapshot_tmp2 = solution_snapshot[501:]-solution_snapshot[501]\n",
    "# solution_snapshot = np.vstack((solution_snapshot_tmp1[1:],solution_snapshot_tmp2[1:]))\n",
    "\n",
    "# remove BC\n",
    "solution_snapshot = solution_snapshot[:,:-1].astype('float32')\n",
    "\n",
    "# define testset and trainset indices\n",
    "test_ind = np.random.permutation(np.arange(solution_snapshot.shape[0]))[:int(0.1*solution_snapshot.shape[0])]\n",
    "train_ind = np.setdiff1d(np.arange(solution_snapshot.shape[0]),test_ind)\n",
    "\n",
    "# set trainset and testset\n",
    "trainset = solution_snapshot[train_ind]\n",
    "testset = solution_snapshot[test_ind] \n",
    "\n",
    "# set dataset\n",
    "dataset = {'train':data_utils.TensorDataset(torch.tensor(trainset)),\n",
    "           'test':data_utils.TensorDataset(torch.tensor(testset))}\n",
    "print(dataset['train'].tensors[0].shape, dataset['test'].tensors[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 1000) (100, 1000)\n"
     ]
    }
   ],
   "source": [
    "# compute dataset shapes\n",
    "dataset_shapes = {'train':trainset.shape,\n",
    "                 'test':testset.shape}\n",
    "\n",
    "print(dataset_shapes['train'],dataset_shapes['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # when inputs and targets are different e.g. Kernel PCA + Decoder\n",
    "# mapped_solution_snapshot = loadmat('./data/mapped_solution_snaphost.mat')['mapped_solution_snapshot']\n",
    "\n",
    "# mapped_trainset = mapped_solution_snapshot[train_ind]\n",
    "# mapped_testset = mapped_solution_snapshot[test_ind]\n",
    "\n",
    "# inputs = {'train':mapped_trainset,'test':mapped_testset}\n",
    "# outputs = {'train':trainset,'test':testset}\n",
    "\n",
    "# dataset = {'train':data_utils.TensorDataset(inputs['train'], targets['train']),\n",
    "#            'test':data_utils.TensorDataset(inputs['test'], targets['test'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set batch_size, number of epochs, paitience for early stop\n",
    "batch_size = 20\n",
    "num_epochs = 10000//5\n",
    "num_epochs_print = num_epochs*5//100\n",
    "early_stop_patience = num_epochs*5//50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data loaders\n",
    "train_loader = DataLoader(dataset=dataset['train'], \n",
    "                          batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(dataset=dataset['test'], \n",
    "                         batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "data_loaders = {'train':train_loader, 'test':test_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # copy trainset to cpu (if inputs~=targets, replace 0 to 1 for targets)\n",
    "# trainset_inputs = data_loaders['train'].dataset.tensors[0].to('cpu')\n",
    "# trainset_targets = data_loaders['train'].dataset.tensors[0].to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set checkpoint\n",
    "PATH = './checkpoint_v2_red-dim_{}.tar'.format(redDim)\n",
    "\n",
    "# set file name for AE\n",
    "file_name_AE_pkl=\"./model/AE_v2_swish_red-dim_{}.pkl\".format(redDim)\n",
    "file_name_AE=\"./model/AE_v2_swish_red-dim_{}.p\".format(redDim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the number of nodes in each layer\n",
    "m = 1000\n",
    "f = redDim\n",
    "b = 36\n",
    "db = 12\n",
    "M2 = b + (m-1)*db\n",
    "M1 = 2*m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in 1000 by 12024 mask: 99.70%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------checkpoint not restored--------\n",
      "\n",
      "Sparsity in 1000 by 12024 mask: 99.70%\n",
      "\n",
      "Start first training... m=1000, f=40, M1=2000, M2=12024, b=36, db=12\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "try:\n",
    "    checkpoint = torch.load(PATH, map_location=device)\n",
    "    \n",
    "    encoder = Encoder(m,M1,f).to(device)\n",
    "    decoder = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    mask = create_mask_v2(m,b,db)\n",
    "    prune.custom_from_mask(decoder.full[2], name='weight', mask=torch.tensor(mask).to(device))    \n",
    "    \n",
    "#     optimizer = torch.optim.LBFGS(list(encoder.parameters()) + list(decoder.parameters()), lr=1)\n",
    "#     scheduler = None     \n",
    "    optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "    decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    last_epoch = checkpoint['epoch']\n",
    "    loss_hist = checkpoint['loss_hist']\n",
    "    best_loss = checkpoint['best_loss']\n",
    "    early_stop_counter = checkpoint['early_stop_counter']\n",
    "    best_encoder_wts = checkpoint['best_encoder_wts']\n",
    "    best_decoder_wts = checkpoint['best_decoder_wts']\n",
    "    \n",
    "    print(\"\\n--------checkpoint restored--------\\n\")\n",
    "    \n",
    "    # compute sparsity in mask\n",
    "    mask = decoder.state_dict()['full.2.weight_mask']\n",
    "    print(\"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "        mask.shape[0], mask.shape[1], 100. * float(torch.sum(mask == 0))/ float(mask.nelement())))\n",
    "\n",
    "    # resume training\n",
    "    print(\"\")\n",
    "    print('Re-start {}th training... m={}, f={}, M1={}, M2={}, b={}, db={}'.format(\n",
    "        last_epoch+1, m, f, M1, M2, b, db))\n",
    "except:\n",
    "    encoder = Encoder(m,M1,f).to(device)\n",
    "    decoder = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    mask = create_mask_v2(m,b,db)\n",
    "    prune.custom_from_mask(decoder.full[2], name='weight', mask=torch.tensor(mask).to(device))\n",
    "\n",
    "#     optimizer = torch.optim.LBFGS(list(encoder.parameters()) + list(decoder.parameters()), lr=1)\n",
    "#     scheduler = None \n",
    "    optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    last_epoch = 0\n",
    "    loss_hist = {'train':[],'test':[]}\n",
    "    best_loss = float(\"inf\")\n",
    "    early_stop_counter = 1\n",
    "    best_encoder_wts = copy.deepcopy(encoder.state_dict())\n",
    "    best_decoder_wts = copy.deepcopy(decoder.state_dict())\n",
    "    \n",
    "    print(\"\\n--------checkpoint not restored--------\\n\")\n",
    "    \n",
    "    # compute sparsity in mask\n",
    "    mask = decoder.state_dict()['full.2.weight_mask']\n",
    "    print(\"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "        mask.shape[0], mask.shape[1], 100. * float(torch.sum(mask == 0))/ float(mask.nelement())))\n",
    "\n",
    "    # start training\n",
    "    print(\"\")\n",
    "    print('Start first training... m={}, f={}, M1={}, M2={}, b={}, db={}'.format(\n",
    "        m, f, M1, M2, b, db))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 1.714959936281149e-05\n",
      "test MSELoss: 1.8523301514505873e-05\n",
      "\n",
      "Epoch 200/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 6.161865642045288e-06\n",
      "test MSELoss: 7.2253858888871035e-06\n",
      "\n",
      "Epoch 300/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.197391252896826e-06\n",
      "test MSELoss: 2.6717959372035695e-06\n",
      "\n",
      "Epoch 400/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.6363170528974377e-06\n",
      "test MSELoss: 1.935497198246594e-06\n",
      "\n",
      "Epoch 500/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.2644233758389115e-06\n",
      "test MSELoss: 1.4516265423480945e-06\n",
      "\n",
      "Epoch 600/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.0040990623060174e-06\n",
      "test MSELoss: 1.166457957424427e-06\n",
      "\n",
      "Epoch 700/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 7.57554209940281e-07\n",
      "test MSELoss: 9.138381528828177e-07\n",
      "\n",
      "Epoch 800/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 7.336226638522526e-07\n",
      "test MSELoss: 8.882480301508622e-07\n",
      "\n",
      "Epoch 900/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 7.137359444995026e-07\n",
      "test MSELoss: 8.600108117207128e-07\n",
      "\n",
      "Epoch 1000/10000, Learning rate 1.0000000000000002e-07\n",
      "----------\n",
      "train MSELoss: 6.824599804783954e-07\n",
      "test MSELoss: 8.322293922446989e-07\n",
      "\n",
      "Epoch 1100/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 6.807971266829959e-07\n",
      "test MSELoss: 8.31932641176536e-07\n",
      "\n",
      "Epoch 1166/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 6.806604214186034e-07\n",
      "test MSELoss: 8.317850301864382e-07\n",
      "\n",
      "Early stopping: 1166th training complete in 0h 6m 53s\n",
      "----------\n",
      "Best train MSELoss: 6.82772054005909e-07\n",
      "Best test MSELoss: 8.297894396491756e-07\n",
      "\n",
      "Saving after 1166th training to ./model/AE_v2_swish_red-dim_40.pkl\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "since = time.time()\n",
    "\n",
    "for epoch in range(last_epoch+1,num_epochs+1):   \n",
    "\n",
    "    if epoch%num_epochs_print == 0:\n",
    "        print()\n",
    "        if scheduler !=None:\n",
    "            print('Epoch {}/{}, Learning rate {}'.format(\n",
    "                epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "        else:\n",
    "            print('Epoch {}/{}'.format(\n",
    "                epoch, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and test phase\n",
    "    for phase in ['train', 'test']:\n",
    "        if phase == 'train':\n",
    "            encoder.train()  # Set model to training mode\n",
    "            decoder.train()  # Set model to training mode\n",
    "        else:\n",
    "            encoder.eval()   # Set model to evaluation mode\n",
    "            decoder.eval()   # Set model to evaluation mode\n",
    "            \n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Iterate over data\n",
    "        for data, in data_loaders[phase]:\n",
    "            inputs = data.to(device)\n",
    "            targets = data.to(device)\n",
    "\n",
    "            if phase == 'train':\n",
    "                if scheduler != None:\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    outputs = decoder(encoder(inputs))\n",
    "                    loss = loss_func(outputs, targets)\n",
    "\n",
    "                    # backward\n",
    "                    loss.backward()\n",
    "\n",
    "                    # optimize\n",
    "                    optimizer.step()  \n",
    "                    \n",
    "                    # add running loss\n",
    "                    running_loss += loss.item()*inputs.shape[0]\n",
    "                else:\n",
    "                    def closure():\n",
    "                        # zero the parameter gradients\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                        # forward\n",
    "                        outputs = decoder(encoder(inputs))\n",
    "                        loss = loss_func(outputs,targets)\n",
    "\n",
    "                        # backward\n",
    "                        loss.backward()\n",
    "                        return loss\n",
    "\n",
    "                    # optimize\n",
    "                    optimizer.step(closure)\n",
    "                    \n",
    "                    # add running loss\n",
    "                    with torch.set_grad_enabled(False):\n",
    "                        outputs = decoder(encoder(inputs))\n",
    "                        running_loss += loss_func(outputs,targets).item()*inputs.shape[0]\n",
    "                    \n",
    "            else:\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    outputs = decoder(encoder(inputs))\n",
    "                    running_loss += loss_func(outputs,targets).item()*inputs.shape[0]\n",
    "\n",
    "        # compute epoch loss\n",
    "        epoch_loss = running_loss / dataset_shapes[phase][0]\n",
    "        loss_hist[phase].append(epoch_loss)\n",
    "            \n",
    "        # update learning rate\n",
    "        if phase == 'train' and scheduler != None:\n",
    "            scheduler.step(epoch_loss)\n",
    "\n",
    "        if epoch%num_epochs_print == 0:\n",
    "            print('{} MSELoss: {}'.format(\n",
    "                phase, epoch_loss))\n",
    "\n",
    "    # deep copy the model\n",
    "    if loss_hist['test'][-1] < best_loss:\n",
    "        best_loss = loss_hist['test'][-1]\n",
    "        early_stop_counter = 1\n",
    "        best_encoder_wts = copy.deepcopy(encoder.state_dict())\n",
    "        best_decoder_wts = copy.deepcopy(decoder.state_dict())\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= early_stop_patience:  \n",
    "            break\n",
    "    \n",
    "    # save checkpoint every num_epoch_print\n",
    "    if epoch%num_epochs_print== 0:\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'encoder_state_dict': encoder.state_dict(),\n",
    "                    'decoder_state_dict': decoder.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss_hist': loss_hist,\n",
    "                    'best_loss': best_loss,\n",
    "                    'early_stop_counter': early_stop_counter,\n",
    "                    'best_encoder_wts': best_encoder_wts,\n",
    "                    'best_decoder_wts': best_decoder_wts,\n",
    "                    }, PATH)        \n",
    "\n",
    "print()\n",
    "print('Epoch {}/{}, Learning rate {}'\\\n",
    "      .format(epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "print('-' * 10)\n",
    "print('train MSELoss: {}'.format(loss_hist['train'][-1]))\n",
    "print('test MSELoss: {}'.format(loss_hist['test'][-1]))\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "\n",
    "# load best model weights\n",
    "encoder.load_state_dict(best_encoder_wts)\n",
    "decoder.load_state_dict(best_decoder_wts)\n",
    "\n",
    "# compute best train MSELoss\n",
    "encoder.to('cpu').eval()\n",
    "decoder.to('cpu').eval()\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    train_inputs = torch.tensor(trainset)\n",
    "    train_targets = torch.tensor(trainset)\n",
    "    train_outputs = decoder(encoder(train_inputs))\n",
    "    train_loss = loss_func(train_outputs,train_targets).item()\n",
    "\n",
    "# print out training time and best results\n",
    "print()\n",
    "if epoch < num_epochs:\n",
    "    print('Early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "else:\n",
    "    print('No early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "print('-' * 10)\n",
    "print('Best train MSELoss: {}'.format(train_loss))\n",
    "print('Best test MSELoss: {}'.format(best_loss))\n",
    "\n",
    "# save models\n",
    "print()\n",
    "print(\"Saving after {}th training to\".format(epoch),\n",
    "      file_name_AE_pkl)\n",
    "# torch.save((encoder,decoder),file_name_AE_pkl) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "checkpoint removed\n"
     ]
    }
   ],
   "source": [
    "# delete checkpoint\n",
    "try:\n",
    "    os.remove(PATH)\n",
    "    print()\n",
    "    print(\"checkpoint removed\")\n",
    "except:\n",
    "    print(\"no checkpoint exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and test loss\n",
    "plt.figure()\n",
    "plt.semilogy(loss_hist['train'])\n",
    "plt.semilogy(loss_hist['test'])\n",
    "plt.legend(['train','test'])\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load models\n",
    "# try:\n",
    "#     encoder,decoder = torch.load(file_name_AE_pkl,map_location='cpu')\n",
    "#     print(\"\\n--------model restored--------\\n\")\n",
    "# except:\n",
    "#     print(\"\\n--------model not restored--------\\n\")\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights and bias\n",
    "en_w1=encoder.full[0].weight.cpu().detach().numpy().astype('float32')\n",
    "en_b1=encoder.full[0].bias.cpu().detach().numpy().astype('float32')\n",
    "en_w2=encoder.full[2].weight.cpu().detach().numpy().astype('float32')\n",
    "\n",
    "de_w1=decoder.full[0].weight.cpu().detach().numpy().astype('float32')\n",
    "de_w2=decoder.full[2].weight.cpu().detach().numpy().astype('float32')\n",
    "\n",
    "de_w2_sp=sp.csr_matrix(de_w2,dtype='float32')\n",
    "\n",
    "de_w1T=de_w1.T\n",
    "de_w2T=de_w2.T\n",
    "\n",
    "de_w2T_sp=de_w2_sp.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy version of AE\n",
    "def sigmoid_np(input):\n",
    "    return (1.0/(1.0+np.exp(-input))).astype('float32')\n",
    "\n",
    "def encoder_np_forward(x):\n",
    "    z1 = en_w1.dot(x) + en_b1\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = en_w2.dot(a1)   \n",
    "    return y\n",
    "\n",
    "def decoder_np_forward(x):\n",
    "    z1 = de_w1.dot(x)\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = de_w2.dot(a1)  \n",
    "    return y\n",
    "\n",
    "def decoder_sp_forward(x):\n",
    "    z1 = de_w1.dot(x)\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = sp.csr_matrix.dot(de_w2_sp,a1)\n",
    "    return y\n",
    "\n",
    "def decoder_np_forward_backward(x):\n",
    "    z1 = de_w1.dot(x)\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = de_w2.dot(a1)\n",
    "\n",
    "    dout = de_w1T\n",
    "    dout = (s1 + a1*(1-s1))*dout\n",
    "    dydxT = dout.dot(de_w2T)   \n",
    "    return y,dydxT.T\n",
    "\n",
    "def decoder_sp_forward_backward(x):\n",
    "    z1 = de_w1.dot(x) \n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = sp.csr_matrix.dot(de_w2_sp,a1)\n",
    "\n",
    "    dout = de_w1T\n",
    "    dout = (s1 + a1*(1-s1))*dout\n",
    "    dydxT = sp.csr_matrix.dot(dout,de_w2T_sp)\n",
    "    return y,dydxT.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE: 6.97474138e-07\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (numpy version)\n",
    "comp_orig_data=np.zeros((nset*nt,f))\n",
    "rest_orig_data=np.zeros(solution_snapshot.shape)\n",
    "\n",
    "for k in range(nset*nt):\n",
    "    comp_orig_data[k]=encoder_np_forward(solution_snapshot[k])\n",
    "    rest_orig_data[k]=decoder_sp_forward(comp_orig_data[k])\n",
    "    \n",
    "print(\"MSELoss of AE: {:.8e}\".format(np.linalg.norm(solution_snapshot-rest_orig_data)**2/np.prod(solution_snapshot.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE: 6.97473524e-07\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (PyTorch model)\n",
    "input_data=torch.tensor(solution_snapshot)\n",
    "target_data=decoder(encoder(input_data))\n",
    "\n",
    "print(\"MSELoss of AE: {:.8e}\".format(torch.nn.functional.mse_loss(input_data,target_data).detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE (predictive case): 1.17366324e-06\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (predictive case)\n",
    "FOM_solution=pickle.load(open('./data/FOM.p','rb'))\n",
    "FOM_solution=FOM_solution.astype('float32')\n",
    "\n",
    "orig_data_FOM = FOM_solution[1:,:-1]\n",
    "ref=FOM_solution[0,:-1]\n",
    "\n",
    "input_FOM=torch.tensor(orig_data_FOM-ref)\n",
    "target_FOM=decoder(encoder(input_FOM))\n",
    "\n",
    "print(\"MSELoss of AE (predictive case): {:.8e}\"\\\n",
    "      .format(torch.nn.functional.mse_loss(input_FOM,target_FOM).detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights and bias   \n",
    "AE={'en_w1':en_w1,'en_b1':en_b1,'en_w2':en_w2,\n",
    "    'de_w1':de_w1,'de_w2':de_w2,\n",
    "    'de_w1T':de_w1T,'de_w2T':de_w2T,'de_w2_sp':de_w2_sp,'de_w2T_sp':de_w2T_sp}\n",
    "\n",
    "pickle.dump(AE,open(file_name_AE,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
