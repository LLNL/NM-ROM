{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.prune as prune\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "from scipy import sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import sys,time\n",
    "import os\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "redDim=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose device that is not being used\n",
    "gpu_ids = \"0\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=gpu_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_v2(m,b,db):\n",
    "    '''\n",
    "    mask=create_mask_v2(m,b,db)  \n",
    "    '''\n",
    "    \n",
    "    M2 = b + db*(m-1)\n",
    "    mask = np.zeros((m,M2),dtype='int')\n",
    "    \n",
    "    block = np.ones(b,dtype='int')\n",
    "    ind = np.arange(b)\n",
    "    for row in range(m):\n",
    "        col = ind + row*db\n",
    "        mask[row,col] = block\n",
    "    \n",
    "    print(\n",
    "        \"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "            m, M2, (1.0-np.count_nonzero(mask)/mask.size)*100\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.spy(mask)\n",
    "    plt.show()\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silu(input):\n",
    "    return input * torch.sigmoid(input)\n",
    "class SiLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return silu(input)\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,m,M1,f):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.full = nn.Sequential(\n",
    "            nn.Linear(m,M1),\n",
    "            SiLU(),\n",
    "            nn.Linear(M1,f,bias=False)\n",
    "        )\n",
    "                \n",
    "    def forward(self, y):     \n",
    "        y = y.view(-1,m)\n",
    "        T = self.full(y)\n",
    "        T = T.squeeze()\n",
    "        \n",
    "        return T\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,f,M2,m):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.full = nn.Sequential(\n",
    "            nn.Linear(f,M2,bias=False),\n",
    "            SiLU(),\n",
    "            nn.Linear(M2,m,bias=False)\n",
    "        )\n",
    "             \n",
    "    def forward(self,T):\n",
    "        T = T.view(-1,f)\n",
    "        y = self.full(T)\n",
    "        y = y.squeeze()\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([900, 1000]) torch.Size([100, 1000])\n"
     ]
    }
   ],
   "source": [
    "# load solution snapshot\n",
    "solution_snapshot_orig = pickle.load(open(\"./data/snapshot_full.p\", \"rb\"))\n",
    "nx=1001\n",
    "nt=500\n",
    "\n",
    "# substract IC -> centered on IC\n",
    "ndata=solution_snapshot_orig.shape[0]\n",
    "nset= round(ndata/(nt+1))\n",
    "\n",
    "solution_snapshot=np.array([])\n",
    "for foo in range(nset):\n",
    "    solution_snapshot=np.append(solution_snapshot,solution_snapshot_orig[foo*(nt+1)+1:(foo+1)*(nt+1)]\\\n",
    "    -solution_snapshot_orig[foo*(nt+1)])\n",
    "\n",
    "solution_snapshot=np.reshape(solution_snapshot,(-1,nx))\n",
    "\n",
    "# solution_snapshot_tmp1 = solution_snapshot[:501]-solution_snapshot[0]\n",
    "# solution_snapshot_tmp2 = solution_snapshot[501:]-solution_snapshot[501]\n",
    "# solution_snapshot = np.vstack((solution_snapshot_tmp1[1:],solution_snapshot_tmp2[1:]))\n",
    "\n",
    "# remove BC\n",
    "solution_snapshot = solution_snapshot[:,:-1].astype('float32')\n",
    "\n",
    "# define testset and trainset indices\n",
    "test_ind = np.random.permutation(np.arange(solution_snapshot.shape[0]))[:int(0.1*solution_snapshot.shape[0])]\n",
    "train_ind = np.setdiff1d(np.arange(solution_snapshot.shape[0]),test_ind)\n",
    "\n",
    "# set trainset and testset\n",
    "trainset = solution_snapshot[train_ind]\n",
    "testset = solution_snapshot[test_ind] \n",
    "\n",
    "# set dataset\n",
    "dataset = {'train':data_utils.TensorDataset(torch.tensor(trainset)),\n",
    "           'test':data_utils.TensorDataset(torch.tensor(testset))}\n",
    "print(dataset['train'].tensors[0].shape, dataset['test'].tensors[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 1000) (100, 1000)\n"
     ]
    }
   ],
   "source": [
    "# compute dataset shapes\n",
    "dataset_shapes = {'train':trainset.shape,\n",
    "                 'test':testset.shape}\n",
    "\n",
    "print(dataset_shapes['train'],dataset_shapes['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set batch_size, number of epochs, paitience for early stop\n",
    "batch_size = 20\n",
    "num_epochs = 10000\n",
    "num_epochs_print = num_epochs//100\n",
    "early_stop_patience = num_epochs//50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data loaders\n",
    "train_loader = DataLoader(dataset=dataset['train'], \n",
    "                          batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(dataset=dataset['test'], \n",
    "                         batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "data_loaders = {'train':train_loader, 'test':test_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set checkpoint\n",
    "PATH = './checkpoint_v2_red-dim_{}.tar'.format(redDim)\n",
    "\n",
    "# set file name for AE\n",
    "file_name_AE_pkl=\"./model/AE_v2_swish_red-dim_{}.pkl\".format(redDim)\n",
    "file_name_AE=\"./model/AE_v2_swish_red-dim_{}.p\".format(redDim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the number of nodes in each layer\n",
    "m = 1000\n",
    "f = redDim\n",
    "b = 36\n",
    "db = 12\n",
    "M2 = b + (m-1)*db\n",
    "M1 = 2*m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in 1000 by 12024 mask: 99.70%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------checkpoint not restored--------\n",
      "\n",
      "Sparsity in 1000 by 12024 mask: 99.70%\n",
      "\n",
      "Start first training... m=1000, f=5, M1=2000, M2=12024, b=36, db=12\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "try:\n",
    "    checkpoint = torch.load(PATH, map_location=device)\n",
    "    \n",
    "    encoder = Encoder(m,M1,f).to(device)\n",
    "    decoder = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    mask = create_mask_v2(m,b,db)\n",
    "    prune.custom_from_mask(decoder.full[2], name='weight', mask=torch.tensor(mask).to(device))    \n",
    "    \n",
    "#     optimizer = torch.optim.LBFGS(list(encoder.parameters()) + list(decoder.parameters()), lr=1)\n",
    "#     scheduler = None     \n",
    "    optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "    decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    last_epoch = checkpoint['epoch']\n",
    "    loss_hist = checkpoint['loss_hist']\n",
    "    best_loss = checkpoint['best_loss']\n",
    "    early_stop_counter = checkpoint['early_stop_counter']\n",
    "    best_encoder_wts = checkpoint['best_encoder_wts']\n",
    "    best_decoder_wts = checkpoint['best_decoder_wts']\n",
    "    \n",
    "    print(\"\\n--------checkpoint restored--------\\n\")\n",
    "    \n",
    "    # compute sparsity in mask\n",
    "    mask = decoder.state_dict()['full.2.weight_mask']\n",
    "    print(\"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "        mask.shape[0], mask.shape[1], 100. * float(torch.sum(mask == 0))/ float(mask.nelement())))\n",
    "\n",
    "    # resume training\n",
    "    print(\"\")\n",
    "    print('Re-start {}th training... m={}, f={}, M1={}, M2={}, b={}, db={}'.format(\n",
    "        last_epoch+1, m, f, M1, M2, b, db))\n",
    "except:\n",
    "    encoder = Encoder(m,M1,f).to(device)\n",
    "    decoder = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    mask = create_mask_v2(m,b,db)\n",
    "    prune.custom_from_mask(decoder.full[2], name='weight', mask=torch.tensor(mask).to(device))\n",
    "\n",
    "#     optimizer = torch.optim.LBFGS(list(encoder.parameters()) + list(decoder.parameters()), lr=1)\n",
    "#     scheduler = None \n",
    "    optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    last_epoch = 0\n",
    "    loss_hist = {'train':[],'test':[]}\n",
    "    best_loss = float(\"inf\")\n",
    "    early_stop_counter = 1\n",
    "    best_encoder_wts = copy.deepcopy(encoder.state_dict())\n",
    "    best_decoder_wts = copy.deepcopy(decoder.state_dict())\n",
    "    \n",
    "    print(\"\\n--------checkpoint not restored--------\\n\")\n",
    "    \n",
    "    # compute sparsity in mask\n",
    "    mask = decoder.state_dict()['full.2.weight_mask']\n",
    "    print(\"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "        mask.shape[0], mask.shape[1], 100. * float(torch.sum(mask == 0))/ float(mask.nelement())))\n",
    "\n",
    "    # start training\n",
    "    print(\"\")\n",
    "    print('Start first training... m={}, f={}, M1={}, M2={}, b={}, db={}'.format(\n",
    "        m, f, M1, M2, b, db))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 1.944950284572163e-05\n",
      "test MSELoss: 1.625546374270925e-05\n",
      "\n",
      "Epoch 200/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.0164280471750923e-05\n",
      "test MSELoss: 8.513390366715611e-06\n",
      "\n",
      "Epoch 300/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 9.389184267800172e-06\n",
      "test MSELoss: 7.744236427242868e-06\n",
      "\n",
      "Epoch 400/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 8.52496418196501e-06\n",
      "test MSELoss: 7.036532224447001e-06\n",
      "\n",
      "Epoch 500/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 7.832397512983233e-06\n",
      "test MSELoss: 6.591223245777655e-06\n",
      "\n",
      "Epoch 600/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 7.217044973610124e-06\n",
      "test MSELoss: 5.979144498269307e-06\n",
      "\n",
      "Epoch 700/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 6.687533975006469e-06\n",
      "test MSELoss: 5.630117175314808e-06\n",
      "\n",
      "Epoch 800/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 6.229210440425151e-06\n",
      "test MSELoss: 5.1900377911806576e-06\n",
      "\n",
      "Epoch 900/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 5.8407683253689254e-06\n",
      "test MSELoss: 4.887252453045221e-06\n",
      "\n",
      "Epoch 1000/10000, Learning rate 1.0000000000000002e-07\n",
      "----------\n",
      "train MSELoss: 5.4153430887203686e-06\n",
      "test MSELoss: 4.604393006957253e-06\n",
      "\n",
      "Epoch 1100/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 5.410608951529462e-06\n",
      "test MSELoss: 4.6023308641451875e-06\n",
      "\n",
      "Epoch 1187/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 5.410464331766383e-06\n",
      "test MSELoss: 4.601887849275954e-06\n",
      "\n",
      "Early stopping: 1187th training complete in 0h 6m 55s\n",
      "----------\n",
      "Best train MSELoss: 5.426452389656333e-06\n",
      "Best test MSELoss: 4.594875144903199e-06\n",
      "\n",
      "Saving after 1187th training to ./model/AE_v2_swish_red-dim_5.pkl\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "since = time.time()\n",
    "\n",
    "for epoch in range(last_epoch+1,num_epochs+1):   \n",
    "\n",
    "    if epoch%num_epochs_print == 0:\n",
    "        print()\n",
    "        if scheduler !=None:\n",
    "            print('Epoch {}/{}, Learning rate {}'.format(\n",
    "                epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "        else:\n",
    "            print('Epoch {}/{}'.format(\n",
    "                epoch, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and test phase\n",
    "    for phase in ['train', 'test']:\n",
    "        if phase == 'train':\n",
    "            encoder.train()  # Set model to training mode\n",
    "            decoder.train()  # Set model to training mode\n",
    "        else:\n",
    "            encoder.eval()   # Set model to evaluation mode\n",
    "            decoder.eval()   # Set model to evaluation mode\n",
    "            \n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Iterate over data\n",
    "        for data, in data_loaders[phase]:\n",
    "            inputs = data.to(device)\n",
    "            targets = data.to(device)\n",
    "\n",
    "            if phase == 'train':\n",
    "                if scheduler != None:\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    outputs = decoder(encoder(inputs))\n",
    "                    loss = loss_func(outputs, targets)\n",
    "\n",
    "                    # backward\n",
    "                    loss.backward()\n",
    "\n",
    "                    # optimize\n",
    "                    optimizer.step()  \n",
    "                    \n",
    "                    # add running loss\n",
    "                    running_loss += loss.item()*inputs.shape[0]\n",
    "                else:\n",
    "                    def closure():\n",
    "                        # zero the parameter gradients\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                        # forward\n",
    "                        outputs = decoder(encoder(inputs))\n",
    "                        loss = loss_func(outputs,targets)\n",
    "\n",
    "                        # backward\n",
    "                        loss.backward()\n",
    "                        return loss\n",
    "\n",
    "                    # optimize\n",
    "                    optimizer.step(closure)\n",
    "                    \n",
    "                    # add running loss\n",
    "                    with torch.set_grad_enabled(False):\n",
    "                        outputs = decoder(encoder(inputs))\n",
    "                        running_loss += loss_func(outputs,targets).item()*inputs.shape[0]\n",
    "                    \n",
    "            else:\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    outputs = decoder(encoder(inputs))\n",
    "                    running_loss += loss_func(outputs,targets).item()*inputs.shape[0]\n",
    "\n",
    "        # compute epoch loss\n",
    "        epoch_loss = running_loss / dataset_shapes[phase][0]\n",
    "        loss_hist[phase].append(epoch_loss)\n",
    "            \n",
    "        # update learning rate\n",
    "        if phase == 'train' and scheduler != None:\n",
    "            scheduler.step(epoch_loss)\n",
    "\n",
    "        if epoch%num_epochs_print == 0:\n",
    "            print('{} MSELoss: {}'.format(\n",
    "                phase, epoch_loss))\n",
    "\n",
    "    # deep copy the model\n",
    "    if loss_hist['test'][-1] < best_loss:\n",
    "        best_loss = loss_hist['test'][-1]\n",
    "        early_stop_counter = 1\n",
    "        best_encoder_wts = copy.deepcopy(encoder.state_dict())\n",
    "        best_decoder_wts = copy.deepcopy(decoder.state_dict())\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= early_stop_patience:  \n",
    "            break\n",
    "    \n",
    "    # save checkpoint every num_epoch_print\n",
    "    if epoch%num_epochs_print== 0:\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'encoder_state_dict': encoder.state_dict(),\n",
    "                    'decoder_state_dict': decoder.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss_hist': loss_hist,\n",
    "                    'best_loss': best_loss,\n",
    "                    'early_stop_counter': early_stop_counter,\n",
    "                    'best_encoder_wts': best_encoder_wts,\n",
    "                    'best_decoder_wts': best_decoder_wts,\n",
    "                    }, PATH)        \n",
    "\n",
    "print()\n",
    "print('Epoch {}/{}, Learning rate {}'\\\n",
    "      .format(epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "print('-' * 10)\n",
    "print('train MSELoss: {}'.format(loss_hist['train'][-1]))\n",
    "print('test MSELoss: {}'.format(loss_hist['test'][-1]))\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "\n",
    "# load best model weights\n",
    "encoder.load_state_dict(best_encoder_wts)\n",
    "decoder.load_state_dict(best_decoder_wts)\n",
    "\n",
    "# compute best train MSELoss\n",
    "encoder.to('cpu').eval()\n",
    "decoder.to('cpu').eval()\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    train_inputs = torch.tensor(trainset)\n",
    "    train_targets = torch.tensor(trainset)\n",
    "    train_outputs = decoder(encoder(train_inputs))\n",
    "    train_loss = loss_func(train_outputs,train_targets).item()\n",
    "\n",
    "# print out training time and best results\n",
    "print()\n",
    "if epoch < num_epochs:\n",
    "    print('Early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "else:\n",
    "    print('No early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "print('-' * 10)\n",
    "print('Best train MSELoss: {}'.format(train_loss))\n",
    "print('Best test MSELoss: {}'.format(best_loss))\n",
    "\n",
    "# # save models\n",
    "# print()\n",
    "# print(\"Saving after {}th training to\".format(epoch),\n",
    "#       file_name_AE_pkl)\n",
    "# torch.save((encoder,decoder),file_name_AE_pkl) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "checkpoint removed\n"
     ]
    }
   ],
   "source": [
    "# delete checkpoint\n",
    "try:\n",
    "    os.remove(PATH)\n",
    "    print()\n",
    "    print(\"checkpoint removed\")\n",
    "except:\n",
    "    print(\"no checkpoint exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD4CAYAAADrRI2NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZxcZZ3v8c+vlq7qvZPu7AsJBiMRkKVFGBwHF4SwuwwXMTM6IFHvyxm8c1HhenX05cyAM45XGUEHEBUVGAZ0BAUNOGRACUICAUNCFkggnaSTdCe9d1V3VT33j1Pdqa5e0umq7j59+vt+vfqVU6dreZ5Avuep3/Occ8w5h4iITB+hyW6AiIhMLAW/iMg0o+AXEZlmFPwiItOMgl9EZJqJTHYDRlJXV+eWLFky2c0QEZlSNmzY0OScmzXc730d/EuWLGH9+vWT3QwRkSnFzF4f6fcq9YiITDMKfhGRacaXwW9ml5jZ7a2trZPdFBGRwPFljd859zDwcH19/bWT3RYRmVp6e3tpaGggkUhMdlPGXTweZ+HChUSj0WN6nS+DX0RkrBoaGqisrGTJkiWY2WQ3Z9w452hubqahoYGlS5ce02t9WeoRERmrRCJBbW1toEMfwMyora0d0zcbBb+IBE7QQ7/PWPvpy+AvdHL315sauePJ14rcKhGRYPBl8DvnHnbOra6urh7T6x/fsp8fPr2ruI0SERmllpYWbrvttmN+3YUXXkhLS8s4tGggXwZ/oQzI6AYzIjJJhgv+dDo94useeeQRampqxqtZ/QK5qscMlPsiMlluuOEGXn31VU499VSi0SgVFRXMmzePjRs3snnzZi6//HJ2795NIpHguuuuY/Xq1cCRy9R0dHSwcuVK3vnOd/L000+zYMECfvGLX1BaWlqU9gUy+ENmOJT8ItPdVx9+mc1724r6nivmV/F3l7x1xOfcfPPNbNq0iY0bN7J27VouuugiNm3a1L/s8q677mLmzJl0d3fz9re/nQ996EPU1tYOeI/t27dz7733cscdd3DFFVfw4IMPsmrVqqL0IZDBbwYZ5b6I+MSZZ545YK39Lbfcws9//nMAdu/ezfbt2wcF/9KlSzn11FMBOOOMM9i1a1fR2uPL4DezS4BLli1bNtZ3UKlHRI46Mp8o5eXl/dtr167l8ccfZ926dZSVlXHuuecOuRY/Fov1b4fDYbq7u4vWHl9O7ha6qidkgEo9IjJJKisraW9vH/J3ra2tzJgxg7KyMl555RWeeeaZCW6dT0f8hVKpR0QmU21tLeeccw4nnXQSpaWlzJkzp/93F1xwAd/73vc45ZRTWL58OWedddaEty+YwY/hVOsRkUl0zz33DLk/Fovx6KOPDvm7vjp+XV0dmzZt6t9//fXXF7Vtviz1FCpkKvSIiAwnkMFvZmRU6xERGVIggx804hcRGU4ggz9kqvWIiAwnkMHvrepR8ouIDMWXwV/oZZkNDfhFRIbjy+Av+ASukM7cFZHJM9bLMgN861vfoqurq8gtGsiXwV8oXZZZRCaT34M/kCdwobldEZlEuZdlPu+885g9ezb3338/yWSSD3zgA3z1q1+ls7OTK664goaGBtLpNF/60pfYv38/e/fu5d3vfjd1dXU88cQT49K+QAa/VvWICACP3gCNfyzue849GVbePOJTci/LvGbNGh544AGeffZZnHNceumlPPnkkxw8eJD58+fzq1/9CvCu4VNdXc03v/lNnnjiCerq6orb7hwq9YiIjKM1a9awZs0aTjvtNE4//XReeeUVtm/fzsknn8zjjz/OF77wBZ566inGOqc5FoEc8WvALyLAUUfmE8E5x4033sgnP/nJQb/bsGEDjzzyCDfeeCPvf//7+fKXvzwhbQrkiD9kukibiEye3Msyn3/++dx11110dHQAsGfPHg4cOMDevXspKytj1apVXH/99Tz//PODXjtegjniR5dlFpHJk3tZ5pUrV3LVVVdx9tlnA1BRUcFPfvITduzYwec+9zlCoRDRaJTvfve7AKxevZqVK1cyb968cZvcNT+PjOvr69369euP+XXffGwbt/x2OztvuhAzG4eWiYhfbdmyhRNPPHGymzFhhuqvmW1wztUP95qAlnq8P318TBMRmTSBDH7DS37lvojIYBMa/GZ2uZndYWa/MLP3j9fnHBnxK/pFpqPp8m9/rP0cdfCb2V1mdsDMNuXtv8DMtprZDjO74SiN/E/n3LXAx4H/MaYWj6qt3p+a4BWZfuLxOM3NzYEPf+cczc3NxOPxY37tsazq+SHwHeDuvh1mFgZuBc4DGoDnzOwhIAzclPf6q51zB7Lb/zf7unHRN6HrVOwRmXYWLlxIQ0MDBw8enOymjLt4PM7ChQuP+XWjDn7n3JNmtiRv95nADufcawBmdh9wmXPuJuDi/PcwL5FvBh51zj0/1OeY2WpgNcDixYtH27y89+hr85heLiJTWDQaZenSpZPdDF8rtMa/ANid87ghu284fw28D/iwmX1qqCc45253ztU75+pnzZo1pkb1T+4q+EVEBin0BK6hFskPG7fOuVuAW476pmaXAJcsW7ZsbI3qG/Gr1CMiMkihI/4GYFHO44XA3gLfs/AbsajUIyIyrEKD/zngBDNbamYlwJXAQ4U3qzB9pR5doVNEZLBjWc55L7AOWG5mDWZ2jXMuBXwG+A2wBbjfOfdyoY0q+J67/aUeERHJdyyrej4yzP5HgEeK1iLvPR8GHq6vr792LK/vX86p5BcRGSSgl2zwBP0EDhGRsfBl8Bet1KPcFxEZxJfBX/iqHl2kTURkOL4M/kIduVaPol9EJJ8vg7/QUk9F916W2xsq9YiIDMGXwV9oqedtO77L90u+oTN3RUSG4MvgL5iFCJHRiF9EZAiBDH5nYUI4Bb+IyBB8GfyF1vgxI0xGpR4RkSH4MvgLrfFjYQynO3CJiAzBl8FfKGchb8SvWo+IyCCBDH5N7oqIDC/Awa/JXRGRofgy+Aud3HWhMCEypJX8IiKD+DL4C53ctWyNP63ZXRGRQXwZ/IWykLeqR8EvIjJYYIM/TIZUJjPZTRER8Z3ABn9II34RkSEFNPhDhMyRSmvELyKSL6DBHwYgnU5PcktERPzHl8Ff8K0XQ1630qlUMZslIhIIvgz+gm+9GIoAkNbkrojIIL4M/kL1j/jTvZPcEhER/wlk8IeyNf6MavwiIoMEMvg1uSsiMrxABn8onB3xZxT8IiL5ghn8/TV+Bb+ISL5ABr9lV/Vk0lrOKSKSz5fBX+g6fo34RUSG58vgL3gdf7hvxK/gFxHJ58vgL1TfiF+TuyIigwU0+LWOX0RkOMEM/r5ST0aTuyIi+YIZ/JESAJwu2SAiMkhAgz8KgNNyThGRQYIZ/NlSj0sdw4j/pf+AH106Ti0SEfGPyGQ3YDyEwtlST+YYgv9nnxin1oiI+EswR/zZUg8q9YiIDBLI4Cd7yQZN7oqIDBbM4A9nR/x5pR7nHI9t3k864yahUSIi/jBhwW9mJ5rZ98zsATP79Lh+WGjo4P/Ny/u59u71/NuTr47rx4uI+Nmogt/M7jKzA2a2KW//BWa21cx2mNkNI72Hc26Lc+5TwBVA/dibPArZM3fJO3P3UGcPAG80d43rx4uI+NloR/w/BC7I3WFmYeBWYCWwAviIma0ws5PN7Jd5P7Ozr7kU+B3w26L1YCjDlHoiYQOgN61Sj4hMX6MKfufck8ChvN1nAjucc68553qA+4DLnHN/dM5dnPdzIPs+Dznn/gT4aDE7MUho6FU9pel2fhr9ByqSjeP68SIiflbIOv4FwO6cxw3AO4Z7spmdC3wQiAGPjPC81cBqgMWLF4+tZdkTuMi7Vs9xe3/FKeGXSTX9FDh/6Nc6B2Zj+1wRkSmgkOAfKh2HraE459YCa4/2ps6524HbAerr68dWkwn1Bf/AUk84G+jOjfC2Cn4RCbhCVvU0AItyHi8E9hbWHE+hd+DqK/VYXvCHRhP8wx+7REQCoZDgfw44wcyWmlkJcCXwUDEaVegduPomd/PvuRsOecE/4jL+EQ8KIiJT32iXc94LrAOWm1mDmV3jnEsBnwF+A2wB7nfOvTx+TT0GfTdiSeWP+L0/Rz5/S8EvIsE2qhq/c+4jw+x/hBEmasfKzC4BLlm2bNnY3mCYE7hstDV+EZEA8+UlG4pV6sm/LHNf4GdU4xeRacyXwV+wvou05S3n7It01fhFZDrzZfAXvqonTAYb4iJt2fcf8cUKfhEJNl8Gf8GlHiBjERjLZZldZsyfKSIyFfgy+IshY2HIpPsvzAbgsqP5kRf1aMQvIsHmy+AvuNSDN+LPpHo4/WuP8ceG7PuMKtMV/CISbL4M/mKVeiJ4l2V+pbHN2zeaTNeIX0QCzpfBXwwuFCGcDf5jy3IFv4gEW3CD3yJE+4I/G+ZHpm11ApeITF++DP5i1PhdKELEBo74bVShruAXkWDzZfAXpcYfjhHDW87ZF+Wjm9tV8ItIsPky+IshEy2jjCRwJMud03X2RUQCG/wuUkaZJbzt/hr/0UfzvXk3aBcRCZrABj8lZcyknVXhx3CZ0Z+N250cw9m+IiJTiC+DvxiTu1ZSwbLQXv4++gPmNq0Dcsr3Iwz8u3tSw/9SRCQAfBn8xZjcDcXK+reTFh/167oU/CIScL4M/mIIxSr6t3vdaO616+lSqUdEAi6wwR+Jl/dvp1PeKH40CzXTxzAfICIyFQU4+I+M+NPZm64fGfAPfwhIp7WOX0SCbVoEfyY9+hF/RiN+EQk4XwZ/cVb1HCn1ZPruvev6rsc//IlcTjdiEZGA82XwF2NVD9GcGv+gEX/e2L+zqX9z5Buxi4hMfb4M/qLIWdXjBtX48zz+lf5NlXpEJOgCHPyV/ZtHavx9yZ9X6sk5IhzLWb4iIlPR9Aj+TN91+bMGDf2PPM6oxi8iATctgv/qvV/xNkZRvs+M6v6MIiJTV4CDv2rQrmHP3M0t9WhyV0QCLsDBXzl437ChnlPqUY1fRAIuuMEfiQ3eN4r6vYJfRILOl8FfjBO48qUzjtzbrQ9HpR4RCTpfBn9RTuDK05PK5Jy5O1Bja3f/tlb1iEjQ+TL4i+YtF/dvJlPpYUs9ew539W9rHb+IBF2wg/+Dd/RveiP+UdT4VeoRkYALdvCXlPHaog/R6GaQzCn1hEaq9avUIyIBF+zgByxSQgm9JFPp/jN4zfKvznlklJ/WCVwiEnDBD/5wCVHSJFMZMmnv8sz5uW86gUtEppHAB3+oJEYJKbp60qzfmb38cl645z7S5K6IBF3ggz8eKyVmvew51EU4W9u3vDq+6SJtIjKNRCa7AeOttDQOwNa9h6kiW+N33mWa97R0c7A9yYBbtCj3RSTgAh/8ZaVlAPz3lj1clh3xh5x3ADjn5v8C4GezjzxfI34RCbrAl3rCUe+aPXuaW4n0lXqyq3v65M71qsYvIkE3ocFvZuVmtsHMLj76s4skHAWghFT/+v1QttTTZ8Dkrkb8IhJwowp+M7vLzA6Y2aa8/ReY2VYz22FmN4zirb4A3D+Who5Z2Bvxl9BLpL/GP3DEPyO5r39byzlFJOhGW+P/IfAd4O6+HWYWBm4FzgMagOfM7CEgDNyU9/qrgVOAzUC8sCaPzfXR+3HZok4oL/iXJrf0b+sOXCISdKMKfufck2a2JG/3mcAO59xrAGZ2H3CZc+4mYFApx8zeDZQDK4BuM3vEDVFXMbPVwGqAxYsXj74nw0m0APCB8O+PfMYIl2xQqUdEgq6QVT0LgN05jxuAdwz3ZOfcFwHM7ONA01Chn33e7cDtAPX19YUPv7tbBu3qG/EPdQDQ5K6IBF0hwZ9/wRsYxe3MnXM/LOAzj92Sc+CpbwzYFSZNJuN4sOQrg5+fN/ErIhI0hazqaQAW5TxeCOwtrDmeot6B603vgSV/OmBXmDS9mQynh3ZwemjHwM/OKPhFJNgKCf7ngBPMbKmZlQBXAg8Vo1FFvwNX3rr9CBnv+vxDSSv4RSTYRruc815gHbDczBrM7BrnXAr4DPAbYAtwv3Pu5WI0quj33E0lBjwMk6Y9MXTAm+stzmeKiPjUaFf1fGSY/Y8AjxS1Rd77Pgw8XF9ff21R3rBi9oCHJaTY19LF/KGem/ftQEQkaAJ/yQYAVn4dPnhn/8NyEjQ0tw/5VNX4RSTofBn8RS/1zFgCp/w5vPkCAMqtm+17m4b+bAW/iAScL4O/6JO7fa76d9Jn/w3lJLn399uGfIpq/CISdIG/LHO+cLyKsPVSbomhn6Aav4gEnC9H/EUv9eSKVQJQx9DvHVKpR0QCzpfBP26lHoCKWQAstIND/lo1fhEJOl8G/7iqnAfALSW3Dvlr0yUbRCTgpl/wz1g64q/zr9UvIhI0vgz+ca3xV80bvO9N7+nfVI1fRILOl8E/rjV+gP+9deDjZEf/pko9IhJ0vgz+cVc5d+DjkrL+zfz78YqIBM30DH7ovxcvZ66GD94Bf7MRANM6fhEJuGl3Ale/1Wth3a1w/k0Q9v4aEsQ04heRwPPliH9cJ3f7zFkBl9/aH/oAaQsr+EUk8HwZ/OM+uTuMNBEFv4gEni+Df7KkCWsdv4gEnoI/R9rChDXiF5GAU/DnyFhY1+oRkcBT8OfIWIRMSsEvIsGm4M8VipBJ90x2K0RExpUvg39ClnMO9bnhKOl0inTGTejniohMJF8G/2Qt54zHYoQyKW57YseEfq6IyETyZfBPlqryUuZXRfiXx7bxwIaGyW6OiMi4UPDnsFgFyyt7eOeyOq7/jxe5be0OnFPZR0SCRcGfa8EZhBpf5Ptv28qfvKmWf/r1Vj565x/oTWcmu2UiIkWj4M+14nIAYr/6a+46P8aqsxbz9KvNnPvPa9nZ1DnJjRMRKQ4Ff655p8A1jwMQv+tc/n7ZNr5yyQqaOpK8+xtr+dSPN2j0LyJTnoI/36K3w18+5G0/cDUfj63l8b/9M2rKovz65UZO+OKj/L/HtrFlX5vq/yIyJZmfw6u+vt6tX79+cj78v/8Znvh7b/vsz+BO/xg/39rNnRva2LyvDYCqeIR/ueJU3nfibADMbHLaKiKSw8w2OOfqh/29H4PfzC4BLlm2bNm127dvn7yGpHvhxx+AXU/173JfPsyP1r3OVx7e3L/PDGaUlfC1y07iolOGuJm7iMgEmpLB32dSR/x9Ukl4+LPw4j1H9p3/j1B/NRsbk3zmnudpONw94CX3f/Jszlw6c4IbKiLiUfAXS8N6uPO9A/d9dhPULCLRm2bVnX9g/euHB/z6q5e+lbctquHOp15jRlkJb51fxUWnzKMyHqWpI8nMshJCIZWHRKS4FPzF5Bw8ezs8+vkj+z69zruNI9CTyvDktoN84u7h23zu8ll8/vy3cOEtT/E/z30Tn7/gLQN+n0ylSWccZSXT93bIIlIYBf946DgI3z8PDu8cuH/Z+2DVg3QmU9y97nW+/utXMDKUk6CDskFvU0M7y+ZU87Urz+HEeVUAfOC23/PCGy3suvmiieiJiATQ0YJfyznHomIWXLcR/uyGgft3PA7/9i7Kf/t/+PTppey6+SJeOPt3bIp/gr+auYkN5Z8lTpLbot/iM+GfszH+SX7a8hes/PZTXHffC6x5uZEX3mgBvJG/iMh40Ii/UK+vgxd+ApsehFTOJG+8BlZcCs/fPeDpv5j711zW+K8D9i1J3EO+39/wHhbUlI5Lk0Uk2I424lchuVDHne39XH4rHN4Fd7wHupoh0TIo9IFBoZ/vS5Efs8JeJ9H7Z+PUYBGZ7lTqKaYZS+Bzr8Lnd8LJfz7ql339sjf3b18TeZSzw5tJ9KrUIyLjQ8FfbGZQNhM+dCd8+TCc/RnvZwQffu4j/MWSVl5698b+fYme3vFuqYhMU6rxT6RXn4AfXz6qpz7z4fWcddIJ49wgEQkirerxk+PPhfmnjeqpqe72cW2KiExfEza5a2bnAl8DXgbuc86tnajP9g0zWL0Wkh2wZz28thZKZ8BjXx701GRC1/8XkfExquA3s7uAi4EDzrmTcvZfAHwbCAN3OuduHuFtHNABxIHpfUPbWIU3+j/+XEinvIvB/dfXAEhc+G3ij1zHxtf2Qd1+KmIRMg6iYaMyHmVOVYzdh7o5YU4F6YyjPKaFWSJybEZV4zezd+GF9t19wW9mYWAbcB5ekD8HfATvIHBT3ltcDTQ55zJmNgf4pnPuo0f73MDV+EeSSnqXhHj9d/CTD/HB5Fd43r35qC+bXx2nqjRKbUUJ4VCIZG+at86vZumsckrCxpyqOLFImGjYOK62nNpy7/pAzjldRlokoIqyjt8596SZLcnbfSawwzn3WvaD7gMuc87dhPftYDiHgdgIDV4NrAZYvHjxaJoXDJHsX0kkDsAtHz6Rptln0drdy+HOHsygtbuXtu5eXmlsJ9GbIWRQEYvQ0NJNc0cPyVSGQ509vNTQSvcIy0FLwiF60hni0RAnL6hm8cxy5lXHSfSmedPsCspKwhxXW87MshKqy6JUl0Yn4m9ARCZIIXWCBcDunMcNwDuGe7KZfRA4H6gBvjPc85xztwO3gzfiL6B9U1PEO1t3YaWxcFHNmN4ik3Hsb0+QSjv2tyVo6kiSTGXY2dTJvpYErd29lERCbG1sZ29LguffaCGdGf6vujIWoSIeoTwWoSIWoSQcYsX8KqpKo+AcK+ZXs6CmlKrSCKmMY9GMMkoiWjcg4leFBP9QdYJh08M59zPgZ6N64yM3Yhlj06awqDfiZ+1N0NMJyTZI9cDckyDR5t0XOF7tfTMIhaE3AeESCB0J2lDImFftHUAWzRx8cbihdPekaTjcRThkHO7qYVdTF509KZo7emg43M3hrh72tyV441AXhzp7eHbXoWHfKxIy5lbHqSmLEgmFqIxHqC0vwcxYPreSGWVRYpEwFbEIdZUxltSWEY+GKQmHdJlqkQlQSPA3AItyHi8E9hbWHI9z7mHg4fr6+muL8X5TSrl3G0f2vgAP/NXYXh+JQetuwOB9X/GuGTRjqff7vrp+JjPgYFFaEuaEOZX9j884buQbyTjn2NeaIJ1xbN7Xxp7D3VTEI2xtbKc90cuhzl5aunrIOMdT25tG1fTKWCQ7NxHCDMIho7YiRnVplDfPriASDtHVk+K0xTM4YXYFNWUlmqsQGYNRn8CVrfH/MmdyN4I3ufteYA/e5O5VzrmXi9W4aTW5m6vrELz+e+hs8kbzmV5v4hfg0GvQ3ggv/wxC0YEXhhuruuXQtNX7FnHWp8HCcOIl0PgSLL/IOxO5qxm2/QZOverIwWOUelIZEqk0rV29VMYjdPWk6epJs6upk8372jCgJ51hV3MXe1u6aenqoSOZYn9bktJoeNj5ipBBxtH/jSIcMhbMKGNBTZzetCOdcZy+uIbqshJS6QxvmlVBRTzC/OpS2hO9zK6KF/53J+JDRbkev5ndC5wL1AH7gb9zzn3fzC4EvoW3kucu59w/FKnR/rjn7lSUaPPuE9DV7G1vfww2/gRO/SjsfApa34BwDNLJsb1/JO7ddyBa6p2MtqAeKudAxRzvQGUGmZR33aIC9Y3m32j2yk7JVIZdTZ1096bZfaiLkBntiV72tyVp7e5lf3uC9kSKTMbR3Nlz9K6EjFTGMa86ztK6cuoqYjhgblWM8lgE5+CUhdV0JFMsnFFGMpXmLXOrKI+FcQ6VpsS3dCMWGV4qCZ0HYc8G2PAjiFXCnLdC2x5vfqHhOe+Ko2NVvRhOvBh2/c57z7d/AmqXgYVgx2+9bxexCq8M1fctwrlj/kYxlN50hpAZrzS20dTRw5yqGE/vaCbjHG2JFDubOimLhtl2oJ2ORIqedIaORGpUBwzwvm3MqowxtypOJBxidmWM2ZUxqkqjtHT1smBGKXUVMeZXxwmHjHDIOw9jSV0ZYTMiYU1+y/hR8EvhUj0QjkJPB2xf491rIBKHbY9C+37vEtRvPONNRM85Gfb/MefFxghz/p7SmdB9COaeDI3Z15ZUQk87LHoHLDsPZhwH+zdB/TXwxjo4/t3e5DbmtS1eVZSudiZTdCZThEJGZzLFwfYkm/e1UVYS4bHNjSypK6czmaKrJ01LVy9bG9vpSWeIhox9bQlG888pGjZCZpSWhJlfXcrimWXEoyHMjPk1cXYf6ubNc7w5jOrSKCctqKasxJsMj0VCOmjIUU3J4FepJwDSvV4gZ9JwaKf3baLxJW/SuXUP7P4DzHqLd+mKcMmRxwdfKexzT10Fm3/hHTTmngLnXOd9oyitgWiZd4mMRKv3TWfuSdBxwJvTKK8tuMuZjCOZymAGu5o7SfRm2N+WYF9LNzPKS9jZ1MmrBzvp7kkTDRuNbQn2tnRzuLOXVCbDCCtqB6iIRehIpqiriPGet8yiqydNd0+aZdkJ71Q6wzM7m7nqzOOYXxPvnyOpKS3h+FnlxCIhTYgH3JQM/j4a8U9TLW9A9SKvFNW2x/uW0dsN+170DgzpHm+Su1ClM6D78JHHFXNh9lugaoE3wT5ruXdZjZrFXps6DsCy93oHs7YGmHca4LzHoewCudCxj8b7/g1mHBzq7OHVgx2kM47FM8s43NXDiw2ttHX30tWTypalHJ3JFPvbErx6sINkr3ew6exJj3g+Rq66ihJikTB1lTEqYmF6046wGRveOMxVZy6mPZFi8cwyTl5YRUUsyr7WbkJmnHV8LeWxMIYRi2iOw68U/DJ9HN51ZETf2uB969j/MjQ865Wiqhd5wb5tDXQ0FuczK+dB+z5vu6wOlpwDmFe26u32SmLzT/XmLvZt9A4kC87IlqmKK5NxtCdSpJ2jpauHP+5pJZnKsL81QSY7dbLh9cPMrozR2JagIhZh9+Eumtp7aGxLjOkzF9SU0t2bpjQaZuGMUmqyZ3qnM3D6cTWk0o651XE6kylqK2K8bWE1FbEI4ewBQ988xseUDH6VemRCOOfNS0TLvANFtAwiJdD8mjd/cfAVb87h8K4jK6H65iOKacYSmHMSuAw07/BWSO15Hk5bBWeu9pbaVsz1vnmkEtC0DarmQ+0J3gGkCOHZt4LKZSe/Gw53sbclQSRspNKOpo4kja0JdjV34pw3a7Nx92GOr6tgZ1MnbYleDDjcdfQbCOUu0a2MR6gujRIy4+LO5NAAAAe+SURBVNRFNXz7ylN1MCiCKRn8fTTiF99yzvtGkUp48wXlddlVUK975z3se9E7mMQq4eBWbx6jvREObvECu3mcBjT113hzK5EYLHkX7H7G+9ax5E+9AwdAWa33nJY3oGK2tzS3r08uM+ZvI8452rpTVJVGONCepKsnzUsNLWScozIW5aWGFpLpDJ3JVP9Kqhd3tzKvOs76172S2znLaqkpLcEMQtb3rcBbImBmpDMOB5RGQ4RD3iS59+OdsZ6/Hc4+NrPs8wdu972+7zP85IKT5jG3emznmij4Rfwo0erNCzRt81Ywlc30vmH0dHkHk1AEqhfA6+u8CfCX/h0Wn+0ts+3t9uY4XJHvy5z7bWbWibDiMu8gsfsP3gmFAJff5i3HfX2dN4n+5z+A2SfCwW3efMnid3irwCIlx/TR7Yle/ubeF9jT0k3GeWWrTDabHNljEq4/qLt70qSdwzlHxkE6+3zvdXjb7si2j2NuWP+++izecfzYFh0o+EWCLJP2JqKjce8bR81xkGyHnf/tla7K66BhvXewqF7ozUdsf8w7yW88nfB+mPc276TB3c/A7LfC26/2lud2NsG6W73zOGqXeW2btbwoJavh5B8gnIN09uDgMvQfZPykIh4hOsalu1My+FXjFxlnff/uzbztQ6/BzOO9A8nhXd7cx+wT4bk7AYPOA948x4HN3iqrkz7sbTf+0fu20nmw8DYtqIdPPO6Vm8ArpYUi3pngfRcizD3Bzznvp28lVZFO/guCKRn8fTTiF5kCMhnvEiHxai94QxHvANK0zZuY7jrkzRuke72luF3N8PS/ettDyj3pL7tt4ez8Q8R7r0zK+4nEvTmKaLn3vrGKI3MWU92HfwgLzxjTS4tyIxYRkWGFQlAxa+C+cATmrPB+hvLevPtMp5Kw/gfeNwvsyHkROG9OId3jBb1z3r5wiXcw6On0Vlv1dHkXLCyp8A4wQRj5xyqP/pwxUvCLyOSLxOCsT012K6YNXfRDRGSa8WXwm9klZnZ7a2vrZDdFRCRwfBn8zrmHnXOrq6urJ7spIiKB48vgFxGR8aPgFxGZZhT8IiLTjIJfRGSa8WXwa1WPiMj48fUlG8zsIPD6GF9eBzQVsTmTKUh9gWD1R33xryD151j7cpxzbtZwv/R18BfCzNaPdK2KqSRIfYFg9Ud98a8g9afYffFlqUdERMaPgl9EZJoJcvDfPtkNKKIg9QWC1R/1xb+C1J+i9iWwNX4RERlakEf8IiIyBAW/iMg0E8jgN7MLzGyrme0wsxsmuz1HY2aLzOwJM9tiZi+b2XXZ/TPN7DEz2579c0bOa27M9m+rmZ0/ea0fmpmFzewFM/tl9vGU7IuZ1ZjZA2b2Sva/z9lTuC//K/v/1yYzu9fM4lOpL2Z2l5kdMLNNOfuOuf1mdoaZ/TH7u1vMJv52XcP05Z+z/5+9ZGY/N7OaceuLcy5QP0AYeBU4HigBXgRWTHa7jtLmecDp2e1KYBuwAvgn4Ibs/huAr2e3V2T7FQOWZvsbnux+5PXpb4F7gF9mH0/JvgA/Aj6R3S4BaqZiX4AFwE6gNPv4fuDjU6kvwLuA04FNOfuOuf3As8DZeDf0fRRY6ZO+vB+IZLe/Pp59CeKI/0xgh3PuNedcD3AfcNkkt2lEzrl9zrnns9vtwBa8f6iX4QUP2T8vz25fBtznnEs653YCO/D67QtmthC4CLgzZ/eU64uZVeH9A/0+gHOuxznXwhTsS1YEKDWzCFAG7GUK9cU59yRwKG/3MbXfzOYBVc65dc5LzrtzXjNhhuqLc26Ncy6VffgMsDC7XfS+BDH4FwC7cx43ZPdNCWa2BDgN+AMwxzm3D7yDAzA7+zS/9/FbwOeBTM6+qdiX44GDwA+yZas7zaycKdgX59we4BvAG8A+oNU5t4Yp2Jc8x9r+Bdnt/P1+czXeCB7GoS9BDP6halxTYs2qmVUADwKfdc61jfTUIfb5oo9mdjFwwDm3YbQvGWKfL/qCN0I+Hfiuc+40oBOvnDAc3/YlW/u+DK9UMB8oN7NVI71kiH2+6MsoDdd+3/fLzL4IpICf9u0a4mkF9SWIwd8ALMp5vBDvK62vmVkUL/R/6pz7WXb3/uzXObJ/Hsju93MfzwEuNbNdeGW295jZT5iafWkAGpxzf8g+fgDvQDAV+/I+YKdz7qBzrhf4GfAnTM2+5DrW9jdwpISSu98XzOxjwMXAR7PlGxiHvgQx+J8DTjCzpWZWAlwJPDTJbRpRdib++8AW59w3c371EPCx7PbHgF/k7L/SzGJmthQ4AW+SZ9I55250zi10zi3B+7v/L+fcKqZmXxqB3Wa2PLvrvcBmpmBf8Eo8Z5lZWfb/t/fizSVNxb7kOqb2Z8tB7WZ2Vvbv4S9zXjOpzOwC4AvApc65rpxfFb8vEz2bPUEz5hfirYx5FfjiZLdnFO19J95XtJeAjdmfC4Fa4LfA9uyfM3Ne88Vs/7YyCasSRtmvczmyqmdK9gU4FVif/W/zn8CMKdyXrwKvAJuAH+OtEpkyfQHuxZuf6MUb7V4zlvYD9dm/g1eB75C9goEP+rIDr5bflwHfG6++6JINIiLTTBBLPSIiMgIFv4jINKPgFxGZZhT8IiLTjIJfRGSaUfCLiEwzCn4RkWnm/wMLCdyD0CD+OwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and test loss\n",
    "plt.figure()\n",
    "plt.semilogy(loss_hist['train'])\n",
    "plt.semilogy(loss_hist['test'])\n",
    "plt.legend(['train','test'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()   \n",
    "\n",
    "pickle.dump(loss_hist,open('./data/loss_hist_v2_swish_red-dim_{}.p'.format(redDim),'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
