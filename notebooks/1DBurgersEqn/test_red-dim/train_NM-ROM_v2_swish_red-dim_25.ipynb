{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.prune as prune\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "from scipy import sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import sys,time\n",
    "import os\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "redDim=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug 21 14:41:25 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.74       Driver Version: 418.74       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro M6000        On   | 00000000:02:00.0 Off |                  Off |\n",
      "| 25%   24C    P8    14W / 250W |      1MiB / 12212MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Quadro M6000        On   | 00000000:03:00.0 Off |                  Off |\n",
      "| 25%   25C    P8    14W / 250W |      1MiB / 12212MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Quadro M6000        On   | 00000000:81:00.0 Off |                  Off |\n",
      "| 25%   28C    P0    62W / 250W |    382MiB / 12212MiB |      8%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Quadro M6000        On   | 00000000:82:00.0 Off |                  Off |\n",
      "| 25%   36C    P0   143W / 250W |   1145MiB / 12212MiB |     97%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    2     16318      C   /home/kim101/anaconda3/bin/python            372MiB |\n",
      "|    3     16293      C   /home/kim101/anaconda3/bin/python           1133MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose device that is not being used\n",
    "gpu_ids = \"1\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=gpu_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_v2(m,b,db):\n",
    "    '''\n",
    "    mask=create_mask_v2(m,b,db)  \n",
    "    '''\n",
    "    \n",
    "    M2 = b + db*(m-1)\n",
    "    mask = np.zeros((m,M2),dtype='int')\n",
    "    \n",
    "    block = np.ones(b,dtype='int')\n",
    "    ind = np.arange(b)\n",
    "    for row in range(m):\n",
    "        col = ind + row*db\n",
    "        mask[row,col] = block\n",
    "    \n",
    "    print(\n",
    "        \"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "            m, M2, (1.0-np.count_nonzero(mask)/mask.size)*100\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.spy(mask)\n",
    "    plt.show()\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silu(input):\n",
    "    return input * torch.sigmoid(input)\n",
    "class SiLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return silu(input)\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,m,M1,f):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.full = nn.Sequential(\n",
    "            nn.Linear(m,M1),\n",
    "            SiLU(),\n",
    "            nn.Linear(M1,f,bias=False)\n",
    "        )\n",
    "                \n",
    "    def forward(self, y):     \n",
    "        y = y.view(-1,m)\n",
    "        T = self.full(y)\n",
    "        T = T.squeeze()\n",
    "        \n",
    "        return T\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,f,M2,m):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.full = nn.Sequential(\n",
    "            nn.Linear(f,M2,bias=False),\n",
    "            SiLU(),\n",
    "            nn.Linear(M2,m,bias=False)\n",
    "        )\n",
    "             \n",
    "    def forward(self,T):\n",
    "        T = T.view(-1,f)\n",
    "        y = self.full(T)\n",
    "        y = y.squeeze()\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([900, 1000]) torch.Size([100, 1000])\n"
     ]
    }
   ],
   "source": [
    "# load solution snapshot\n",
    "solution_snapshot_orig = pickle.load(open(\"./data/snapshot_full.p\", \"rb\"))\n",
    "nx=1001\n",
    "nt=500\n",
    "\n",
    "# substract IC -> centered on IC\n",
    "ndata=solution_snapshot_orig.shape[0]\n",
    "nset= round(ndata/(nt+1))\n",
    "\n",
    "solution_snapshot=np.array([])\n",
    "for foo in range(nset):\n",
    "    solution_snapshot=np.append(solution_snapshot,solution_snapshot_orig[foo*(nt+1)+1:(foo+1)*(nt+1)]\\\n",
    "    -solution_snapshot_orig[foo*(nt+1)])\n",
    "\n",
    "solution_snapshot=np.reshape(solution_snapshot,(-1,nx))\n",
    "\n",
    "# solution_snapshot_tmp1 = solution_snapshot[:501]-solution_snapshot[0]\n",
    "# solution_snapshot_tmp2 = solution_snapshot[501:]-solution_snapshot[501]\n",
    "# solution_snapshot = np.vstack((solution_snapshot_tmp1[1:],solution_snapshot_tmp2[1:]))\n",
    "\n",
    "# remove BC\n",
    "solution_snapshot = solution_snapshot[:,:-1].astype('float32')\n",
    "\n",
    "# define testset and trainset indices\n",
    "test_ind = np.random.permutation(np.arange(solution_snapshot.shape[0]))[:int(0.1*solution_snapshot.shape[0])]\n",
    "train_ind = np.setdiff1d(np.arange(solution_snapshot.shape[0]),test_ind)\n",
    "\n",
    "# set trainset and testset\n",
    "trainset = solution_snapshot[train_ind]\n",
    "testset = solution_snapshot[test_ind] \n",
    "\n",
    "# set dataset\n",
    "dataset = {'train':data_utils.TensorDataset(torch.tensor(trainset)),\n",
    "           'test':data_utils.TensorDataset(torch.tensor(testset))}\n",
    "print(dataset['train'].tensors[0].shape, dataset['test'].tensors[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 1000) (100, 1000)\n"
     ]
    }
   ],
   "source": [
    "# compute dataset shapes\n",
    "dataset_shapes = {'train':trainset.shape,\n",
    "                 'test':testset.shape}\n",
    "\n",
    "print(dataset_shapes['train'],dataset_shapes['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # when inputs and targets are different e.g. Kernel PCA + Decoder\n",
    "# mapped_solution_snapshot = loadmat('./data/mapped_solution_snaphost.mat')['mapped_solution_snapshot']\n",
    "\n",
    "# mapped_trainset = mapped_solution_snapshot[train_ind]\n",
    "# mapped_testset = mapped_solution_snapshot[test_ind]\n",
    "\n",
    "# inputs = {'train':mapped_trainset,'test':mapped_testset}\n",
    "# outputs = {'train':trainset,'test':testset}\n",
    "\n",
    "# dataset = {'train':data_utils.TensorDataset(inputs['train'], targets['train']),\n",
    "#            'test':data_utils.TensorDataset(inputs['test'], targets['test'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set batch_size, number of epochs, paitience for early stop\n",
    "batch_size = 20\n",
    "num_epochs = 10000//5\n",
    "num_epochs_print = num_epochs*5//100\n",
    "early_stop_patience = num_epochs*5//50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data loaders\n",
    "train_loader = DataLoader(dataset=dataset['train'], \n",
    "                          batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(dataset=dataset['test'], \n",
    "                         batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "data_loaders = {'train':train_loader, 'test':test_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # copy trainset to cpu (if inputs~=targets, replace 0 to 1 for targets)\n",
    "# trainset_inputs = data_loaders['train'].dataset.tensors[0].to('cpu')\n",
    "# trainset_targets = data_loaders['train'].dataset.tensors[0].to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set checkpoint\n",
    "PATH = './checkpoint_v2_red-dim_{}.tar'.format(redDim)\n",
    "\n",
    "# set file name for AE\n",
    "file_name_AE_pkl=\"./model/AE_v2_swish_red-dim_{}.pkl\".format(redDim)\n",
    "file_name_AE=\"./model/AE_v2_swish_red-dim_{}.p\".format(redDim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the number of nodes in each layer\n",
    "m = 1000\n",
    "f = redDim\n",
    "b = 36\n",
    "db = 12\n",
    "M2 = b + (m-1)*db\n",
    "M1 = 2*m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in 1000 by 12024 mask: 99.70%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAA+CAYAAAAvbrxJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAJa0lEQVR4nO3db4wdVR3G8e9jV4oUkRYqWQpJW9MQm0aFbrSAICkoUAjViKaNhRIhvBDj30Tb8EZfEdQYJRqwqZAGkL9WaIgKpghoYopbwFooK+WPpVjoJSpUSKTgzxfnLL132e7OtvfemTv7fJJm5547c3ue7HZ/nTlnzigiMDMzG/ausjtgZmbV4sJgZmYtXBjMzKyFC4OZmbVwYTAzsxYuDGZm1qL0wiDpHElDkrZLWlV2f4qQdLyk30vaJulxSV/N7TMk/U7SU/nr9KZjVueMQ5LObmpfKOmv+b1rJKmMTCNJmiLpUUn35Nd1ynakpDslPZm/hyfXLN/X88/lVkm3SDq0l/NJul7Sbklbm9ralkfSVEm35fZNkmZXIN/388/nFkm/knRkV/NFRGl/gCnA08Bc4BDgL8D8MvtUsN/9wEl5+73A34D5wPeAVbl9FXB13p6fs00F5uTMU/J7DwMnAwJ+A5xbdr7cr28AvwDuya/rlG0dcFnePgQ4si75gFnAs8B78uvbgUt6OR9wOnASsLWprW15gC8B1+XtZcBtFcj3KaAvb1/d7Xxl/xCfDNzb9Ho1sLrMPh1gjruBTwJDQH9u6weGRssF3Juz9wNPNrUvB35WgTzHARuBxewrDHXJdgTpF6dGtNcl3yzgeWAG0Afck3/J9HQ+YPaIX5xtyzO8T97uA14e+fPR7Xwj3vsMcHM385V9KWn4h3jYztzWM/Jp2YnAJuCYiNgFkL++P++2v5yz8vbI9rL9CPgW8L+mtrpkmws0gBvypbK1kqZRk3wR8QLwA2AHsAt4JSLuoyb5mrQzz9vHRMSbwCvAUR3r+cR9kXQGAF3KV3ZhGO2aZc+s0SHpcOCXwNci4tWxdh2lLcZoL42k84HdEbG56CGjtFUyW9ZHOm2/NiJOBF4jXYrYn57Kl6+1LyVdZjgWmCZpxViHjNJW2XwFHEieymaVdCXwJnDzcNMou7U9X9mFYSdwfNPr44B/lNSXCZH0blJRuDki1ufmlyT15/f7gd25fX85d+btke1lOhW4QNJzwK3AYkk3UY9skPq1MyI25dd3kgpFXfKdBTwbEY2I2AusB06hPvmGtTPP28dI6gPeB/yzYz0vSNJK4HzgC5GvA9GlfGUXhj8D8yTNkXQIaWBkQ8l9Glce7f85sC0iftj01gZgZd5eSRp7GG5flmcHzAHmAQ/nU+A9khblz7y46ZhSRMTqiDguImaTvh/3R8QKapANICJeBJ6XdEJuOhN4gprkI11CWiTpsNyvM4Ft1CffsHbmaf6sC0k/82WfuZ8DfBu4ICJeb3qrO/nKGkxqGiRZQprV8zRwZdn9Kdjnj5NOxbYAj+U/S0jX7TYCT+WvM5qOuTJnHKJpdgcwAGzN7/2ELg96jZPzDPYNPtcmG/ARYDB//+4Cptcs33eBJ3PfbiTNYOnZfMAtpPGSvaT//V7azjzAocAdwHbSzJ65Fci3nTQuMPz75bpu5hs+0MzMDCj/UpKZmVWMC4OZmbVwYTAzsxYuDGZm1qJjhUETWBxP0uWd6kcVOF/vqnM2cL5e1slsHSkMkqYAPwXOJS36tFzS/DEOqe03L3O+3lXnbOB8vay3CgPwUWB7RDwTEW+Q7qBd2qG/y8zM2qgj9zFIuhA4JyIuy68vAj4WEV9u2udycsWbOnXqwgULFrzjczZv3szChQvb3r9uazQazJw5s+xudEyd89U5GzhfL2s0GuzYsePliGh7wL52f2A27qJNEbEGWAMwMDAQg4ODB/+XSviGPTObLCT9vROf26lLSaUsjjfRoqBqPHDLzKxSxi0MOoDHWJIe8LJY0jOSzqOii+O5kJiZvVORM4Y3gW9GxAeBRcAVeYbRKmBjRMwjLWK1CiC/93ngs/n4u4A7IuLxdne+2yZSSFxEzKxXjVsYImJXRDySt/eQlvCdRZpltC7vtg74dN5eCtwaERsiYi5wP6lwTCoHMtbhYmJmVTChMYaDfIzlyM+6XNKgpMFGozHxnteQL22ZWRUULgxteIxla0PEmogYiIiBuk4n6zRf2jKzTihUGJoeY3kM6cHUAA1JD+bB5weBl3P7TmBFXgpjCPgw1Xok4KTksxEzK6rIrKThx1geCjzU9Na/gNfz4PPr7HuG6FbgE6RLTpeRCsPB36RgXeVCYjZ5FbnB7VTgIuA/pLGCmZKWkB6H+F9JTwEvAjPy/gtIBeQx0oymLaRHzv2pvV23KjmQQuKbEc2qqcispD+SLiOdQToD+ENE/BqYGRGnRcS8iDgNODofMgu4MSI+EBEnkArEOwafbXLzGYlZdRW5lHQ+sDsiNhf8zEKDz56VZBPhQmLWPUUGn08FLpD0HGmV1MWSbgJektQPkL/uzvsXWg7Ds5Ksk1xIzA5ckUtJq0njBoPAG8BbpGct3Ac8lMcYHgJ+mw/ZAHwlz0p6BvgQ8HAH+m7WNi4kZvsUvY/hx6Rf/BeTisA20uWh4X8dzf9KYkSbRxitdlxIrM7GnZUk6QjgdOCSSP8aHsjtZwOnRcSufCnpgXzIUuCaiLgq73cv6cE9npVkk5ZnbVkvKXLGMBdoADdIelTSWknT8JIYZh3jMxIrU5HC0AecBFwbEScCr5FXUt0PL4lh1mUuJNZORW5w2wm8ClwvKUg3s+0lL4kBHEuadTRySYzvkAaq9wBr29xvMzsIvrRlYylyxjAFOAxYHhELgH7SGYCXxDCbJHxGMrkUnZX0b2CdpC3AUaQzgOnA4Xm66uGMviTGWvYtiWFmk4RX/u1tRe5jeAG4CphHOlvYGBHr8ZIYZtYGPhupniJLYkwnTUGdQxpPmCZpxViHjNLmJTHMrC38dMTOK3Ip6Szg2YhoRMReYD1wCl4Sw8x6hM9KJqZIYdgBLJJ0WH42w5mkO583ACvzPiuBu/P2BmCZpKmS5pAuQXlJDDPrGZN9jGTc6aoRsUnSncAjpOcrPAqsIQ043y7pUlLx+Fze/3FJtwNP5P2viIi3OtR/M7NS1XHqr6rQwYGBgRgc9IxWM7ORxiokkjZHRNtnfVaiMEjaAwyV3Y8OOpp9NwDWUZ3z1TkbOF8vOxqYFhFtH6QtcudzNwx1oupVhaRB5+tNdc4GztfLcrbZnfjsoje4mZnZJOHCYGZmLapSGNaU3YEOc77eVeds4Hy9rGPZKjH4bGZm1VGVMwYzM6sIFwYzM2vhwmBmZi1cGMzMrIULg5mZtfg/q2Ps8+mTzXwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------checkpoint not restored--------\n",
      "\n",
      "Sparsity in 1000 by 12024 mask: 99.70%\n",
      "\n",
      "Start first training... m=1000, f=25, M1=2000, M2=12024, b=36, db=12\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "try:\n",
    "    checkpoint = torch.load(PATH, map_location=device)\n",
    "    \n",
    "    encoder = Encoder(m,M1,f).to(device)\n",
    "    decoder = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    mask = create_mask_v2(m,b,db)\n",
    "    prune.custom_from_mask(decoder.full[2], name='weight', mask=torch.tensor(mask).to(device))    \n",
    "    \n",
    "#     optimizer = torch.optim.LBFGS(list(encoder.parameters()) + list(decoder.parameters()), lr=1)\n",
    "#     scheduler = None     \n",
    "    optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "    decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    last_epoch = checkpoint['epoch']\n",
    "    loss_hist = checkpoint['loss_hist']\n",
    "    best_loss = checkpoint['best_loss']\n",
    "    early_stop_counter = checkpoint['early_stop_counter']\n",
    "    best_encoder_wts = checkpoint['best_encoder_wts']\n",
    "    best_decoder_wts = checkpoint['best_decoder_wts']\n",
    "    \n",
    "    print(\"\\n--------checkpoint restored--------\\n\")\n",
    "    \n",
    "    # compute sparsity in mask\n",
    "    mask = decoder.state_dict()['full.2.weight_mask']\n",
    "    print(\"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "        mask.shape[0], mask.shape[1], 100. * float(torch.sum(mask == 0))/ float(mask.nelement())))\n",
    "\n",
    "    # resume training\n",
    "    print(\"\")\n",
    "    print('Re-start {}th training... m={}, f={}, M1={}, M2={}, b={}, db={}'.format(\n",
    "        last_epoch+1, m, f, M1, M2, b, db))\n",
    "except:\n",
    "    encoder = Encoder(m,M1,f).to(device)\n",
    "    decoder = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    mask = create_mask_v2(m,b,db)\n",
    "    prune.custom_from_mask(decoder.full[2], name='weight', mask=torch.tensor(mask).to(device))\n",
    "\n",
    "#     optimizer = torch.optim.LBFGS(list(encoder.parameters()) + list(decoder.parameters()), lr=1)\n",
    "#     scheduler = None \n",
    "    optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    last_epoch = 0\n",
    "    loss_hist = {'train':[],'test':[]}\n",
    "    best_loss = float(\"inf\")\n",
    "    early_stop_counter = 1\n",
    "    best_encoder_wts = copy.deepcopy(encoder.state_dict())\n",
    "    best_decoder_wts = copy.deepcopy(decoder.state_dict())\n",
    "    \n",
    "    print(\"\\n--------checkpoint not restored--------\\n\")\n",
    "    \n",
    "    # compute sparsity in mask\n",
    "    mask = decoder.state_dict()['full.2.weight_mask']\n",
    "    print(\"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "        mask.shape[0], mask.shape[1], 100. * float(torch.sum(mask == 0))/ float(mask.nelement())))\n",
    "\n",
    "    # start training\n",
    "    print(\"\")\n",
    "    print('Start first training... m={}, f={}, M1={}, M2={}, b={}, db={}'.format(\n",
    "        m, f, M1, M2, b, db))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100/2000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 1.105635673310543e-05\n",
      "test MSELoss: 1.2544886158138979e-05\n",
      "\n",
      "Epoch 200/2000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 4.753415972421257e-06\n",
      "test MSELoss: 5.610129846900236e-06\n",
      "\n",
      "Epoch 300/2000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.3566100796601354e-06\n",
      "test MSELoss: 1.8274418835062534e-06\n",
      "\n",
      "Epoch 400/2000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 1.232086820992764e-06\n",
      "test MSELoss: 1.6665116845615558e-06\n",
      "\n",
      "Epoch 500/2000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 1.1834080068082484e-06\n",
      "test MSELoss: 1.613390895727207e-06\n",
      "\n",
      "Epoch 600/2000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 1.1453440480282653e-06\n",
      "test MSELoss: 1.564491844874283e-06\n",
      "\n",
      "Epoch 700/2000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 1.10497010660361e-06\n",
      "test MSELoss: 1.5175690805335763e-06\n",
      "\n",
      "Epoch 800/2000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 1.0719013112571298e-06\n",
      "test MSELoss: 1.4745858834430691e-06\n",
      "\n",
      "Epoch 900/2000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 1.0329833748477944e-06\n",
      "test MSELoss: 1.419993327544944e-06\n",
      "\n",
      "Epoch 1000/2000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 1.0033121510686113e-06\n",
      "test MSELoss: 1.381721392590407e-06\n",
      "\n",
      "Epoch 1100/2000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 9.725022992926016e-07\n",
      "test MSELoss: 1.345249393125414e-06\n",
      "\n",
      "Epoch 1200/2000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 9.422409612448569e-07\n",
      "test MSELoss: 1.3094688256387598e-06\n",
      "\n",
      "Epoch 1300/2000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 9.145183450224674e-07\n",
      "test MSELoss: 1.2692245945800095e-06\n",
      "\n",
      "Epoch 1400/2000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 8.882013313874874e-07\n",
      "test MSELoss: 1.2372452374620479e-06\n",
      "\n",
      "Epoch 1500/2000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 8.651896065556584e-07\n",
      "test MSELoss: 1.1985958963123267e-06\n",
      "\n",
      "Epoch 1600/2000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 8.3789881652289e-07\n",
      "test MSELoss: 1.1674303095787763e-06\n",
      "\n",
      "Epoch 1700/2000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 8.186500445440793e-07\n",
      "test MSELoss: 1.1526463708833034e-06\n",
      "\n",
      "Epoch 1800/2000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 8.18485875697661e-07\n",
      "test MSELoss: 1.1521318924678781e-06\n",
      "\n",
      "Epoch 1900/2000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 8.183347050463554e-07\n",
      "test MSELoss: 1.1520887369442789e-06\n",
      "\n",
      "Epoch 2000/2000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 8.181761434874109e-07\n",
      "test MSELoss: 1.1517817711137468e-06\n",
      "\n",
      "Epoch 2000/2000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 8.181761434874109e-07\n",
      "test MSELoss: 1.1517817711137468e-06\n",
      "\n",
      "No early stopping: 2000th training complete in 0h 11m 46s\n",
      "----------\n",
      "Best train MSELoss: 8.180563781934325e-07\n",
      "Best test MSELoss: 1.1516323752402968e-06\n",
      "\n",
      "Saving after 2000th training to ./model/AE_v2_swish_red-dim_25.pkl\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "since = time.time()\n",
    "\n",
    "for epoch in range(last_epoch+1,num_epochs+1):   \n",
    "\n",
    "    if epoch%num_epochs_print == 0:\n",
    "        print()\n",
    "        if scheduler !=None:\n",
    "            print('Epoch {}/{}, Learning rate {}'.format(\n",
    "                epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "        else:\n",
    "            print('Epoch {}/{}'.format(\n",
    "                epoch, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and test phase\n",
    "    for phase in ['train', 'test']:\n",
    "        if phase == 'train':\n",
    "            encoder.train()  # Set model to training mode\n",
    "            decoder.train()  # Set model to training mode\n",
    "        else:\n",
    "            encoder.eval()   # Set model to evaluation mode\n",
    "            decoder.eval()   # Set model to evaluation mode\n",
    "            \n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Iterate over data\n",
    "        for data, in data_loaders[phase]:\n",
    "            inputs = data.to(device)\n",
    "            targets = data.to(device)\n",
    "\n",
    "            if phase == 'train':\n",
    "                if scheduler != None:\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    outputs = decoder(encoder(inputs))\n",
    "                    loss = loss_func(outputs, targets)\n",
    "\n",
    "                    # backward\n",
    "                    loss.backward()\n",
    "\n",
    "                    # optimize\n",
    "                    optimizer.step()  \n",
    "                    \n",
    "                    # add running loss\n",
    "                    running_loss += loss.item()*inputs.shape[0]\n",
    "                else:\n",
    "                    def closure():\n",
    "                        # zero the parameter gradients\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                        # forward\n",
    "                        outputs = decoder(encoder(inputs))\n",
    "                        loss = loss_func(outputs,targets)\n",
    "\n",
    "                        # backward\n",
    "                        loss.backward()\n",
    "                        return loss\n",
    "\n",
    "                    # optimize\n",
    "                    optimizer.step(closure)\n",
    "                    \n",
    "                    # add running loss\n",
    "                    with torch.set_grad_enabled(False):\n",
    "                        outputs = decoder(encoder(inputs))\n",
    "                        running_loss += loss_func(outputs,targets).item()*inputs.shape[0]\n",
    "                    \n",
    "            else:\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    outputs = decoder(encoder(inputs))\n",
    "                    running_loss += loss_func(outputs,targets).item()*inputs.shape[0]\n",
    "\n",
    "        # compute epoch loss\n",
    "        epoch_loss = running_loss / dataset_shapes[phase][0]\n",
    "        loss_hist[phase].append(epoch_loss)\n",
    "            \n",
    "        # update learning rate\n",
    "        if phase == 'train' and scheduler != None:\n",
    "            scheduler.step(epoch_loss)\n",
    "\n",
    "        if epoch%num_epochs_print == 0:\n",
    "            print('{} MSELoss: {}'.format(\n",
    "                phase, epoch_loss))\n",
    "\n",
    "    # deep copy the model\n",
    "    if loss_hist['test'][-1] < best_loss:\n",
    "        best_loss = loss_hist['test'][-1]\n",
    "        early_stop_counter = 1\n",
    "        best_encoder_wts = copy.deepcopy(encoder.state_dict())\n",
    "        best_decoder_wts = copy.deepcopy(decoder.state_dict())\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= early_stop_patience:  \n",
    "            break\n",
    "    \n",
    "    # save checkpoint every num_epoch_print\n",
    "    if epoch%num_epochs_print== 0:\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'encoder_state_dict': encoder.state_dict(),\n",
    "                    'decoder_state_dict': decoder.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss_hist': loss_hist,\n",
    "                    'best_loss': best_loss,\n",
    "                    'early_stop_counter': early_stop_counter,\n",
    "                    'best_encoder_wts': best_encoder_wts,\n",
    "                    'best_decoder_wts': best_decoder_wts,\n",
    "                    }, PATH)        \n",
    "\n",
    "print()\n",
    "print('Epoch {}/{}, Learning rate {}'\\\n",
    "      .format(epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "print('-' * 10)\n",
    "print('train MSELoss: {}'.format(loss_hist['train'][-1]))\n",
    "print('test MSELoss: {}'.format(loss_hist['test'][-1]))\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "\n",
    "# load best model weights\n",
    "encoder.load_state_dict(best_encoder_wts)\n",
    "decoder.load_state_dict(best_decoder_wts)\n",
    "\n",
    "# compute best train MSELoss\n",
    "encoder.to('cpu').eval()\n",
    "decoder.to('cpu').eval()\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    train_inputs = torch.tensor(trainset)\n",
    "    train_targets = torch.tensor(trainset)\n",
    "    train_outputs = decoder(encoder(train_inputs))\n",
    "    train_loss = loss_func(train_outputs,train_targets).item()\n",
    "\n",
    "# print out training time and best results\n",
    "print()\n",
    "if epoch < num_epochs:\n",
    "    print('Early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "else:\n",
    "    print('No early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "print('-' * 10)\n",
    "print('Best train MSELoss: {}'.format(train_loss))\n",
    "print('Best test MSELoss: {}'.format(best_loss))\n",
    "\n",
    "# save models\n",
    "print()\n",
    "print(\"Saving after {}th training to\".format(epoch),\n",
    "      file_name_AE_pkl)\n",
    "# torch.save((encoder,decoder),file_name_AE_pkl) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "checkpoint removed\n"
     ]
    }
   ],
   "source": [
    "# delete checkpoint\n",
    "try:\n",
    "    os.remove(PATH)\n",
    "    print()\n",
    "    print(\"checkpoint removed\")\n",
    "except:\n",
    "    print(\"no checkpoint exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and test loss\n",
    "plt.figure()\n",
    "plt.semilogy(loss_hist['train'])\n",
    "plt.semilogy(loss_hist['test'])\n",
    "plt.legend(['train','test'])\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load models\n",
    "# try:\n",
    "#     encoder,decoder = torch.load(file_name_AE_pkl,map_location='cpu')\n",
    "#     print(\"\\n--------model restored--------\\n\")\n",
    "# except:\n",
    "#     print(\"\\n--------model not restored--------\\n\")\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights and bias\n",
    "en_w1=encoder.full[0].weight.cpu().detach().numpy().astype('float32')\n",
    "en_b1=encoder.full[0].bias.cpu().detach().numpy().astype('float32')\n",
    "en_w2=encoder.full[2].weight.cpu().detach().numpy().astype('float32')\n",
    "\n",
    "de_w1=decoder.full[0].weight.cpu().detach().numpy().astype('float32')\n",
    "de_w2=decoder.full[2].weight.cpu().detach().numpy().astype('float32')\n",
    "\n",
    "de_w2_sp=sp.csr_matrix(de_w2,dtype='float32')\n",
    "\n",
    "de_w1T=de_w1.T\n",
    "de_w2T=de_w2.T\n",
    "\n",
    "de_w2T_sp=de_w2_sp.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy version of AE\n",
    "def sigmoid_np(input):\n",
    "    return (1.0/(1.0+np.exp(-input))).astype('float32')\n",
    "\n",
    "def encoder_np_forward(x):\n",
    "    z1 = en_w1.dot(x) + en_b1\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = en_w2.dot(a1)   \n",
    "    return y\n",
    "\n",
    "def decoder_np_forward(x):\n",
    "    z1 = de_w1.dot(x)\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = de_w2.dot(a1)  \n",
    "    return y\n",
    "\n",
    "def decoder_sp_forward(x):\n",
    "    z1 = de_w1.dot(x)\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = sp.csr_matrix.dot(de_w2_sp,a1)\n",
    "    return y\n",
    "\n",
    "def decoder_np_forward_backward(x):\n",
    "    z1 = de_w1.dot(x)\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = de_w2.dot(a1)\n",
    "\n",
    "    dout = de_w1T\n",
    "    dout = (s1 + a1*(1-s1))*dout\n",
    "    dydxT = dout.dot(de_w2T)   \n",
    "    return y,dydxT.T\n",
    "\n",
    "def decoder_sp_forward_backward(x):\n",
    "    z1 = de_w1.dot(x) \n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = sp.csr_matrix.dot(de_w2_sp,a1)\n",
    "\n",
    "    dout = de_w1T\n",
    "    dout = (s1 + a1*(1-s1))*dout\n",
    "    dydxT = sp.csr_matrix.dot(dout,de_w2T_sp)\n",
    "    return y,dydxT.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE: 8.51414527e-07\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (numpy version)\n",
    "comp_orig_data=np.zeros((nset*nt,f))\n",
    "rest_orig_data=np.zeros(solution_snapshot.shape)\n",
    "\n",
    "for k in range(nset*nt):\n",
    "    comp_orig_data[k]=encoder_np_forward(solution_snapshot[k])\n",
    "    rest_orig_data[k]=decoder_sp_forward(comp_orig_data[k])\n",
    "    \n",
    "print(\"MSELoss of AE: {:.8e}\".format(np.linalg.norm(solution_snapshot-rest_orig_data)**2/np.prod(solution_snapshot.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE: 8.51413745e-07\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (PyTorch model)\n",
    "input_data=torch.tensor(solution_snapshot)\n",
    "target_data=decoder(encoder(input_data))\n",
    "\n",
    "print(\"MSELoss of AE: {:.8e}\".format(torch.nn.functional.mse_loss(input_data,target_data).detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE (predictive case): 1.24465930e-06\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (predictive case)\n",
    "FOM_solution=pickle.load(open('./data/FOM.p','rb'))\n",
    "FOM_solution=FOM_solution.astype('float32')\n",
    "\n",
    "orig_data_FOM = FOM_solution[1:,:-1]\n",
    "ref=FOM_solution[0,:-1]\n",
    "\n",
    "input_FOM=torch.tensor(orig_data_FOM-ref)\n",
    "target_FOM=decoder(encoder(input_FOM))\n",
    "\n",
    "print(\"MSELoss of AE (predictive case): {:.8e}\"\\\n",
    "      .format(torch.nn.functional.mse_loss(input_FOM,target_FOM).detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights and bias   \n",
    "AE={'en_w1':en_w1,'en_b1':en_b1,'en_w2':en_w2,\n",
    "    'de_w1':de_w1,'de_w2':de_w2,\n",
    "    'de_w1T':de_w1T,'de_w2T':de_w2T,'de_w2_sp':de_w2_sp,'de_w2T_sp':de_w2T_sp}\n",
    "\n",
    "pickle.dump(AE,open(file_name_AE,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
