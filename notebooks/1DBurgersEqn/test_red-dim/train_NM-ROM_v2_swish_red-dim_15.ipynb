{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.prune as prune\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "from scipy import sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import sys,time\n",
    "import os\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "redDim=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug 21 14:41:28 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.74       Driver Version: 418.74       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro M6000        On   | 00000000:02:00.0 Off |                  Off |\n",
      "| 25%   24C    P8    14W / 250W |      1MiB / 12212MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Quadro M6000        On   | 00000000:03:00.0 Off |                  Off |\n",
      "| 25%   27C    P0    62W / 250W |    346MiB / 12212MiB |     10%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Quadro M6000        On   | 00000000:81:00.0 Off |                  Off |\n",
      "| 25%   32C    P0   139W / 250W |   1145MiB / 12212MiB |     95%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Quadro M6000        On   | 00000000:82:00.0 Off |                  Off |\n",
      "| 25%   37C    P0   142W / 250W |   1145MiB / 12212MiB |     95%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    1     16340      C   /home/kim101/anaconda3/bin/python            334MiB |\n",
      "|    2     16318      C   /home/kim101/anaconda3/bin/python           1133MiB |\n",
      "|    3     16293      C   /home/kim101/anaconda3/bin/python           1133MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose device that is not being used\n",
    "gpu_ids = \"0\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=gpu_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_v2(m,b,db):\n",
    "    '''\n",
    "    mask=create_mask_v2(m,b,db)  \n",
    "    '''\n",
    "    \n",
    "    M2 = b + db*(m-1)\n",
    "    mask = np.zeros((m,M2),dtype='int')\n",
    "    \n",
    "    block = np.ones(b,dtype='int')\n",
    "    ind = np.arange(b)\n",
    "    for row in range(m):\n",
    "        col = ind + row*db\n",
    "        mask[row,col] = block\n",
    "    \n",
    "    print(\n",
    "        \"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "            m, M2, (1.0-np.count_nonzero(mask)/mask.size)*100\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.spy(mask)\n",
    "    plt.show()\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silu(input):\n",
    "    return input * torch.sigmoid(input)\n",
    "class SiLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return silu(input)\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,m,M1,f):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.full = nn.Sequential(\n",
    "            nn.Linear(m,M1),\n",
    "            SiLU(),\n",
    "            nn.Linear(M1,f,bias=False)\n",
    "        )\n",
    "                \n",
    "    def forward(self, y):     \n",
    "        y = y.view(-1,m)\n",
    "        T = self.full(y)\n",
    "        T = T.squeeze()\n",
    "        \n",
    "        return T\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,f,M2,m):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.full = nn.Sequential(\n",
    "            nn.Linear(f,M2,bias=False),\n",
    "            SiLU(),\n",
    "            nn.Linear(M2,m,bias=False)\n",
    "        )\n",
    "             \n",
    "    def forward(self,T):\n",
    "        T = T.view(-1,f)\n",
    "        y = self.full(T)\n",
    "        y = y.squeeze()\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([900, 1000]) torch.Size([100, 1000])\n"
     ]
    }
   ],
   "source": [
    "# load solution snapshot\n",
    "solution_snapshot_orig = pickle.load(open(\"./data/snapshot_full.p\", \"rb\"))\n",
    "nx=1001\n",
    "nt=500\n",
    "\n",
    "# substract IC -> centered on IC\n",
    "ndata=solution_snapshot_orig.shape[0]\n",
    "nset= round(ndata/(nt+1))\n",
    "\n",
    "solution_snapshot=np.array([])\n",
    "for foo in range(nset):\n",
    "    solution_snapshot=np.append(solution_snapshot,solution_snapshot_orig[foo*(nt+1)+1:(foo+1)*(nt+1)]\\\n",
    "    -solution_snapshot_orig[foo*(nt+1)])\n",
    "\n",
    "solution_snapshot=np.reshape(solution_snapshot,(-1,nx))\n",
    "\n",
    "# solution_snapshot_tmp1 = solution_snapshot[:501]-solution_snapshot[0]\n",
    "# solution_snapshot_tmp2 = solution_snapshot[501:]-solution_snapshot[501]\n",
    "# solution_snapshot = np.vstack((solution_snapshot_tmp1[1:],solution_snapshot_tmp2[1:]))\n",
    "\n",
    "# remove BC\n",
    "solution_snapshot = solution_snapshot[:,:-1].astype('float32')\n",
    "\n",
    "# define testset and trainset indices\n",
    "test_ind = np.random.permutation(np.arange(solution_snapshot.shape[0]))[:int(0.1*solution_snapshot.shape[0])]\n",
    "train_ind = np.setdiff1d(np.arange(solution_snapshot.shape[0]),test_ind)\n",
    "\n",
    "# set trainset and testset\n",
    "trainset = solution_snapshot[train_ind]\n",
    "testset = solution_snapshot[test_ind] \n",
    "\n",
    "# set dataset\n",
    "dataset = {'train':data_utils.TensorDataset(torch.tensor(trainset)),\n",
    "           'test':data_utils.TensorDataset(torch.tensor(testset))}\n",
    "print(dataset['train'].tensors[0].shape, dataset['test'].tensors[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 1000) (100, 1000)\n"
     ]
    }
   ],
   "source": [
    "# compute dataset shapes\n",
    "dataset_shapes = {'train':trainset.shape,\n",
    "                 'test':testset.shape}\n",
    "\n",
    "print(dataset_shapes['train'],dataset_shapes['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # when inputs and targets are different e.g. Kernel PCA + Decoder\n",
    "# mapped_solution_snapshot = loadmat('./data/mapped_solution_snaphost.mat')['mapped_solution_snapshot']\n",
    "\n",
    "# mapped_trainset = mapped_solution_snapshot[train_ind]\n",
    "# mapped_testset = mapped_solution_snapshot[test_ind]\n",
    "\n",
    "# inputs = {'train':mapped_trainset,'test':mapped_testset}\n",
    "# outputs = {'train':trainset,'test':testset}\n",
    "\n",
    "# dataset = {'train':data_utils.TensorDataset(inputs['train'], targets['train']),\n",
    "#            'test':data_utils.TensorDataset(inputs['test'], targets['test'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set batch_size, number of epochs, paitience for early stop\n",
    "batch_size = 20\n",
    "num_epochs = 10000//5\n",
    "num_epochs_print = num_epochs*5//100\n",
    "early_stop_patience = num_epochs*5//50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data loaders\n",
    "train_loader = DataLoader(dataset=dataset['train'], \n",
    "                          batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(dataset=dataset['test'], \n",
    "                         batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "data_loaders = {'train':train_loader, 'test':test_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # copy trainset to cpu (if inputs~=targets, replace 0 to 1 for targets)\n",
    "# trainset_inputs = data_loaders['train'].dataset.tensors[0].to('cpu')\n",
    "# trainset_targets = data_loaders['train'].dataset.tensors[0].to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set checkpoint\n",
    "PATH = './checkpoint_v2_red-dim_{}.tar'.format(redDim)\n",
    "\n",
    "# set file name for AE\n",
    "file_name_AE_pkl=\"./model/AE_v2_swish_red-dim_{}.pkl\".format(redDim)\n",
    "file_name_AE=\"./model/AE_v2_swish_red-dim_{}.p\".format(redDim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the number of nodes in each layer\n",
    "m = 1000\n",
    "f = redDim\n",
    "b = 36\n",
    "db = 12\n",
    "M2 = b + (m-1)*db\n",
    "M1 = 2*m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in 1000 by 12024 mask: 99.70%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------checkpoint not restored--------\n",
      "\n",
      "Sparsity in 1000 by 12024 mask: 99.70%\n",
      "\n",
      "Start first training... m=1000, f=15, M1=2000, M2=12024, b=36, db=12\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "try:\n",
    "    checkpoint = torch.load(PATH, map_location=device)\n",
    "    \n",
    "    encoder = Encoder(m,M1,f).to(device)\n",
    "    decoder = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    mask = create_mask_v2(m,b,db)\n",
    "    prune.custom_from_mask(decoder.full[2], name='weight', mask=torch.tensor(mask).to(device))    \n",
    "    \n",
    "#     optimizer = torch.optim.LBFGS(list(encoder.parameters()) + list(decoder.parameters()), lr=1)\n",
    "#     scheduler = None     \n",
    "    optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "    decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    last_epoch = checkpoint['epoch']\n",
    "    loss_hist = checkpoint['loss_hist']\n",
    "    best_loss = checkpoint['best_loss']\n",
    "    early_stop_counter = checkpoint['early_stop_counter']\n",
    "    best_encoder_wts = checkpoint['best_encoder_wts']\n",
    "    best_decoder_wts = checkpoint['best_decoder_wts']\n",
    "    \n",
    "    print(\"\\n--------checkpoint restored--------\\n\")\n",
    "    \n",
    "    # compute sparsity in mask\n",
    "    mask = decoder.state_dict()['full.2.weight_mask']\n",
    "    print(\"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "        mask.shape[0], mask.shape[1], 100. * float(torch.sum(mask == 0))/ float(mask.nelement())))\n",
    "\n",
    "    # resume training\n",
    "    print(\"\")\n",
    "    print('Re-start {}th training... m={}, f={}, M1={}, M2={}, b={}, db={}'.format(\n",
    "        last_epoch+1, m, f, M1, M2, b, db))\n",
    "except:\n",
    "    encoder = Encoder(m,M1,f).to(device)\n",
    "    decoder = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    mask = create_mask_v2(m,b,db)\n",
    "    prune.custom_from_mask(decoder.full[2], name='weight', mask=torch.tensor(mask).to(device))\n",
    "\n",
    "#     optimizer = torch.optim.LBFGS(list(encoder.parameters()) + list(decoder.parameters()), lr=1)\n",
    "#     scheduler = None \n",
    "    optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    last_epoch = 0\n",
    "    loss_hist = {'train':[],'test':[]}\n",
    "    best_loss = float(\"inf\")\n",
    "    early_stop_counter = 1\n",
    "    best_encoder_wts = copy.deepcopy(encoder.state_dict())\n",
    "    best_decoder_wts = copy.deepcopy(decoder.state_dict())\n",
    "    \n",
    "    print(\"\\n--------checkpoint not restored--------\\n\")\n",
    "    \n",
    "    # compute sparsity in mask\n",
    "    mask = decoder.state_dict()['full.2.weight_mask']\n",
    "    print(\"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "        mask.shape[0], mask.shape[1], 100. * float(torch.sum(mask == 0))/ float(mask.nelement())))\n",
    "\n",
    "    # start training\n",
    "    print(\"\")\n",
    "    print('Start first training... m={}, f={}, M1={}, M2={}, b={}, db={}'.format(\n",
    "        m, f, M1, M2, b, db))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100/2000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 1.8570771984135112e-05\n",
      "test MSELoss: 2.1181047122809106e-05\n",
      "\n",
      "Epoch 200/2000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 8.764382649436205e-06\n",
      "test MSELoss: 9.10500039026374e-06\n",
      "\n",
      "Epoch 300/2000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.8131191230487377e-06\n",
      "test MSELoss: 3.315032563477871e-06\n",
      "\n",
      "Epoch 400/2000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.459825229076766e-06\n",
      "test MSELoss: 2.848293615898001e-06\n",
      "\n",
      "Epoch 500/2000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.0331246332716544e-06\n",
      "test MSELoss: 2.313352365490573e-06\n",
      "\n",
      "Epoch 600/2000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.7064840878649395e-06\n",
      "test MSELoss: 1.996103242163372e-06\n",
      "\n",
      "Epoch 700/2000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.437587734977165e-06\n",
      "test MSELoss: 1.6718653114367044e-06\n",
      "\n",
      "Epoch 800/2000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.2509305861385656e-06\n",
      "test MSELoss: 1.459385453017603e-06\n",
      "\n",
      "Epoch 900/2000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 1.0084831640395148e-06\n",
      "test MSELoss: 1.2160781579950708e-06\n",
      "\n",
      "Epoch 1000/2000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 9.909441157813288e-07\n",
      "test MSELoss: 1.202729936267133e-06\n",
      "\n",
      "Epoch 1100/2000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 9.907618593590288e-07\n",
      "test MSELoss: 1.202337034555967e-06\n",
      "\n",
      "Epoch 1142/2000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 9.906987328476034e-07\n",
      "test MSELoss: 1.202278747314267e-06\n",
      "\n",
      "Early stopping: 1142th training complete in 0h 6m 40s\n",
      "----------\n",
      "Best train MSELoss: 9.910340850183275e-07\n",
      "Best test MSELoss: 1.2016878372378414e-06\n",
      "\n",
      "Saving after 1142th training to ./model/AE_v2_swish_red-dim_15.pkl\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "since = time.time()\n",
    "\n",
    "for epoch in range(last_epoch+1,num_epochs+1):   \n",
    "\n",
    "    if epoch%num_epochs_print == 0:\n",
    "        print()\n",
    "        if scheduler !=None:\n",
    "            print('Epoch {}/{}, Learning rate {}'.format(\n",
    "                epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "        else:\n",
    "            print('Epoch {}/{}'.format(\n",
    "                epoch, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and test phase\n",
    "    for phase in ['train', 'test']:\n",
    "        if phase == 'train':\n",
    "            encoder.train()  # Set model to training mode\n",
    "            decoder.train()  # Set model to training mode\n",
    "        else:\n",
    "            encoder.eval()   # Set model to evaluation mode\n",
    "            decoder.eval()   # Set model to evaluation mode\n",
    "            \n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Iterate over data\n",
    "        for data, in data_loaders[phase]:\n",
    "            inputs = data.to(device)\n",
    "            targets = data.to(device)\n",
    "\n",
    "            if phase == 'train':\n",
    "                if scheduler != None:\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    outputs = decoder(encoder(inputs))\n",
    "                    loss = loss_func(outputs, targets)\n",
    "\n",
    "                    # backward\n",
    "                    loss.backward()\n",
    "\n",
    "                    # optimize\n",
    "                    optimizer.step()  \n",
    "                    \n",
    "                    # add running loss\n",
    "                    running_loss += loss.item()*inputs.shape[0]\n",
    "                else:\n",
    "                    def closure():\n",
    "                        # zero the parameter gradients\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                        # forward\n",
    "                        outputs = decoder(encoder(inputs))\n",
    "                        loss = loss_func(outputs,targets)\n",
    "\n",
    "                        # backward\n",
    "                        loss.backward()\n",
    "                        return loss\n",
    "\n",
    "                    # optimize\n",
    "                    optimizer.step(closure)\n",
    "                    \n",
    "                    # add running loss\n",
    "                    with torch.set_grad_enabled(False):\n",
    "                        outputs = decoder(encoder(inputs))\n",
    "                        running_loss += loss_func(outputs,targets).item()*inputs.shape[0]\n",
    "                    \n",
    "            else:\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    outputs = decoder(encoder(inputs))\n",
    "                    running_loss += loss_func(outputs,targets).item()*inputs.shape[0]\n",
    "\n",
    "        # compute epoch loss\n",
    "        epoch_loss = running_loss / dataset_shapes[phase][0]\n",
    "        loss_hist[phase].append(epoch_loss)\n",
    "            \n",
    "        # update learning rate\n",
    "        if phase == 'train' and scheduler != None:\n",
    "            scheduler.step(epoch_loss)\n",
    "\n",
    "        if epoch%num_epochs_print == 0:\n",
    "            print('{} MSELoss: {}'.format(\n",
    "                phase, epoch_loss))\n",
    "\n",
    "    # deep copy the model\n",
    "    if loss_hist['test'][-1] < best_loss:\n",
    "        best_loss = loss_hist['test'][-1]\n",
    "        early_stop_counter = 1\n",
    "        best_encoder_wts = copy.deepcopy(encoder.state_dict())\n",
    "        best_decoder_wts = copy.deepcopy(decoder.state_dict())\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= early_stop_patience:  \n",
    "            break\n",
    "    \n",
    "    # save checkpoint every num_epoch_print\n",
    "    if epoch%num_epochs_print== 0:\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'encoder_state_dict': encoder.state_dict(),\n",
    "                    'decoder_state_dict': decoder.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss_hist': loss_hist,\n",
    "                    'best_loss': best_loss,\n",
    "                    'early_stop_counter': early_stop_counter,\n",
    "                    'best_encoder_wts': best_encoder_wts,\n",
    "                    'best_decoder_wts': best_decoder_wts,\n",
    "                    }, PATH)        \n",
    "\n",
    "print()\n",
    "print('Epoch {}/{}, Learning rate {}'\\\n",
    "      .format(epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "print('-' * 10)\n",
    "print('train MSELoss: {}'.format(loss_hist['train'][-1]))\n",
    "print('test MSELoss: {}'.format(loss_hist['test'][-1]))\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "\n",
    "# load best model weights\n",
    "encoder.load_state_dict(best_encoder_wts)\n",
    "decoder.load_state_dict(best_decoder_wts)\n",
    "\n",
    "# compute best train MSELoss\n",
    "encoder.to('cpu').eval()\n",
    "decoder.to('cpu').eval()\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    train_inputs = torch.tensor(trainset)\n",
    "    train_targets = torch.tensor(trainset)\n",
    "    train_outputs = decoder(encoder(train_inputs))\n",
    "    train_loss = loss_func(train_outputs,train_targets).item()\n",
    "\n",
    "# print out training time and best results\n",
    "print()\n",
    "if epoch < num_epochs:\n",
    "    print('Early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "else:\n",
    "    print('No early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "print('-' * 10)\n",
    "print('Best train MSELoss: {}'.format(train_loss))\n",
    "print('Best test MSELoss: {}'.format(best_loss))\n",
    "\n",
    "# save models\n",
    "print()\n",
    "print(\"Saving after {}th training to\".format(epoch),\n",
    "      file_name_AE_pkl)\n",
    "# torch.save((encoder,decoder),file_name_AE_pkl) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "checkpoint removed\n"
     ]
    }
   ],
   "source": [
    "# delete checkpoint\n",
    "try:\n",
    "    os.remove(PATH)\n",
    "    print()\n",
    "    print(\"checkpoint removed\")\n",
    "except:\n",
    "    print(\"no checkpoint exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and test loss\n",
    "plt.figure()\n",
    "plt.semilogy(loss_hist['train'])\n",
    "plt.semilogy(loss_hist['test'])\n",
    "plt.legend(['train','test'])\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load models\n",
    "# try:\n",
    "#     encoder,decoder = torch.load(file_name_AE_pkl,map_location='cpu')\n",
    "#     print(\"\\n--------model restored--------\\n\")\n",
    "# except:\n",
    "#     print(\"\\n--------model not restored--------\\n\")\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights and bias\n",
    "en_w1=encoder.full[0].weight.cpu().detach().numpy().astype('float32')\n",
    "en_b1=encoder.full[0].bias.cpu().detach().numpy().astype('float32')\n",
    "en_w2=encoder.full[2].weight.cpu().detach().numpy().astype('float32')\n",
    "\n",
    "de_w1=decoder.full[0].weight.cpu().detach().numpy().astype('float32')\n",
    "de_w2=decoder.full[2].weight.cpu().detach().numpy().astype('float32')\n",
    "\n",
    "de_w2_sp=sp.csr_matrix(de_w2,dtype='float32')\n",
    "\n",
    "de_w1T=de_w1.T\n",
    "de_w2T=de_w2.T\n",
    "\n",
    "de_w2T_sp=de_w2_sp.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy version of AE\n",
    "def sigmoid_np(input):\n",
    "    return (1.0/(1.0+np.exp(-input))).astype('float32')\n",
    "\n",
    "def encoder_np_forward(x):\n",
    "    z1 = en_w1.dot(x) + en_b1\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = en_w2.dot(a1)   \n",
    "    return y\n",
    "\n",
    "def decoder_np_forward(x):\n",
    "    z1 = de_w1.dot(x)\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = de_w2.dot(a1)  \n",
    "    return y\n",
    "\n",
    "def decoder_sp_forward(x):\n",
    "    z1 = de_w1.dot(x)\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = sp.csr_matrix.dot(de_w2_sp,a1)\n",
    "    return y\n",
    "\n",
    "def decoder_np_forward_backward(x):\n",
    "    z1 = de_w1.dot(x)\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = de_w2.dot(a1)\n",
    "\n",
    "    dout = de_w1T\n",
    "    dout = (s1 + a1*(1-s1))*dout\n",
    "    dydxT = dout.dot(de_w2T)   \n",
    "    return y,dydxT.T\n",
    "\n",
    "def decoder_sp_forward_backward(x):\n",
    "    z1 = de_w1.dot(x) \n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = sp.csr_matrix.dot(de_w2_sp,a1)\n",
    "\n",
    "    dout = de_w1T\n",
    "    dout = (s1 + a1*(1-s1))*dout\n",
    "    dydxT = sp.csr_matrix.dot(dout,de_w2T_sp)\n",
    "    return y,dydxT.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE: 1.01209961e-06\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (numpy version)\n",
    "comp_orig_data=np.zeros((nset*nt,f))\n",
    "rest_orig_data=np.zeros(solution_snapshot.shape)\n",
    "\n",
    "for k in range(nset*nt):\n",
    "    comp_orig_data[k]=encoder_np_forward(solution_snapshot[k])\n",
    "    rest_orig_data[k]=decoder_sp_forward(comp_orig_data[k])\n",
    "    \n",
    "print(\"MSELoss of AE: {:.8e}\".format(np.linalg.norm(solution_snapshot-rest_orig_data)**2/np.prod(solution_snapshot.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE: 1.01209901e-06\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (PyTorch model)\n",
    "input_data=torch.tensor(solution_snapshot)\n",
    "target_data=decoder(encoder(input_data))\n",
    "\n",
    "print(\"MSELoss of AE: {:.8e}\".format(torch.nn.functional.mse_loss(input_data,target_data).detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE (predictive case): 9.35988169e-07\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (predictive case)\n",
    "FOM_solution=pickle.load(open('./data/FOM.p','rb'))\n",
    "FOM_solution=FOM_solution.astype('float32')\n",
    "\n",
    "orig_data_FOM = FOM_solution[1:,:-1]\n",
    "ref=FOM_solution[0,:-1]\n",
    "\n",
    "input_FOM=torch.tensor(orig_data_FOM-ref)\n",
    "target_FOM=decoder(encoder(input_FOM))\n",
    "\n",
    "print(\"MSELoss of AE (predictive case): {:.8e}\"\\\n",
    "      .format(torch.nn.functional.mse_loss(input_FOM,target_FOM).detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights and bias   \n",
    "AE={'en_w1':en_w1,'en_b1':en_b1,'en_w2':en_w2,\n",
    "    'de_w1':de_w1,'de_w2':de_w2,\n",
    "    'de_w1T':de_w1T,'de_w2T':de_w2T,'de_w2_sp':de_w2_sp,'de_w2T_sp':de_w2T_sp}\n",
    "\n",
    "pickle.dump(AE,open(file_name_AE,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
