{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.prune as prune\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "from scipy import sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import sys,time\n",
    "import os\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "redDim=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug 21 13:39:05 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.74       Driver Version: 418.74       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro M6000        On   | 00000000:02:00.0 Off |                  Off |\n",
      "| 25%   24C    P8    14W / 250W |      1MiB / 12212MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Quadro M6000        On   | 00000000:03:00.0 Off |                  Off |\n",
      "| 25%   25C    P8    14W / 250W |      1MiB / 12212MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Quadro M6000        On   | 00000000:81:00.0 Off |                  Off |\n",
      "| 25%   26C    P8    14W / 250W |      1MiB / 12212MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Quadro M6000        On   | 00000000:82:00.0 Off |                  Off |\n",
      "| 25%   27C    P8    14W / 250W |      1MiB / 12212MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose device that is not being used\n",
    "gpu_ids = \"0\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=gpu_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_v2(m,b,db):\n",
    "    '''\n",
    "    mask=create_mask_v2(m,b,db)  \n",
    "    '''\n",
    "    \n",
    "    M2 = b + db*(m-1)\n",
    "    mask = np.zeros((m,M2),dtype='int')\n",
    "    \n",
    "    block = np.ones(b,dtype='int')\n",
    "    ind = np.arange(b)\n",
    "    for row in range(m):\n",
    "        col = ind + row*db\n",
    "        mask[row,col] = block\n",
    "    \n",
    "    print(\n",
    "        \"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "            m, M2, (1.0-np.count_nonzero(mask)/mask.size)*100\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.spy(mask)\n",
    "    plt.show()\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silu(input):\n",
    "    return input * torch.sigmoid(input)\n",
    "class SiLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return silu(input)\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,m,M1,f):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.full = nn.Sequential(\n",
    "            nn.Linear(m,M1),\n",
    "            SiLU(),\n",
    "            nn.Linear(M1,f,bias=False)\n",
    "        )\n",
    "                \n",
    "    def forward(self, y):     \n",
    "        y = y.view(-1,m)\n",
    "        T = self.full(y)\n",
    "        T = T.squeeze()\n",
    "        \n",
    "        return T\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,f,M2,m):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.full = nn.Sequential(\n",
    "            nn.Linear(f,M2,bias=False),\n",
    "            SiLU(),\n",
    "            nn.Linear(M2,m,bias=False)\n",
    "        )\n",
    "             \n",
    "    def forward(self,T):\n",
    "        T = T.view(-1,f)\n",
    "        y = self.full(T)\n",
    "        y = y.squeeze()\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([900, 1000]) torch.Size([100, 1000])\n"
     ]
    }
   ],
   "source": [
    "# load solution snapshot\n",
    "solution_snapshot_orig = pickle.load(open(\"./data/snapshot_full.p\", \"rb\"))\n",
    "nx=1001\n",
    "nt=500\n",
    "\n",
    "# substract IC -> centered on IC\n",
    "ndata=solution_snapshot_orig.shape[0]\n",
    "nset= round(ndata/(nt+1))\n",
    "\n",
    "solution_snapshot=np.array([])\n",
    "for foo in range(nset):\n",
    "    solution_snapshot=np.append(solution_snapshot,solution_snapshot_orig[foo*(nt+1)+1:(foo+1)*(nt+1)]\\\n",
    "    -solution_snapshot_orig[foo*(nt+1)])\n",
    "\n",
    "solution_snapshot=np.reshape(solution_snapshot,(-1,nx))\n",
    "\n",
    "# solution_snapshot_tmp1 = solution_snapshot[:501]-solution_snapshot[0]\n",
    "# solution_snapshot_tmp2 = solution_snapshot[501:]-solution_snapshot[501]\n",
    "# solution_snapshot = np.vstack((solution_snapshot_tmp1[1:],solution_snapshot_tmp2[1:]))\n",
    "\n",
    "# remove BC\n",
    "solution_snapshot = solution_snapshot[:,:-1].astype('float32')\n",
    "\n",
    "# define testset and trainset indices\n",
    "test_ind = np.random.permutation(np.arange(solution_snapshot.shape[0]))[:int(0.1*solution_snapshot.shape[0])]\n",
    "train_ind = np.setdiff1d(np.arange(solution_snapshot.shape[0]),test_ind)\n",
    "\n",
    "# set trainset and testset\n",
    "trainset = solution_snapshot[train_ind]\n",
    "testset = solution_snapshot[test_ind] \n",
    "\n",
    "# set dataset\n",
    "dataset = {'train':data_utils.TensorDataset(torch.tensor(trainset)),\n",
    "           'test':data_utils.TensorDataset(torch.tensor(testset))}\n",
    "print(dataset['train'].tensors[0].shape, dataset['test'].tensors[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 1000) (100, 1000)\n"
     ]
    }
   ],
   "source": [
    "# compute dataset shapes\n",
    "dataset_shapes = {'train':trainset.shape,\n",
    "                 'test':testset.shape}\n",
    "\n",
    "print(dataset_shapes['train'],dataset_shapes['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # when inputs and targets are different e.g. Kernel PCA + Decoder\n",
    "# mapped_solution_snapshot = loadmat('./data/mapped_solution_snaphost.mat')['mapped_solution_snapshot']\n",
    "\n",
    "# mapped_trainset = mapped_solution_snapshot[train_ind]\n",
    "# mapped_testset = mapped_solution_snapshot[test_ind]\n",
    "\n",
    "# inputs = {'train':mapped_trainset,'test':mapped_testset}\n",
    "# outputs = {'train':trainset,'test':testset}\n",
    "\n",
    "# dataset = {'train':data_utils.TensorDataset(inputs['train'], targets['train']),\n",
    "#            'test':data_utils.TensorDataset(inputs['test'], targets['test'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set batch_size, number of epochs, paitience for early stop\n",
    "batch_size = 20\n",
    "num_epochs = 10000//5\n",
    "num_epochs_print = num_epochs*5//100\n",
    "early_stop_patience = num_epochs*5//50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data loaders\n",
    "train_loader = DataLoader(dataset=dataset['train'], \n",
    "                          batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(dataset=dataset['test'], \n",
    "                         batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "data_loaders = {'train':train_loader, 'test':test_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # copy trainset to cpu (if inputs~=targets, replace 0 to 1 for targets)\n",
    "# trainset_inputs = data_loaders['train'].dataset.tensors[0].to('cpu')\n",
    "# trainset_targets = data_loaders['train'].dataset.tensors[0].to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set checkpoint\n",
    "PATH = './checkpoint_v2_red-dim_{}.tar'.format(redDim)\n",
    "\n",
    "# set file name for AE\n",
    "file_name_AE_pkl=\"./model/AE_v2_swish_red-dim_{}.pkl\".format(redDim)\n",
    "file_name_AE=\"./model/AE_v2_swish_red-dim_{}.p\".format(redDim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the number of nodes in each layer\n",
    "m = 1000\n",
    "f = redDim\n",
    "b = 36\n",
    "db = 12\n",
    "M2 = b + (m-1)*db\n",
    "M1 = 2*m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in 1000 by 12024 mask: 99.70%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------checkpoint not restored--------\n",
      "\n",
      "Sparsity in 1000 by 12024 mask: 99.70%\n",
      "\n",
      "Start first training... m=1000, f=2, M1=2000, M2=12024, b=36, db=12\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "try:\n",
    "    checkpoint = torch.load(PATH, map_location=device)\n",
    "    \n",
    "    encoder = Encoder(m,M1,f).to(device)\n",
    "    decoder = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    mask = create_mask_v2(m,b,db)\n",
    "    prune.custom_from_mask(decoder.full[2], name='weight', mask=torch.tensor(mask).to(device))    \n",
    "    \n",
    "#     optimizer = torch.optim.LBFGS(list(encoder.parameters()) + list(decoder.parameters()), lr=1)\n",
    "#     scheduler = None     \n",
    "    optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "    decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    last_epoch = checkpoint['epoch']\n",
    "    loss_hist = checkpoint['loss_hist']\n",
    "    best_loss = checkpoint['best_loss']\n",
    "    early_stop_counter = checkpoint['early_stop_counter']\n",
    "    best_encoder_wts = checkpoint['best_encoder_wts']\n",
    "    best_decoder_wts = checkpoint['best_decoder_wts']\n",
    "    \n",
    "    print(\"\\n--------checkpoint restored--------\\n\")\n",
    "    \n",
    "    # compute sparsity in mask\n",
    "    mask = decoder.state_dict()['full.2.weight_mask']\n",
    "    print(\"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "        mask.shape[0], mask.shape[1], 100. * float(torch.sum(mask == 0))/ float(mask.nelement())))\n",
    "\n",
    "    # resume training\n",
    "    print(\"\")\n",
    "    print('Re-start {}th training... m={}, f={}, M1={}, M2={}, b={}, db={}'.format(\n",
    "        last_epoch+1, m, f, M1, M2, b, db))\n",
    "except:\n",
    "    encoder = Encoder(m,M1,f).to(device)\n",
    "    decoder = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    mask = create_mask_v2(m,b,db)\n",
    "    prune.custom_from_mask(decoder.full[2], name='weight', mask=torch.tensor(mask).to(device))\n",
    "\n",
    "#     optimizer = torch.optim.LBFGS(list(encoder.parameters()) + list(decoder.parameters()), lr=1)\n",
    "#     scheduler = None \n",
    "    optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    last_epoch = 0\n",
    "    loss_hist = {'train':[],'test':[]}\n",
    "    best_loss = float(\"inf\")\n",
    "    early_stop_counter = 1\n",
    "    best_encoder_wts = copy.deepcopy(encoder.state_dict())\n",
    "    best_decoder_wts = copy.deepcopy(decoder.state_dict())\n",
    "    \n",
    "    print(\"\\n--------checkpoint not restored--------\\n\")\n",
    "    \n",
    "    # compute sparsity in mask\n",
    "    mask = decoder.state_dict()['full.2.weight_mask']\n",
    "    print(\"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "        mask.shape[0], mask.shape[1], 100. * float(torch.sum(mask == 0))/ float(mask.nelement())))\n",
    "\n",
    "    # start training\n",
    "    print(\"\")\n",
    "    print('Start first training... m={}, f={}, M1={}, M2={}, b={}, db={}'.format(\n",
    "        m, f, M1, M2, b, db))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 3.522251863614656e-05\n",
      "test MSELoss: 3.7213143514236435e-05\n",
      "\n",
      "Epoch 200/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 2.8195247513293807e-05\n",
      "test MSELoss: 2.6053335022879765e-05\n",
      "\n",
      "Epoch 300/10000, Learning rate 1.0000000000000002e-07\n",
      "----------\n",
      "train MSELoss: 1.956310340271254e-05\n",
      "test MSELoss: 1.9806006639555564e-05\n",
      "\n",
      "Epoch 400/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 1.955564447497535e-05\n",
      "test MSELoss: 1.9813134349533358e-05\n",
      "\n",
      "Epoch 485/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 1.9554952005920415e-05\n",
      "test MSELoss: 1.9813001199509016e-05\n",
      "\n",
      "Early stopping: 485th training complete in 0h 2m 49s\n",
      "----------\n",
      "Best train MSELoss: 1.957195308932569e-05\n",
      "Best test MSELoss: 1.9797692584688775e-05\n",
      "\n",
      "Saving after 485th training to ./model/AE_v2_swish_red-dim_2.pkl\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "since = time.time()\n",
    "\n",
    "for epoch in range(last_epoch+1,num_epochs+1):   \n",
    "\n",
    "    if epoch%num_epochs_print == 0:\n",
    "        print()\n",
    "        if scheduler !=None:\n",
    "            print('Epoch {}/{}, Learning rate {}'.format(\n",
    "                epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "        else:\n",
    "            print('Epoch {}/{}'.format(\n",
    "                epoch, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and test phase\n",
    "    for phase in ['train', 'test']:\n",
    "        if phase == 'train':\n",
    "            encoder.train()  # Set model to training mode\n",
    "            decoder.train()  # Set model to training mode\n",
    "        else:\n",
    "            encoder.eval()   # Set model to evaluation mode\n",
    "            decoder.eval()   # Set model to evaluation mode\n",
    "            \n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Iterate over data\n",
    "        for data, in data_loaders[phase]:\n",
    "            inputs = data.to(device)\n",
    "            targets = data.to(device)\n",
    "\n",
    "            if phase == 'train':\n",
    "                if scheduler != None:\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    outputs = decoder(encoder(inputs))\n",
    "                    loss = loss_func(outputs, targets)\n",
    "\n",
    "                    # backward\n",
    "                    loss.backward()\n",
    "\n",
    "                    # optimize\n",
    "                    optimizer.step()  \n",
    "                    \n",
    "                    # add running loss\n",
    "                    running_loss += loss.item()*inputs.shape[0]\n",
    "                else:\n",
    "                    def closure():\n",
    "                        # zero the parameter gradients\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                        # forward\n",
    "                        outputs = decoder(encoder(inputs))\n",
    "                        loss = loss_func(outputs,targets)\n",
    "\n",
    "                        # backward\n",
    "                        loss.backward()\n",
    "                        return loss\n",
    "\n",
    "                    # optimize\n",
    "                    optimizer.step(closure)\n",
    "                    \n",
    "                    # add running loss\n",
    "                    with torch.set_grad_enabled(False):\n",
    "                        outputs = decoder(encoder(inputs))\n",
    "                        running_loss += loss_func(outputs,targets).item()*inputs.shape[0]\n",
    "                    \n",
    "            else:\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    outputs = decoder(encoder(inputs))\n",
    "                    running_loss += loss_func(outputs,targets).item()*inputs.shape[0]\n",
    "\n",
    "        # compute epoch loss\n",
    "        epoch_loss = running_loss / dataset_shapes[phase][0]\n",
    "        loss_hist[phase].append(epoch_loss)\n",
    "            \n",
    "        # update learning rate\n",
    "        if phase == 'train' and scheduler != None:\n",
    "            scheduler.step(epoch_loss)\n",
    "\n",
    "        if epoch%num_epochs_print == 0:\n",
    "            print('{} MSELoss: {}'.format(\n",
    "                phase, epoch_loss))\n",
    "\n",
    "    # deep copy the model\n",
    "    if loss_hist['test'][-1] < best_loss:\n",
    "        best_loss = loss_hist['test'][-1]\n",
    "        early_stop_counter = 1\n",
    "        best_encoder_wts = copy.deepcopy(encoder.state_dict())\n",
    "        best_decoder_wts = copy.deepcopy(decoder.state_dict())\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= early_stop_patience:  \n",
    "            break\n",
    "    \n",
    "    # save checkpoint every num_epoch_print\n",
    "    if epoch%num_epochs_print== 0:\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'encoder_state_dict': encoder.state_dict(),\n",
    "                    'decoder_state_dict': decoder.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss_hist': loss_hist,\n",
    "                    'best_loss': best_loss,\n",
    "                    'early_stop_counter': early_stop_counter,\n",
    "                    'best_encoder_wts': best_encoder_wts,\n",
    "                    'best_decoder_wts': best_decoder_wts,\n",
    "                    }, PATH)        \n",
    "\n",
    "print()\n",
    "print('Epoch {}/{}, Learning rate {}'\\\n",
    "      .format(epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "print('-' * 10)\n",
    "print('train MSELoss: {}'.format(loss_hist['train'][-1]))\n",
    "print('test MSELoss: {}'.format(loss_hist['test'][-1]))\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "\n",
    "# load best model weights\n",
    "encoder.load_state_dict(best_encoder_wts)\n",
    "decoder.load_state_dict(best_decoder_wts)\n",
    "\n",
    "# compute best train MSELoss\n",
    "encoder.to('cpu').eval()\n",
    "decoder.to('cpu').eval()\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    train_inputs = torch.tensor(trainset)\n",
    "    train_targets = torch.tensor(trainset)\n",
    "    train_outputs = decoder(encoder(train_inputs))\n",
    "    train_loss = loss_func(train_outputs,train_targets).item()\n",
    "\n",
    "# print out training time and best results\n",
    "print()\n",
    "if epoch < num_epochs:\n",
    "    print('Early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "else:\n",
    "    print('No early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "print('-' * 10)\n",
    "print('Best train MSELoss: {}'.format(train_loss))\n",
    "print('Best test MSELoss: {}'.format(best_loss))\n",
    "\n",
    "# save models\n",
    "print()\n",
    "print(\"Saving after {}th training to\".format(epoch),\n",
    "      file_name_AE_pkl)\n",
    "# torch.save((encoder,decoder),file_name_AE_pkl) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "checkpoint removed\n"
     ]
    }
   ],
   "source": [
    "# delete checkpoint\n",
    "try:\n",
    "    os.remove(PATH)\n",
    "    print()\n",
    "    print(\"checkpoint removed\")\n",
    "except:\n",
    "    print(\"no checkpoint exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and test loss\n",
    "plt.figure()\n",
    "plt.semilogy(loss_hist['train'])\n",
    "plt.semilogy(loss_hist['test'])\n",
    "plt.legend(['train','test'])\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load models\n",
    "# try:\n",
    "#     encoder,decoder = torch.load(file_name_AE_pkl,map_location='cpu')\n",
    "#     print(\"\\n--------model restored--------\\n\")\n",
    "# except:\n",
    "#     print(\"\\n--------model not restored--------\\n\")\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights and bias\n",
    "en_w1=encoder.full[0].weight.cpu().detach().numpy().astype('float32')\n",
    "en_b1=encoder.full[0].bias.cpu().detach().numpy().astype('float32')\n",
    "en_w2=encoder.full[2].weight.cpu().detach().numpy().astype('float32')\n",
    "\n",
    "de_w1=decoder.full[0].weight.cpu().detach().numpy().astype('float32')\n",
    "de_w2=decoder.full[2].weight.cpu().detach().numpy().astype('float32')\n",
    "\n",
    "de_w2_sp=sp.csr_matrix(de_w2,dtype='float32')\n",
    "\n",
    "de_w1T=de_w1.T\n",
    "de_w2T=de_w2.T\n",
    "\n",
    "de_w2T_sp=de_w2_sp.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy version of AE\n",
    "def sigmoid_np(input):\n",
    "    return (1.0/(1.0+np.exp(-input))).astype('float32')\n",
    "\n",
    "def encoder_np_forward(x):\n",
    "    z1 = en_w1.dot(x) + en_b1\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = en_w2.dot(a1)   \n",
    "    return y\n",
    "\n",
    "def decoder_np_forward(x):\n",
    "    z1 = de_w1.dot(x)\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = de_w2.dot(a1)  \n",
    "    return y\n",
    "\n",
    "def decoder_sp_forward(x):\n",
    "    z1 = de_w1.dot(x)\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = sp.csr_matrix.dot(de_w2_sp,a1)\n",
    "    return y\n",
    "\n",
    "def decoder_np_forward_backward(x):\n",
    "    z1 = de_w1.dot(x)\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = de_w2.dot(a1)\n",
    "\n",
    "    dout = de_w1T\n",
    "    dout = (s1 + a1*(1-s1))*dout\n",
    "    dydxT = dout.dot(de_w2T)   \n",
    "    return y,dydxT.T\n",
    "\n",
    "def decoder_sp_forward_backward(x):\n",
    "    z1 = de_w1.dot(x) \n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = sp.csr_matrix.dot(de_w2_sp,a1)\n",
    "\n",
    "    dout = de_w1T\n",
    "    dout = (s1 + a1*(1-s1))*dout\n",
    "    dydxT = sp.csr_matrix.dot(dout,de_w2T_sp)\n",
    "    return y,dydxT.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE: 1.95945433e-05\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (numpy version)\n",
    "comp_orig_data=np.zeros((nset*nt,f))\n",
    "rest_orig_data=np.zeros(solution_snapshot.shape)\n",
    "\n",
    "for k in range(nset*nt):\n",
    "    comp_orig_data[k]=encoder_np_forward(solution_snapshot[k])\n",
    "    rest_orig_data[k]=decoder_sp_forward(comp_orig_data[k])\n",
    "    \n",
    "print(\"MSELoss of AE: {:.8e}\".format(np.linalg.norm(solution_snapshot-rest_orig_data)**2/np.prod(solution_snapshot.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE: 1.95945213e-05\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (PyTorch model)\n",
    "input_data=torch.tensor(solution_snapshot)\n",
    "target_data=decoder(encoder(input_data))\n",
    "\n",
    "print(\"MSELoss of AE: {:.8e}\".format(torch.nn.functional.mse_loss(input_data,target_data).detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE (predictive case): 5.08021458e-06\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (predictive case)\n",
    "FOM_solution=pickle.load(open('./data/FOM.p','rb'))\n",
    "FOM_solution=FOM_solution.astype('float32')\n",
    "\n",
    "orig_data_FOM = FOM_solution[1:,:-1]\n",
    "ref=FOM_solution[0,:-1]\n",
    "\n",
    "input_FOM=torch.tensor(orig_data_FOM-ref)\n",
    "target_FOM=decoder(encoder(input_FOM))\n",
    "\n",
    "print(\"MSELoss of AE (predictive case): {:.8e}\"\\\n",
    "      .format(torch.nn.functional.mse_loss(input_FOM,target_FOM).detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights and bias   \n",
    "AE={'en_w1':en_w1,'en_b1':en_b1,'en_w2':en_w2,\n",
    "    'de_w1':de_w1,'de_w2':de_w2,\n",
    "    'de_w1T':de_w1T,'de_w2T':de_w2T,'de_w2_sp':de_w2_sp,'de_w2T_sp':de_w2T_sp}\n",
    "\n",
    "pickle.dump(AE,open(file_name_AE,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
