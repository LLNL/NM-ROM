{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.prune as prune\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "from scipy import sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import sys,time\n",
    "import os\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "redDim=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug 21 14:41:23 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.74       Driver Version: 418.74       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro M6000        On   | 00000000:02:00.0 Off |                  Off |\n",
      "| 25%   24C    P8    14W / 250W |      1MiB / 12212MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Quadro M6000        On   | 00000000:03:00.0 Off |                  Off |\n",
      "| 25%   25C    P8    14W / 250W |      1MiB / 12212MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Quadro M6000        On   | 00000000:81:00.0 Off |                  Off |\n",
      "| 25%   27C    P8    14W / 250W |      1MiB / 12212MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Quadro M6000        On   | 00000000:82:00.0 Off |                  Off |\n",
      "| 25%   35C    P0   141W / 250W |   1145MiB / 12212MiB |     94%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    3     16293      C   /home/kim101/anaconda3/bin/python           1133MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose device that is not being used\n",
    "gpu_ids = \"2\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=gpu_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_v2(m,b,db):\n",
    "    '''\n",
    "    mask=create_mask_v2(m,b,db)  \n",
    "    '''\n",
    "    \n",
    "    M2 = b + db*(m-1)\n",
    "    mask = np.zeros((m,M2),dtype='int')\n",
    "    \n",
    "    block = np.ones(b,dtype='int')\n",
    "    ind = np.arange(b)\n",
    "    for row in range(m):\n",
    "        col = ind + row*db\n",
    "        mask[row,col] = block\n",
    "    \n",
    "    print(\n",
    "        \"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "            m, M2, (1.0-np.count_nonzero(mask)/mask.size)*100\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.spy(mask)\n",
    "    plt.show()\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silu(input):\n",
    "    return input * torch.sigmoid(input)\n",
    "class SiLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return silu(input)\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,m,M1,f):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.full = nn.Sequential(\n",
    "            nn.Linear(m,M1),\n",
    "            SiLU(),\n",
    "            nn.Linear(M1,f,bias=False)\n",
    "        )\n",
    "                \n",
    "    def forward(self, y):     \n",
    "        y = y.view(-1,m)\n",
    "        T = self.full(y)\n",
    "        T = T.squeeze()\n",
    "        \n",
    "        return T\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,f,M2,m):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.full = nn.Sequential(\n",
    "            nn.Linear(f,M2,bias=False),\n",
    "            SiLU(),\n",
    "            nn.Linear(M2,m,bias=False)\n",
    "        )\n",
    "             \n",
    "    def forward(self,T):\n",
    "        T = T.view(-1,f)\n",
    "        y = self.full(T)\n",
    "        y = y.squeeze()\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([900, 1000]) torch.Size([100, 1000])\n"
     ]
    }
   ],
   "source": [
    "# load solution snapshot\n",
    "solution_snapshot_orig = pickle.load(open(\"./data/snapshot_full.p\", \"rb\"))\n",
    "nx=1001\n",
    "nt=500\n",
    "\n",
    "# substract IC -> centered on IC\n",
    "ndata=solution_snapshot_orig.shape[0]\n",
    "nset= round(ndata/(nt+1))\n",
    "\n",
    "solution_snapshot=np.array([])\n",
    "for foo in range(nset):\n",
    "    solution_snapshot=np.append(solution_snapshot,solution_snapshot_orig[foo*(nt+1)+1:(foo+1)*(nt+1)]\\\n",
    "    -solution_snapshot_orig[foo*(nt+1)])\n",
    "\n",
    "solution_snapshot=np.reshape(solution_snapshot,(-1,nx))\n",
    "\n",
    "# solution_snapshot_tmp1 = solution_snapshot[:501]-solution_snapshot[0]\n",
    "# solution_snapshot_tmp2 = solution_snapshot[501:]-solution_snapshot[501]\n",
    "# solution_snapshot = np.vstack((solution_snapshot_tmp1[1:],solution_snapshot_tmp2[1:]))\n",
    "\n",
    "# remove BC\n",
    "solution_snapshot = solution_snapshot[:,:-1].astype('float32')\n",
    "\n",
    "# define testset and trainset indices\n",
    "test_ind = np.random.permutation(np.arange(solution_snapshot.shape[0]))[:int(0.1*solution_snapshot.shape[0])]\n",
    "train_ind = np.setdiff1d(np.arange(solution_snapshot.shape[0]),test_ind)\n",
    "\n",
    "# set trainset and testset\n",
    "trainset = solution_snapshot[train_ind]\n",
    "testset = solution_snapshot[test_ind] \n",
    "\n",
    "# set dataset\n",
    "dataset = {'train':data_utils.TensorDataset(torch.tensor(trainset)),\n",
    "           'test':data_utils.TensorDataset(torch.tensor(testset))}\n",
    "print(dataset['train'].tensors[0].shape, dataset['test'].tensors[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 1000) (100, 1000)\n"
     ]
    }
   ],
   "source": [
    "# compute dataset shapes\n",
    "dataset_shapes = {'train':trainset.shape,\n",
    "                 'test':testset.shape}\n",
    "\n",
    "print(dataset_shapes['train'],dataset_shapes['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # when inputs and targets are different e.g. Kernel PCA + Decoder\n",
    "# mapped_solution_snapshot = loadmat('./data/mapped_solution_snaphost.mat')['mapped_solution_snapshot']\n",
    "\n",
    "# mapped_trainset = mapped_solution_snapshot[train_ind]\n",
    "# mapped_testset = mapped_solution_snapshot[test_ind]\n",
    "\n",
    "# inputs = {'train':mapped_trainset,'test':mapped_testset}\n",
    "# outputs = {'train':trainset,'test':testset}\n",
    "\n",
    "# dataset = {'train':data_utils.TensorDataset(inputs['train'], targets['train']),\n",
    "#            'test':data_utils.TensorDataset(inputs['test'], targets['test'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set batch_size, number of epochs, paitience for early stop\n",
    "batch_size = 20\n",
    "num_epochs = 10000//5\n",
    "num_epochs_print = num_epochs*5//100\n",
    "early_stop_patience = num_epochs*5//50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data loaders\n",
    "train_loader = DataLoader(dataset=dataset['train'], \n",
    "                          batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(dataset=dataset['test'], \n",
    "                         batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "data_loaders = {'train':train_loader, 'test':test_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # copy trainset to cpu (if inputs~=targets, replace 0 to 1 for targets)\n",
    "# trainset_inputs = data_loaders['train'].dataset.tensors[0].to('cpu')\n",
    "# trainset_targets = data_loaders['train'].dataset.tensors[0].to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set checkpoint\n",
    "PATH = './checkpoint_v2_red-dim_{}.tar'.format(redDim)\n",
    "\n",
    "# set file name for AE\n",
    "file_name_AE_pkl=\"./model/AE_v2_swish_red-dim_{}.pkl\".format(redDim)\n",
    "file_name_AE=\"./model/AE_v2_swish_red-dim_{}.p\".format(redDim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the number of nodes in each layer\n",
    "m = 1000\n",
    "f = redDim\n",
    "b = 36\n",
    "db = 12\n",
    "M2 = b + (m-1)*db\n",
    "M1 = 2*m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in 1000 by 12024 mask: 99.70%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------checkpoint not restored--------\n",
      "\n",
      "Sparsity in 1000 by 12024 mask: 99.70%\n",
      "\n",
      "Start first training... m=1000, f=30, M1=2000, M2=12024, b=36, db=12\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "try:\n",
    "    checkpoint = torch.load(PATH, map_location=device)\n",
    "    \n",
    "    encoder = Encoder(m,M1,f).to(device)\n",
    "    decoder = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    mask = create_mask_v2(m,b,db)\n",
    "    prune.custom_from_mask(decoder.full[2], name='weight', mask=torch.tensor(mask).to(device))    \n",
    "    \n",
    "#     optimizer = torch.optim.LBFGS(list(encoder.parameters()) + list(decoder.parameters()), lr=1)\n",
    "#     scheduler = None     \n",
    "    optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "    decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    last_epoch = checkpoint['epoch']\n",
    "    loss_hist = checkpoint['loss_hist']\n",
    "    best_loss = checkpoint['best_loss']\n",
    "    early_stop_counter = checkpoint['early_stop_counter']\n",
    "    best_encoder_wts = checkpoint['best_encoder_wts']\n",
    "    best_decoder_wts = checkpoint['best_decoder_wts']\n",
    "    \n",
    "    print(\"\\n--------checkpoint restored--------\\n\")\n",
    "    \n",
    "    # compute sparsity in mask\n",
    "    mask = decoder.state_dict()['full.2.weight_mask']\n",
    "    print(\"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "        mask.shape[0], mask.shape[1], 100. * float(torch.sum(mask == 0))/ float(mask.nelement())))\n",
    "\n",
    "    # resume training\n",
    "    print(\"\")\n",
    "    print('Re-start {}th training... m={}, f={}, M1={}, M2={}, b={}, db={}'.format(\n",
    "        last_epoch+1, m, f, M1, M2, b, db))\n",
    "except:\n",
    "    encoder = Encoder(m,M1,f).to(device)\n",
    "    decoder = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    mask = create_mask_v2(m,b,db)\n",
    "    prune.custom_from_mask(decoder.full[2], name='weight', mask=torch.tensor(mask).to(device))\n",
    "\n",
    "#     optimizer = torch.optim.LBFGS(list(encoder.parameters()) + list(decoder.parameters()), lr=1)\n",
    "#     scheduler = None \n",
    "    optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    last_epoch = 0\n",
    "    loss_hist = {'train':[],'test':[]}\n",
    "    best_loss = float(\"inf\")\n",
    "    early_stop_counter = 1\n",
    "    best_encoder_wts = copy.deepcopy(encoder.state_dict())\n",
    "    best_decoder_wts = copy.deepcopy(decoder.state_dict())\n",
    "    \n",
    "    print(\"\\n--------checkpoint not restored--------\\n\")\n",
    "    \n",
    "    # compute sparsity in mask\n",
    "    mask = decoder.state_dict()['full.2.weight_mask']\n",
    "    print(\"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "        mask.shape[0], mask.shape[1], 100. * float(torch.sum(mask == 0))/ float(mask.nelement())))\n",
    "\n",
    "    # start training\n",
    "    print(\"\")\n",
    "    print('Start first training... m={}, f={}, M1={}, M2={}, b={}, db={}'.format(\n",
    "        m, f, M1, M2, b, db))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100/2000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 1.2977706016196558e-05\n",
      "test MSELoss: 1.6528396736248395e-05\n",
      "\n",
      "Epoch 200/2000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 7.085510464498333e-06\n",
      "test MSELoss: 8.771079046709929e-06\n",
      "\n",
      "Epoch 300/2000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.152850664869119e-06\n",
      "test MSELoss: 3.115940580755705e-06\n",
      "\n",
      "Epoch 400/2000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.7049601524377067e-06\n",
      "test MSELoss: 2.3770792040522793e-06\n",
      "\n",
      "Epoch 500/2000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.346292193223538e-06\n",
      "test MSELoss: 1.9081905975326663e-06\n",
      "\n",
      "Epoch 600/2000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.1216647294531868e-06\n",
      "test MSELoss: 1.5017224541225005e-06\n",
      "\n",
      "Epoch 700/2000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 8.272723031647426e-07\n",
      "test MSELoss: 1.1702370215971313e-06\n",
      "\n",
      "Epoch 800/2000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 8.089928731654557e-07\n",
      "test MSELoss: 1.1509050182212377e-06\n",
      "\n",
      "Epoch 900/2000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 7.850479120305762e-07\n",
      "test MSELoss: 1.1174717087669705e-06\n",
      "\n",
      "Epoch 1000/2000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 7.847759819570556e-07\n",
      "test MSELoss: 1.1176854513905709e-06\n",
      "\n",
      "Epoch 1037/2000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 7.847204781480994e-07\n",
      "test MSELoss: 1.1176864745721104e-06\n",
      "\n",
      "Early stopping: 1037th training complete in 0h 6m 6s\n",
      "----------\n",
      "Best train MSELoss: 7.947439826239133e-07\n",
      "Best test MSELoss: 1.1096845469182881e-06\n",
      "\n",
      "Saving after 1037th training to ./model/AE_v2_swish_red-dim_30.pkl\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "since = time.time()\n",
    "\n",
    "for epoch in range(last_epoch+1,num_epochs+1):   \n",
    "\n",
    "    if epoch%num_epochs_print == 0:\n",
    "        print()\n",
    "        if scheduler !=None:\n",
    "            print('Epoch {}/{}, Learning rate {}'.format(\n",
    "                epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "        else:\n",
    "            print('Epoch {}/{}'.format(\n",
    "                epoch, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and test phase\n",
    "    for phase in ['train', 'test']:\n",
    "        if phase == 'train':\n",
    "            encoder.train()  # Set model to training mode\n",
    "            decoder.train()  # Set model to training mode\n",
    "        else:\n",
    "            encoder.eval()   # Set model to evaluation mode\n",
    "            decoder.eval()   # Set model to evaluation mode\n",
    "            \n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Iterate over data\n",
    "        for data, in data_loaders[phase]:\n",
    "            inputs = data.to(device)\n",
    "            targets = data.to(device)\n",
    "\n",
    "            if phase == 'train':\n",
    "                if scheduler != None:\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    outputs = decoder(encoder(inputs))\n",
    "                    loss = loss_func(outputs, targets)\n",
    "\n",
    "                    # backward\n",
    "                    loss.backward()\n",
    "\n",
    "                    # optimize\n",
    "                    optimizer.step()  \n",
    "                    \n",
    "                    # add running loss\n",
    "                    running_loss += loss.item()*inputs.shape[0]\n",
    "                else:\n",
    "                    def closure():\n",
    "                        # zero the parameter gradients\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                        # forward\n",
    "                        outputs = decoder(encoder(inputs))\n",
    "                        loss = loss_func(outputs,targets)\n",
    "\n",
    "                        # backward\n",
    "                        loss.backward()\n",
    "                        return loss\n",
    "\n",
    "                    # optimize\n",
    "                    optimizer.step(closure)\n",
    "                    \n",
    "                    # add running loss\n",
    "                    with torch.set_grad_enabled(False):\n",
    "                        outputs = decoder(encoder(inputs))\n",
    "                        running_loss += loss_func(outputs,targets).item()*inputs.shape[0]\n",
    "                    \n",
    "            else:\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    outputs = decoder(encoder(inputs))\n",
    "                    running_loss += loss_func(outputs,targets).item()*inputs.shape[0]\n",
    "\n",
    "        # compute epoch loss\n",
    "        epoch_loss = running_loss / dataset_shapes[phase][0]\n",
    "        loss_hist[phase].append(epoch_loss)\n",
    "            \n",
    "        # update learning rate\n",
    "        if phase == 'train' and scheduler != None:\n",
    "            scheduler.step(epoch_loss)\n",
    "\n",
    "        if epoch%num_epochs_print == 0:\n",
    "            print('{} MSELoss: {}'.format(\n",
    "                phase, epoch_loss))\n",
    "\n",
    "    # deep copy the model\n",
    "    if loss_hist['test'][-1] < best_loss:\n",
    "        best_loss = loss_hist['test'][-1]\n",
    "        early_stop_counter = 1\n",
    "        best_encoder_wts = copy.deepcopy(encoder.state_dict())\n",
    "        best_decoder_wts = copy.deepcopy(decoder.state_dict())\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= early_stop_patience:  \n",
    "            break\n",
    "    \n",
    "    # save checkpoint every num_epoch_print\n",
    "    if epoch%num_epochs_print== 0:\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'encoder_state_dict': encoder.state_dict(),\n",
    "                    'decoder_state_dict': decoder.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss_hist': loss_hist,\n",
    "                    'best_loss': best_loss,\n",
    "                    'early_stop_counter': early_stop_counter,\n",
    "                    'best_encoder_wts': best_encoder_wts,\n",
    "                    'best_decoder_wts': best_decoder_wts,\n",
    "                    }, PATH)        \n",
    "\n",
    "print()\n",
    "print('Epoch {}/{}, Learning rate {}'\\\n",
    "      .format(epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "print('-' * 10)\n",
    "print('train MSELoss: {}'.format(loss_hist['train'][-1]))\n",
    "print('test MSELoss: {}'.format(loss_hist['test'][-1]))\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "\n",
    "# load best model weights\n",
    "encoder.load_state_dict(best_encoder_wts)\n",
    "decoder.load_state_dict(best_decoder_wts)\n",
    "\n",
    "# compute best train MSELoss\n",
    "encoder.to('cpu').eval()\n",
    "decoder.to('cpu').eval()\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    train_inputs = torch.tensor(trainset)\n",
    "    train_targets = torch.tensor(trainset)\n",
    "    train_outputs = decoder(encoder(train_inputs))\n",
    "    train_loss = loss_func(train_outputs,train_targets).item()\n",
    "\n",
    "# print out training time and best results\n",
    "print()\n",
    "if epoch < num_epochs:\n",
    "    print('Early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "else:\n",
    "    print('No early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "print('-' * 10)\n",
    "print('Best train MSELoss: {}'.format(train_loss))\n",
    "print('Best test MSELoss: {}'.format(best_loss))\n",
    "\n",
    "# save models\n",
    "print()\n",
    "print(\"Saving after {}th training to\".format(epoch),\n",
    "      file_name_AE_pkl)\n",
    "# torch.save((encoder,decoder),file_name_AE_pkl) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "checkpoint removed\n"
     ]
    }
   ],
   "source": [
    "# delete checkpoint\n",
    "try:\n",
    "    os.remove(PATH)\n",
    "    print()\n",
    "    print(\"checkpoint removed\")\n",
    "except:\n",
    "    print(\"no checkpoint exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and test loss\n",
    "plt.figure()\n",
    "plt.semilogy(loss_hist['train'])\n",
    "plt.semilogy(loss_hist['test'])\n",
    "plt.legend(['train','test'])\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load models\n",
    "# try:\n",
    "#     encoder,decoder = torch.load(file_name_AE_pkl,map_location='cpu')\n",
    "#     print(\"\\n--------model restored--------\\n\")\n",
    "# except:\n",
    "#     print(\"\\n--------model not restored--------\\n\")\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights and bias\n",
    "en_w1=encoder.full[0].weight.cpu().detach().numpy().astype('float32')\n",
    "en_b1=encoder.full[0].bias.cpu().detach().numpy().astype('float32')\n",
    "en_w2=encoder.full[2].weight.cpu().detach().numpy().astype('float32')\n",
    "\n",
    "de_w1=decoder.full[0].weight.cpu().detach().numpy().astype('float32')\n",
    "de_w2=decoder.full[2].weight.cpu().detach().numpy().astype('float32')\n",
    "\n",
    "de_w2_sp=sp.csr_matrix(de_w2,dtype='float32')\n",
    "\n",
    "de_w1T=de_w1.T\n",
    "de_w2T=de_w2.T\n",
    "\n",
    "de_w2T_sp=de_w2_sp.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy version of AE\n",
    "def sigmoid_np(input):\n",
    "    return (1.0/(1.0+np.exp(-input))).astype('float32')\n",
    "\n",
    "def encoder_np_forward(x):\n",
    "    z1 = en_w1.dot(x) + en_b1\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = en_w2.dot(a1)   \n",
    "    return y\n",
    "\n",
    "def decoder_np_forward(x):\n",
    "    z1 = de_w1.dot(x)\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = de_w2.dot(a1)  \n",
    "    return y\n",
    "\n",
    "def decoder_sp_forward(x):\n",
    "    z1 = de_w1.dot(x)\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = sp.csr_matrix.dot(de_w2_sp,a1)\n",
    "    return y\n",
    "\n",
    "def decoder_np_forward_backward(x):\n",
    "    z1 = de_w1.dot(x)\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = de_w2.dot(a1)\n",
    "\n",
    "    dout = de_w1T\n",
    "    dout = (s1 + a1*(1-s1))*dout\n",
    "    dydxT = dout.dot(de_w2T)   \n",
    "    return y,dydxT.T\n",
    "\n",
    "def decoder_sp_forward_backward(x):\n",
    "    z1 = de_w1.dot(x) \n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = sp.csr_matrix.dot(de_w2_sp,a1)\n",
    "\n",
    "    dout = de_w1T\n",
    "    dout = (s1 + a1*(1-s1))*dout\n",
    "    dydxT = sp.csr_matrix.dot(dout,de_w2T_sp)\n",
    "    return y,dydxT.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE: 8.26238669e-07\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (numpy version)\n",
    "comp_orig_data=np.zeros((nset*nt,f))\n",
    "rest_orig_data=np.zeros(solution_snapshot.shape)\n",
    "\n",
    "for k in range(nset*nt):\n",
    "    comp_orig_data[k]=encoder_np_forward(solution_snapshot[k])\n",
    "    rest_orig_data[k]=decoder_sp_forward(comp_orig_data[k])\n",
    "    \n",
    "print(\"MSELoss of AE: {:.8e}\".format(np.linalg.norm(solution_snapshot-rest_orig_data)**2/np.prod(solution_snapshot.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE: 8.26238022e-07\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (PyTorch model)\n",
    "input_data=torch.tensor(solution_snapshot)\n",
    "target_data=decoder(encoder(input_data))\n",
    "\n",
    "print(\"MSELoss of AE: {:.8e}\".format(torch.nn.functional.mse_loss(input_data,target_data).detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE (predictive case): 1.16118190e-06\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (predictive case)\n",
    "FOM_solution=pickle.load(open('./data/FOM.p','rb'))\n",
    "FOM_solution=FOM_solution.astype('float32')\n",
    "\n",
    "orig_data_FOM = FOM_solution[1:,:-1]\n",
    "ref=FOM_solution[0,:-1]\n",
    "\n",
    "input_FOM=torch.tensor(orig_data_FOM-ref)\n",
    "target_FOM=decoder(encoder(input_FOM))\n",
    "\n",
    "print(\"MSELoss of AE (predictive case): {:.8e}\"\\\n",
    "      .format(torch.nn.functional.mse_loss(input_FOM,target_FOM).detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights and bias   \n",
    "AE={'en_w1':en_w1,'en_b1':en_b1,'en_w2':en_w2,\n",
    "    'de_w1':de_w1,'de_w2':de_w2,\n",
    "    'de_w1T':de_w1T,'de_w2T':de_w2T,'de_w2_sp':de_w2_sp,'de_w2T_sp':de_w2T_sp}\n",
    "\n",
    "pickle.dump(AE,open(file_name_AE,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
