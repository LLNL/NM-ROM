{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.prune as prune\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "from scipy import sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import sys,time\n",
    "import os\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nparam=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug 21 17:19:19 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.74       Driver Version: 418.74       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro M6000        On   | 00000000:02:00.0 Off |                  Off |\n",
      "| 24%   36C    P0   149W / 250W |   1145MiB / 12212MiB |     92%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Quadro M6000        On   | 00000000:03:00.0 Off |                  Off |\n",
      "| 24%   31C    P0   134W / 250W |   1147MiB / 12212MiB |     60%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Quadro M6000        On   | 00000000:81:00.0 Off |                  Off |\n",
      "| 25%   28C    P0    62W / 250W |    340MiB / 12212MiB |      7%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Quadro M6000        On   | 00000000:82:00.0 Off |                  Off |\n",
      "| 25%   27C    P8    14W / 250W |      1MiB / 12212MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     18897      C   /home/kim101/anaconda3/bin/python           1133MiB |\n",
      "|    1     18918      C   /home/kim101/anaconda3/bin/python           1135MiB |\n",
      "|    2     18933      C   /home/kim101/anaconda3/bin/python            328MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose device that is not being used\n",
    "gpu_ids = \"3\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=gpu_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_v2(m,b,db):\n",
    "    '''\n",
    "    mask=create_mask_v2(m,b,db)  \n",
    "    '''\n",
    "    \n",
    "    M2 = b + db*(m-1)\n",
    "    mask = np.zeros((m,M2),dtype='int')\n",
    "    \n",
    "    block = np.ones(b,dtype='int')\n",
    "    ind = np.arange(b)\n",
    "    for row in range(m):\n",
    "        col = ind + row*db\n",
    "        mask[row,col] = block\n",
    "    \n",
    "    print(\n",
    "        \"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "            m, M2, (1.0-np.count_nonzero(mask)/mask.size)*100\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.spy(mask)\n",
    "    plt.show()\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silu(input):\n",
    "    return input * torch.sigmoid(input)\n",
    "class SiLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return silu(input)\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,m,M1,f):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.full = nn.Sequential(\n",
    "            nn.Linear(m,M1),\n",
    "            SiLU(),\n",
    "            nn.Linear(M1,f,bias=False)\n",
    "        )\n",
    "                \n",
    "    def forward(self, y):     \n",
    "        y = y.view(-1,m)\n",
    "        T = self.full(y)\n",
    "        T = T.squeeze()\n",
    "        \n",
    "        return T\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,f,M2,m):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.full = nn.Sequential(\n",
    "            nn.Linear(f,M2,bias=False),\n",
    "            SiLU(),\n",
    "            nn.Linear(M2,m,bias=False)\n",
    "        )\n",
    "             \n",
    "    def forward(self,T):\n",
    "        T = T.view(-1,f)\n",
    "        y = self.full(T)\n",
    "        y = y.squeeze()\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4500, 1000]) torch.Size([500, 1000])\n"
     ]
    }
   ],
   "source": [
    "# load solution snapshot\n",
    "solution_snapshot_orig = pickle.load(open(\"./data/snapshot_full_nparam_{}.p\".format(nparam), \"rb\"))\n",
    "nx=1001\n",
    "nt=500\n",
    "\n",
    "# substract IC -> centered on IC\n",
    "ndata=solution_snapshot_orig.shape[0]\n",
    "nset= round(ndata/(nt+1))\n",
    "\n",
    "solution_snapshot=np.array([])\n",
    "for foo in range(nset):\n",
    "    solution_snapshot=np.append(solution_snapshot,solution_snapshot_orig[foo*(nt+1)+1:(foo+1)*(nt+1)]\\\n",
    "    -solution_snapshot_orig[foo*(nt+1)])\n",
    "\n",
    "solution_snapshot=np.reshape(solution_snapshot,(-1,nx))\n",
    "\n",
    "# remove BC\n",
    "solution_snapshot = solution_snapshot[:,:-1].astype('float32')\n",
    "\n",
    "# define testset and trainset indices\n",
    "test_ind = np.random.permutation(np.arange(solution_snapshot.shape[0]))[:int(0.1*solution_snapshot.shape[0])]\n",
    "train_ind = np.setdiff1d(np.arange(solution_snapshot.shape[0]),test_ind)\n",
    "\n",
    "# set trainset and testset\n",
    "trainset = solution_snapshot[train_ind]\n",
    "testset = solution_snapshot[test_ind] \n",
    "\n",
    "# set dataset\n",
    "dataset = {'train':data_utils.TensorDataset(torch.tensor(trainset)),\n",
    "           'test':data_utils.TensorDataset(torch.tensor(testset))}\n",
    "print(dataset['train'].tensors[0].shape, dataset['test'].tensors[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 1000) (500, 1000)\n"
     ]
    }
   ],
   "source": [
    "# compute dataset shapes\n",
    "dataset_shapes = {'train':trainset.shape,\n",
    "                 'test':testset.shape}\n",
    "\n",
    "print(dataset_shapes['train'],dataset_shapes['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # when inputs and targets are different e.g. Kernel PCA + Decoder\n",
    "# mapped_solution_snapshot = loadmat('./data/mapped_solution_snaphost.mat')['mapped_solution_snapshot']\n",
    "\n",
    "# mapped_trainset = mapped_solution_snapshot[train_ind]\n",
    "# mapped_testset = mapped_solution_snapshot[test_ind]\n",
    "\n",
    "# inputs = {'train':mapped_trainset,'test':mapped_testset}\n",
    "# outputs = {'train':trainset,'test':testset}\n",
    "\n",
    "# dataset = {'train':data_utils.TensorDataset(inputs['train'], targets['train']),\n",
    "#            'test':data_utils.TensorDataset(inputs['test'], targets['test'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set batch_size, number of epochs, paitience for early stop\n",
    "batch_size = 20*nparam\n",
    "num_epochs = 10000//5\n",
    "num_epochs_print = num_epochs*5//100\n",
    "early_stop_patience = num_epochs*5//50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data loaders\n",
    "train_loader = DataLoader(dataset=dataset['train'], \n",
    "                          batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(dataset=dataset['test'], \n",
    "                         batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "data_loaders = {'train':train_loader, 'test':test_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # copy trainset to cpu (if inputs~=targets, replace 0 to 1 for targets)\n",
    "# trainset_inputs = data_loaders['train'].dataset.tensors[0].to('cpu')\n",
    "# trainset_targets = data_loaders['train'].dataset.tensors[0].to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set checkpoint\n",
    "PATH = './checkpoint_v2_nparam_{}.tar'.format(nparam)\n",
    "\n",
    "# set file name for AE\n",
    "file_name_AE_pkl=\"./model/AE_v2_swish_nparam_{}.pkl\".format(nparam)\n",
    "file_name_AE=\"./model/AE_v2_swish_nparam_{}.p\".format(nparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the number of nodes in each layer\n",
    "m = 1000\n",
    "f = 5\n",
    "b = 36\n",
    "db = 12\n",
    "M2 = b + (m-1)*db\n",
    "M1 = 2*m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in 1000 by 12024 mask: 99.70%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------checkpoint not restored--------\n",
      "\n",
      "Sparsity in 1000 by 12024 mask: 99.70%\n",
      "\n",
      "Start first training... m=1000, f=5, M1=2000, M2=12024, b=36, db=12\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "try:\n",
    "    checkpoint = torch.load(PATH, map_location=device)\n",
    "    \n",
    "    encoder = Encoder(m,M1,f).to(device)\n",
    "    decoder = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    mask = create_mask_v2(m,b,db)\n",
    "    prune.custom_from_mask(decoder.full[2], name='weight', mask=torch.tensor(mask).to(device))    \n",
    "    \n",
    "#     optimizer = torch.optim.LBFGS(list(encoder.parameters()) + list(decoder.parameters()), lr=1)\n",
    "#     scheduler = None     \n",
    "    optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "    decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    last_epoch = checkpoint['epoch']\n",
    "    loss_hist = checkpoint['loss_hist']\n",
    "    best_loss = checkpoint['best_loss']\n",
    "    early_stop_counter = checkpoint['early_stop_counter']\n",
    "    best_encoder_wts = checkpoint['best_encoder_wts']\n",
    "    best_decoder_wts = checkpoint['best_decoder_wts']\n",
    "    \n",
    "    print(\"\\n--------checkpoint restored--------\\n\")\n",
    "    \n",
    "    # compute sparsity in mask\n",
    "    mask = decoder.state_dict()['full.2.weight_mask']\n",
    "    print(\"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "        mask.shape[0], mask.shape[1], 100. * float(torch.sum(mask == 0))/ float(mask.nelement())))\n",
    "\n",
    "    # resume training\n",
    "    print(\"\")\n",
    "    print('Re-start {}th training... m={}, f={}, M1={}, M2={}, b={}, db={}'.format(\n",
    "        last_epoch+1, m, f, M1, M2, b, db))\n",
    "except:\n",
    "    encoder = Encoder(m,M1,f).to(device)\n",
    "    decoder = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    mask = create_mask_v2(m,b,db)\n",
    "    prune.custom_from_mask(decoder.full[2], name='weight', mask=torch.tensor(mask).to(device))\n",
    "\n",
    "#     optimizer = torch.optim.LBFGS(list(encoder.parameters()) + list(decoder.parameters()), lr=1)\n",
    "#     scheduler = None \n",
    "    optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    last_epoch = 0\n",
    "    loss_hist = {'train':[],'test':[]}\n",
    "    best_loss = float(\"inf\")\n",
    "    early_stop_counter = 1\n",
    "    best_encoder_wts = copy.deepcopy(encoder.state_dict())\n",
    "    best_decoder_wts = copy.deepcopy(decoder.state_dict())\n",
    "    \n",
    "    print(\"\\n--------checkpoint not restored--------\\n\")\n",
    "    \n",
    "    # compute sparsity in mask\n",
    "    mask = decoder.state_dict()['full.2.weight_mask']\n",
    "    print(\"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "        mask.shape[0], mask.shape[1], 100. * float(torch.sum(mask == 0))/ float(mask.nelement())))\n",
    "\n",
    "    # start training\n",
    "    print(\"\")\n",
    "    print('Start first training... m={}, f={}, M1={}, M2={}, b={}, db={}'.format(\n",
    "        m, f, M1, M2, b, db))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100/2000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 1.3819438875846874e-05\n",
      "test MSELoss: 1.2968877308594529e-05\n",
      "\n",
      "Epoch 200/2000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 1.1178559685100076e-05\n",
      "test MSELoss: 1.0547551028139424e-05\n",
      "\n",
      "Epoch 300/2000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 9.184781972888028e-06\n",
      "test MSELoss: 8.606622213847003e-06\n",
      "\n",
      "Epoch 400/2000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 7.160447340639722e-06\n",
      "test MSELoss: 7.230906339827925e-06\n",
      "\n",
      "Epoch 500/2000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 6.006798260690023e-06\n",
      "test MSELoss: 5.58433357582544e-06\n",
      "\n",
      "Epoch 600/2000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 5.980479747651972e-06\n",
      "test MSELoss: 5.552609945880249e-06\n",
      "\n",
      "Epoch 700/2000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 5.928431720450236e-06\n",
      "test MSELoss: 5.511159724846948e-06\n",
      "\n",
      "Epoch 800/2000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 5.88012542519007e-06\n",
      "test MSELoss: 5.460157353809336e-06\n",
      "\n",
      "Epoch 900/2000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 5.830997542943805e-06\n",
      "test MSELoss: 5.4208843721426095e-06\n",
      "\n",
      "Epoch 1000/2000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 5.786008781190807e-06\n",
      "test MSELoss: 5.389110719988821e-06\n",
      "\n",
      "Epoch 1100/2000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 5.737946877262503e-06\n",
      "test MSELoss: 5.331066859071143e-06\n",
      "\n",
      "Epoch 1200/2000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 5.689345380233135e-06\n",
      "test MSELoss: 5.286674058879725e-06\n",
      "\n",
      "Epoch 1300/2000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 5.644199558850637e-06\n",
      "test MSELoss: 5.243276791588869e-06\n",
      "\n",
      "Epoch 1400/2000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 5.599880781422447e-06\n",
      "test MSELoss: 5.201125986786792e-06\n",
      "\n",
      "Epoch 1500/2000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 5.558449477878942e-06\n",
      "test MSELoss: 5.160825730854413e-06\n",
      "\n",
      "Epoch 1600/2000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 5.511756282632834e-06\n",
      "test MSELoss: 5.123080518387723e-06\n",
      "\n",
      "Epoch 1700/2000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 5.473289921711613e-06\n",
      "test MSELoss: 5.080239498056472e-06\n",
      "\n",
      "Epoch 1800/2000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 5.424881793361338e-06\n",
      "test MSELoss: 5.041987697040895e-06\n",
      "\n",
      "Epoch 1900/2000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 5.387049956577054e-06\n",
      "test MSELoss: 5.00636824654066e-06\n",
      "\n",
      "Epoch 2000/2000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 5.3439788239807565e-06\n",
      "test MSELoss: 4.970611462340457e-06\n",
      "\n",
      "Epoch 2000/2000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 5.3439788239807565e-06\n",
      "test MSELoss: 4.970611462340457e-06\n",
      "\n",
      "No early stopping: 2000th training complete in 0h 9m 49s\n",
      "----------\n",
      "Best train MSELoss: 5.3402691264636815e-06\n",
      "Best test MSELoss: 4.966937194694765e-06\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "since = time.time()\n",
    "\n",
    "for epoch in range(last_epoch+1,num_epochs+1):   \n",
    "\n",
    "    if epoch%num_epochs_print == 0:\n",
    "        print()\n",
    "        if scheduler !=None:\n",
    "            print('Epoch {}/{}, Learning rate {}'.format(\n",
    "                epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "        else:\n",
    "            print('Epoch {}/{}'.format(\n",
    "                epoch, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and test phase\n",
    "    for phase in ['train', 'test']:\n",
    "        if phase == 'train':\n",
    "            encoder.train()  # Set model to training mode\n",
    "            decoder.train()  # Set model to training mode\n",
    "        else:\n",
    "            encoder.eval()   # Set model to evaluation mode\n",
    "            decoder.eval()   # Set model to evaluation mode\n",
    "            \n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Iterate over data\n",
    "        for data, in data_loaders[phase]:\n",
    "            inputs = data.to(device)\n",
    "            targets = data.to(device)\n",
    "\n",
    "            if phase == 'train':\n",
    "                if scheduler != None:\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    outputs = decoder(encoder(inputs))\n",
    "                    loss = loss_func(outputs, targets)\n",
    "\n",
    "                    # backward\n",
    "                    loss.backward()\n",
    "\n",
    "                    # optimize\n",
    "                    optimizer.step()  \n",
    "                    \n",
    "                    # add running loss\n",
    "                    running_loss += loss.item()*inputs.shape[0]\n",
    "                else:\n",
    "                    def closure():\n",
    "                        # zero the parameter gradients\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                        # forward\n",
    "                        outputs = decoder(encoder(inputs))\n",
    "                        loss = loss_func(outputs,targets)\n",
    "\n",
    "                        # backward\n",
    "                        loss.backward()\n",
    "                        return loss\n",
    "\n",
    "                    # optimize\n",
    "                    optimizer.step(closure)\n",
    "                    \n",
    "                    # add running loss\n",
    "                    with torch.set_grad_enabled(False):\n",
    "                        outputs = decoder(encoder(inputs))\n",
    "                        running_loss += loss_func(outputs,targets).item()*inputs.shape[0]\n",
    "                    \n",
    "            else:\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    outputs = decoder(encoder(inputs))\n",
    "                    running_loss += loss_func(outputs,targets).item()*inputs.shape[0]\n",
    "\n",
    "        # compute epoch loss\n",
    "        epoch_loss = running_loss / dataset_shapes[phase][0]\n",
    "        loss_hist[phase].append(epoch_loss)\n",
    "            \n",
    "        # update learning rate\n",
    "        if phase == 'train' and scheduler != None:\n",
    "            scheduler.step(epoch_loss)\n",
    "\n",
    "        if epoch%num_epochs_print == 0:\n",
    "            print('{} MSELoss: {}'.format(\n",
    "                phase, epoch_loss))\n",
    "\n",
    "    # deep copy the model\n",
    "    if loss_hist['test'][-1] < best_loss:\n",
    "        best_loss = loss_hist['test'][-1]\n",
    "        early_stop_counter = 1\n",
    "        best_encoder_wts = copy.deepcopy(encoder.state_dict())\n",
    "        best_decoder_wts = copy.deepcopy(decoder.state_dict())\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= early_stop_patience:  \n",
    "            break\n",
    "    \n",
    "    # save checkpoint every num_epoch_print\n",
    "    if epoch%num_epochs_print== 0:\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'encoder_state_dict': encoder.state_dict(),\n",
    "                    'decoder_state_dict': decoder.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss_hist': loss_hist,\n",
    "                    'best_loss': best_loss,\n",
    "                    'early_stop_counter': early_stop_counter,\n",
    "                    'best_encoder_wts': best_encoder_wts,\n",
    "                    'best_decoder_wts': best_decoder_wts,\n",
    "                    }, PATH)        \n",
    "\n",
    "print()\n",
    "print('Epoch {}/{}, Learning rate {}'\\\n",
    "      .format(epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "print('-' * 10)\n",
    "print('train MSELoss: {}'.format(loss_hist['train'][-1]))\n",
    "print('test MSELoss: {}'.format(loss_hist['test'][-1]))\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "\n",
    "# load best model weights\n",
    "encoder.load_state_dict(best_encoder_wts)\n",
    "decoder.load_state_dict(best_decoder_wts)\n",
    "\n",
    "# compute best train MSELoss\n",
    "encoder.to('cpu').eval()\n",
    "decoder.to('cpu').eval()\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    train_inputs = torch.tensor(trainset)\n",
    "    train_targets = torch.tensor(trainset)\n",
    "    train_outputs = decoder(encoder(train_inputs))\n",
    "    train_loss = loss_func(train_outputs,train_targets).item()\n",
    "\n",
    "# print out training time and best results\n",
    "print()\n",
    "if epoch < num_epochs:\n",
    "    print('Early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "else:\n",
    "    print('No early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "print('-' * 10)\n",
    "print('Best train MSELoss: {}'.format(train_loss))\n",
    "print('Best test MSELoss: {}'.format(best_loss))\n",
    "\n",
    "# save models\n",
    "# print()\n",
    "# print(\"Saving after {}th training to\".format(epoch),\n",
    "#       file_name_AE_pkl)\n",
    "# torch.save((encoder,decoder),file_name_AE_pkl) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "checkpoint removed\n"
     ]
    }
   ],
   "source": [
    "# delete checkpoint\n",
    "try:\n",
    "    os.remove(PATH)\n",
    "    print()\n",
    "    print(\"checkpoint removed\")\n",
    "except:\n",
    "    print(\"no checkpoint exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and test loss\n",
    "plt.figure()\n",
    "plt.semilogy(loss_hist['train'])\n",
    "plt.semilogy(loss_hist['test'])\n",
    "plt.legend(['train','test'])\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load models\n",
    "# try:\n",
    "#     encoder,decoder = torch.load(file_name_AE_pkl,map_location='cpu')\n",
    "#     print(\"\\n--------model restored--------\\n\")\n",
    "# except:\n",
    "#     print(\"\\n--------model not restored--------\\n\")\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights and bias\n",
    "en_w1=encoder.full[0].weight.cpu().detach().numpy().astype('float32')\n",
    "en_b1=encoder.full[0].bias.cpu().detach().numpy().astype('float32')\n",
    "en_w2=encoder.full[2].weight.cpu().detach().numpy().astype('float32')\n",
    "\n",
    "de_w1=decoder.full[0].weight.cpu().detach().numpy().astype('float32')\n",
    "de_w2=decoder.full[2].weight.cpu().detach().numpy().astype('float32')\n",
    "\n",
    "de_w2_sp=sp.csr_matrix(de_w2,dtype='float32')\n",
    "\n",
    "de_w1T=de_w1.T\n",
    "de_w2T=de_w2.T\n",
    "\n",
    "de_w2T_sp=de_w2_sp.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy version of AE\n",
    "def sigmoid_np(input):\n",
    "    return (1.0/(1.0+np.exp(-input))).astype('float32')\n",
    "\n",
    "def encoder_np_forward(x):\n",
    "    z1 = en_w1.dot(x) + en_b1\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = en_w2.dot(a1)   \n",
    "    return y\n",
    "\n",
    "def decoder_np_forward(x):\n",
    "    z1 = de_w1.dot(x)\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = de_w2.dot(a1)  \n",
    "    return y\n",
    "\n",
    "def decoder_sp_forward(x):\n",
    "    z1 = de_w1.dot(x)\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = sp.csr_matrix.dot(de_w2_sp,a1)\n",
    "    return y\n",
    "\n",
    "def decoder_np_forward_backward(x):\n",
    "    z1 = de_w1.dot(x)\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = de_w2.dot(a1)\n",
    "\n",
    "    dout = de_w1T\n",
    "    dout = (s1 + a1*(1-s1))*dout\n",
    "    dydxT = dout.dot(de_w2T)   \n",
    "    return y,dydxT.T\n",
    "\n",
    "def decoder_sp_forward_backward(x):\n",
    "    z1 = de_w1.dot(x) \n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = sp.csr_matrix.dot(de_w2_sp,a1)\n",
    "\n",
    "    dout = de_w1T\n",
    "    dout = (s1 + a1*(1-s1))*dout\n",
    "    dydxT = sp.csr_matrix.dot(dout,de_w2T_sp)\n",
    "    return y,dydxT.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE: 5.30296927e-06\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (numpy version)\n",
    "comp_orig_data=np.zeros((nset*nt,f))\n",
    "rest_orig_data=np.zeros(solution_snapshot.shape)\n",
    "\n",
    "for k in range(nset*nt):\n",
    "    comp_orig_data[k]=encoder_np_forward(solution_snapshot[k])\n",
    "    rest_orig_data[k]=decoder_sp_forward(comp_orig_data[k])\n",
    "    \n",
    "print(\"MSELoss of AE: {:.8e}\".format(np.linalg.norm(solution_snapshot-rest_orig_data)**2/np.prod(solution_snapshot.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE: 5.30292346e-06\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (PyTorch model)\n",
    "input_data=torch.tensor(solution_snapshot)\n",
    "target_data=decoder(encoder(input_data))\n",
    "\n",
    "print(\"MSELoss of AE: {:.8e}\".format(torch.nn.functional.mse_loss(input_data,target_data).detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE (predictive case): 7.47565991e-07\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (predictive case)\n",
    "FOM_solution=pickle.load(open('./data/FOM.p','rb'))\n",
    "FOM_solution=FOM_solution.astype('float32')\n",
    "\n",
    "orig_data_FOM = FOM_solution[1:,:-1]\n",
    "ref=FOM_solution[0,:-1]\n",
    "\n",
    "input_FOM=torch.tensor(orig_data_FOM-ref)\n",
    "target_FOM=decoder(encoder(input_FOM))\n",
    "\n",
    "print(\"MSELoss of AE (predictive case): {:.8e}\"\\\n",
    "      .format(torch.nn.functional.mse_loss(input_FOM,target_FOM).detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights and bias   \n",
    "AE={'en_w1':en_w1,'en_b1':en_b1,'en_w2':en_w2,\n",
    "    'de_w1':de_w1,'de_w2':de_w2,\n",
    "    'de_w1T':de_w1T,'de_w2T':de_w2T,'de_w2_sp':de_w2_sp,'de_w2T_sp':de_w2T_sp}\n",
    "\n",
    "pickle.dump(AE,open(file_name_AE,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
