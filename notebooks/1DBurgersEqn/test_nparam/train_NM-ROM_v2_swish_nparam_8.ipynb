{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.prune as prune\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "from scipy import sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import sys,time\n",
    "import os\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nparam=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Aug 21 17:19:17 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.74       Driver Version: 418.74       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro M6000        On   | 00000000:02:00.0 Off |                  Off |\n",
      "| 25%   33C    P0   106W / 250W |   1143MiB / 12212MiB |     40%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Quadro M6000        On   | 00000000:03:00.0 Off |                  Off |\n",
      "| 25%   27C    P0    61W / 250W |    209MiB / 12212MiB |      8%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Quadro M6000        On   | 00000000:81:00.0 Off |                  Off |\n",
      "| 26%   27C    P8    14W / 250W |      1MiB / 12212MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Quadro M6000        On   | 00000000:82:00.0 Off |                  Off |\n",
      "| 25%   27C    P8    14W / 250W |      1MiB / 12212MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|    0     18897      C   /home/kim101/anaconda3/bin/python           1131MiB |\n",
      "|    1     18918      C   /home/kim101/anaconda3/bin/python            199MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose device that is not being used\n",
    "gpu_ids = \"2\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=gpu_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_v2(m,b,db):\n",
    "    '''\n",
    "    mask=create_mask_v2(m,b,db)  \n",
    "    '''\n",
    "    \n",
    "    M2 = b + db*(m-1)\n",
    "    mask = np.zeros((m,M2),dtype='int')\n",
    "    \n",
    "    block = np.ones(b,dtype='int')\n",
    "    ind = np.arange(b)\n",
    "    for row in range(m):\n",
    "        col = ind + row*db\n",
    "        mask[row,col] = block\n",
    "    \n",
    "    print(\n",
    "        \"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "            m, M2, (1.0-np.count_nonzero(mask)/mask.size)*100\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.spy(mask)\n",
    "    plt.show()\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silu(input):\n",
    "    return input * torch.sigmoid(input)\n",
    "class SiLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return silu(input)\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,m,M1,f):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.full = nn.Sequential(\n",
    "            nn.Linear(m,M1),\n",
    "            SiLU(),\n",
    "            nn.Linear(M1,f,bias=False)\n",
    "        )\n",
    "                \n",
    "    def forward(self, y):     \n",
    "        y = y.view(-1,m)\n",
    "        T = self.full(y)\n",
    "        T = T.squeeze()\n",
    "        \n",
    "        return T\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,f,M2,m):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.full = nn.Sequential(\n",
    "            nn.Linear(f,M2,bias=False),\n",
    "            SiLU(),\n",
    "            nn.Linear(M2,m,bias=False)\n",
    "        )\n",
    "             \n",
    "    def forward(self,T):\n",
    "        T = T.view(-1,f)\n",
    "        y = self.full(T)\n",
    "        y = y.squeeze()\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3600, 1000]) torch.Size([400, 1000])\n"
     ]
    }
   ],
   "source": [
    "# load solution snapshot\n",
    "solution_snapshot_orig = pickle.load(open(\"./data/snapshot_full_nparam_{}.p\".format(nparam), \"rb\"))\n",
    "nx=1001\n",
    "nt=500\n",
    "\n",
    "# substract IC -> centered on IC\n",
    "ndata=solution_snapshot_orig.shape[0]\n",
    "nset= round(ndata/(nt+1))\n",
    "\n",
    "solution_snapshot=np.array([])\n",
    "for foo in range(nset):\n",
    "    solution_snapshot=np.append(solution_snapshot,solution_snapshot_orig[foo*(nt+1)+1:(foo+1)*(nt+1)]\\\n",
    "    -solution_snapshot_orig[foo*(nt+1)])\n",
    "\n",
    "solution_snapshot=np.reshape(solution_snapshot,(-1,nx))\n",
    "\n",
    "# remove BC\n",
    "solution_snapshot = solution_snapshot[:,:-1].astype('float32')\n",
    "\n",
    "# define testset and trainset indices\n",
    "test_ind = np.random.permutation(np.arange(solution_snapshot.shape[0]))[:int(0.1*solution_snapshot.shape[0])]\n",
    "train_ind = np.setdiff1d(np.arange(solution_snapshot.shape[0]),test_ind)\n",
    "\n",
    "# set trainset and testset\n",
    "trainset = solution_snapshot[train_ind]\n",
    "testset = solution_snapshot[test_ind] \n",
    "\n",
    "# set dataset\n",
    "dataset = {'train':data_utils.TensorDataset(torch.tensor(trainset)),\n",
    "           'test':data_utils.TensorDataset(torch.tensor(testset))}\n",
    "print(dataset['train'].tensors[0].shape, dataset['test'].tensors[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3600, 1000) (400, 1000)\n"
     ]
    }
   ],
   "source": [
    "# compute dataset shapes\n",
    "dataset_shapes = {'train':trainset.shape,\n",
    "                 'test':testset.shape}\n",
    "\n",
    "print(dataset_shapes['train'],dataset_shapes['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # when inputs and targets are different e.g. Kernel PCA + Decoder\n",
    "# mapped_solution_snapshot = loadmat('./data/mapped_solution_snaphost.mat')['mapped_solution_snapshot']\n",
    "\n",
    "# mapped_trainset = mapped_solution_snapshot[train_ind]\n",
    "# mapped_testset = mapped_solution_snapshot[test_ind]\n",
    "\n",
    "# inputs = {'train':mapped_trainset,'test':mapped_testset}\n",
    "# outputs = {'train':trainset,'test':testset}\n",
    "\n",
    "# dataset = {'train':data_utils.TensorDataset(inputs['train'], targets['train']),\n",
    "#            'test':data_utils.TensorDataset(inputs['test'], targets['test'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set batch_size, number of epochs, paitience for early stop\n",
    "batch_size = 20*nparam\n",
    "num_epochs = 10000//5\n",
    "num_epochs_print = num_epochs*5//100\n",
    "early_stop_patience = num_epochs*5//50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data loaders\n",
    "train_loader = DataLoader(dataset=dataset['train'], \n",
    "                          batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(dataset=dataset['test'], \n",
    "                         batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "data_loaders = {'train':train_loader, 'test':test_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # copy trainset to cpu (if inputs~=targets, replace 0 to 1 for targets)\n",
    "# trainset_inputs = data_loaders['train'].dataset.tensors[0].to('cpu')\n",
    "# trainset_targets = data_loaders['train'].dataset.tensors[0].to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set checkpoint\n",
    "PATH = './checkpoint_v2_nparam_{}.tar'.format(nparam)\n",
    "\n",
    "# set file name for AE\n",
    "file_name_AE_pkl=\"./model/AE_v2_swish_nparam_{}.pkl\".format(nparam)\n",
    "file_name_AE=\"./model/AE_v2_swish_nparam_{}.p\".format(nparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the number of nodes in each layer\n",
    "m = 1000\n",
    "f = 5\n",
    "b = 36\n",
    "db = 12\n",
    "M2 = b + (m-1)*db\n",
    "M1 = 2*m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in 1000 by 12024 mask: 99.70%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------checkpoint not restored--------\n",
      "\n",
      "Sparsity in 1000 by 12024 mask: 99.70%\n",
      "\n",
      "Start first training... m=1000, f=5, M1=2000, M2=12024, b=36, db=12\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "try:\n",
    "    checkpoint = torch.load(PATH, map_location=device)\n",
    "    \n",
    "    encoder = Encoder(m,M1,f).to(device)\n",
    "    decoder = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    mask = create_mask_v2(m,b,db)\n",
    "    prune.custom_from_mask(decoder.full[2], name='weight', mask=torch.tensor(mask).to(device))    \n",
    "    \n",
    "#     optimizer = torch.optim.LBFGS(list(encoder.parameters()) + list(decoder.parameters()), lr=1)\n",
    "#     scheduler = None     \n",
    "    optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "    decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    last_epoch = checkpoint['epoch']\n",
    "    loss_hist = checkpoint['loss_hist']\n",
    "    best_loss = checkpoint['best_loss']\n",
    "    early_stop_counter = checkpoint['early_stop_counter']\n",
    "    best_encoder_wts = checkpoint['best_encoder_wts']\n",
    "    best_decoder_wts = checkpoint['best_decoder_wts']\n",
    "    \n",
    "    print(\"\\n--------checkpoint restored--------\\n\")\n",
    "    \n",
    "    # compute sparsity in mask\n",
    "    mask = decoder.state_dict()['full.2.weight_mask']\n",
    "    print(\"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "        mask.shape[0], mask.shape[1], 100. * float(torch.sum(mask == 0))/ float(mask.nelement())))\n",
    "\n",
    "    # resume training\n",
    "    print(\"\")\n",
    "    print('Re-start {}th training... m={}, f={}, M1={}, M2={}, b={}, db={}'.format(\n",
    "        last_epoch+1, m, f, M1, M2, b, db))\n",
    "except:\n",
    "    encoder = Encoder(m,M1,f).to(device)\n",
    "    decoder = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    mask = create_mask_v2(m,b,db)\n",
    "    prune.custom_from_mask(decoder.full[2], name='weight', mask=torch.tensor(mask).to(device))\n",
    "\n",
    "#     optimizer = torch.optim.LBFGS(list(encoder.parameters()) + list(decoder.parameters()), lr=1)\n",
    "#     scheduler = None \n",
    "    optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    last_epoch = 0\n",
    "    loss_hist = {'train':[],'test':[]}\n",
    "    best_loss = float(\"inf\")\n",
    "    early_stop_counter = 1\n",
    "    best_encoder_wts = copy.deepcopy(encoder.state_dict())\n",
    "    best_decoder_wts = copy.deepcopy(decoder.state_dict())\n",
    "    \n",
    "    print(\"\\n--------checkpoint not restored--------\\n\")\n",
    "    \n",
    "    # compute sparsity in mask\n",
    "    mask = decoder.state_dict()['full.2.weight_mask']\n",
    "    print(\"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "        mask.shape[0], mask.shape[1], 100. * float(torch.sum(mask == 0))/ float(mask.nelement())))\n",
    "\n",
    "    # start training\n",
    "    print(\"\")\n",
    "    print('Start first training... m={}, f={}, M1={}, M2={}, b={}, db={}'.format(\n",
    "        m, f, M1, M2, b, db))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100/2000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 1.309974530967237e-05\n",
      "test MSELoss: 1.4280452342063655e-05\n",
      "\n",
      "Epoch 200/2000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 1.0798827841224718e-05\n",
      "test MSELoss: 1.191948031191714e-05\n",
      "\n",
      "Epoch 300/2000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 8.490155737995843e-06\n",
      "test MSELoss: 9.88917763606878e-06\n",
      "\n",
      "Epoch 400/2000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 6.197916445671581e-06\n",
      "test MSELoss: 7.347945484070806e-06\n",
      "\n",
      "Epoch 500/2000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 5.905627666733279e-06\n",
      "test MSELoss: 7.0306156885635575e-06\n",
      "\n",
      "Epoch 600/2000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 5.557723559629974e-06\n",
      "test MSELoss: 6.637319620494963e-06\n",
      "\n",
      "Epoch 700/2000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 5.2046726523258254e-06\n",
      "test MSELoss: 6.271523488976527e-06\n",
      "\n",
      "Epoch 800/2000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 4.908756505351954e-06\n",
      "test MSELoss: 5.935048011451727e-06\n",
      "\n",
      "Epoch 900/2000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 4.600870134810167e-06\n",
      "test MSELoss: 5.598628195002675e-06\n",
      "\n",
      "Epoch 1000/2000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 4.3520869945091865e-06\n",
      "test MSELoss: 5.289982982503716e-06\n",
      "\n",
      "Epoch 1100/2000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 4.092363279697667e-06\n",
      "test MSELoss: 5.022787354391766e-06\n",
      "\n",
      "Epoch 1200/2000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 3.8828268972995125e-06\n",
      "test MSELoss: 4.7805579015403055e-06\n",
      "\n",
      "Epoch 1300/2000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 3.6657282483550566e-06\n",
      "test MSELoss: 4.513179919740651e-06\n",
      "\n",
      "Epoch 1400/2000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 3.4800108096533223e-06\n",
      "test MSELoss: 4.287003048375482e-06\n",
      "\n",
      "Epoch 1500/2000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 3.3218306978394846e-06\n",
      "test MSELoss: 4.094494443052099e-06\n",
      "\n",
      "Epoch 1600/2000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 3.2143066669555587e-06\n",
      "test MSELoss: 3.98240890717716e-06\n",
      "\n",
      "Epoch 1700/2000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 3.1923761626886618e-06\n",
      "test MSELoss: 3.95609786210116e-06\n",
      "\n",
      "Epoch 1800/2000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 3.177660937581095e-06\n",
      "test MSELoss: 3.946836295654066e-06\n",
      "\n",
      "Epoch 1900/2000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 3.177507243081992e-06\n",
      "test MSELoss: 3.946371998608811e-06\n",
      "\n",
      "Epoch 2000/2000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 3.1773254502493528e-06\n",
      "test MSELoss: 3.946262859244598e-06\n",
      "\n",
      "Epoch 2000/2000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 3.1773254502493528e-06\n",
      "test MSELoss: 3.946262859244598e-06\n",
      "\n",
      "No early stopping: 2000th training complete in 0h 9m 16s\n",
      "----------\n",
      "Best train MSELoss: 3.1773154205438914e-06\n",
      "Best test MSELoss: 3.94614339711552e-06\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "since = time.time()\n",
    "\n",
    "for epoch in range(last_epoch+1,num_epochs+1):   \n",
    "\n",
    "    if epoch%num_epochs_print == 0:\n",
    "        print()\n",
    "        if scheduler !=None:\n",
    "            print('Epoch {}/{}, Learning rate {}'.format(\n",
    "                epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "        else:\n",
    "            print('Epoch {}/{}'.format(\n",
    "                epoch, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and test phase\n",
    "    for phase in ['train', 'test']:\n",
    "        if phase == 'train':\n",
    "            encoder.train()  # Set model to training mode\n",
    "            decoder.train()  # Set model to training mode\n",
    "        else:\n",
    "            encoder.eval()   # Set model to evaluation mode\n",
    "            decoder.eval()   # Set model to evaluation mode\n",
    "            \n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Iterate over data\n",
    "        for data, in data_loaders[phase]:\n",
    "            inputs = data.to(device)\n",
    "            targets = data.to(device)\n",
    "\n",
    "            if phase == 'train':\n",
    "                if scheduler != None:\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    outputs = decoder(encoder(inputs))\n",
    "                    loss = loss_func(outputs, targets)\n",
    "\n",
    "                    # backward\n",
    "                    loss.backward()\n",
    "\n",
    "                    # optimize\n",
    "                    optimizer.step()  \n",
    "                    \n",
    "                    # add running loss\n",
    "                    running_loss += loss.item()*inputs.shape[0]\n",
    "                else:\n",
    "                    def closure():\n",
    "                        # zero the parameter gradients\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                        # forward\n",
    "                        outputs = decoder(encoder(inputs))\n",
    "                        loss = loss_func(outputs,targets)\n",
    "\n",
    "                        # backward\n",
    "                        loss.backward()\n",
    "                        return loss\n",
    "\n",
    "                    # optimize\n",
    "                    optimizer.step(closure)\n",
    "                    \n",
    "                    # add running loss\n",
    "                    with torch.set_grad_enabled(False):\n",
    "                        outputs = decoder(encoder(inputs))\n",
    "                        running_loss += loss_func(outputs,targets).item()*inputs.shape[0]\n",
    "                    \n",
    "            else:\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    outputs = decoder(encoder(inputs))\n",
    "                    running_loss += loss_func(outputs,targets).item()*inputs.shape[0]\n",
    "\n",
    "        # compute epoch loss\n",
    "        epoch_loss = running_loss / dataset_shapes[phase][0]\n",
    "        loss_hist[phase].append(epoch_loss)\n",
    "            \n",
    "        # update learning rate\n",
    "        if phase == 'train' and scheduler != None:\n",
    "            scheduler.step(epoch_loss)\n",
    "\n",
    "        if epoch%num_epochs_print == 0:\n",
    "            print('{} MSELoss: {}'.format(\n",
    "                phase, epoch_loss))\n",
    "\n",
    "    # deep copy the model\n",
    "    if loss_hist['test'][-1] < best_loss:\n",
    "        best_loss = loss_hist['test'][-1]\n",
    "        early_stop_counter = 1\n",
    "        best_encoder_wts = copy.deepcopy(encoder.state_dict())\n",
    "        best_decoder_wts = copy.deepcopy(decoder.state_dict())\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= early_stop_patience:  \n",
    "            break\n",
    "    \n",
    "    # save checkpoint every num_epoch_print\n",
    "    if epoch%num_epochs_print== 0:\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'encoder_state_dict': encoder.state_dict(),\n",
    "                    'decoder_state_dict': decoder.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss_hist': loss_hist,\n",
    "                    'best_loss': best_loss,\n",
    "                    'early_stop_counter': early_stop_counter,\n",
    "                    'best_encoder_wts': best_encoder_wts,\n",
    "                    'best_decoder_wts': best_decoder_wts,\n",
    "                    }, PATH)        \n",
    "\n",
    "print()\n",
    "print('Epoch {}/{}, Learning rate {}'\\\n",
    "      .format(epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "print('-' * 10)\n",
    "print('train MSELoss: {}'.format(loss_hist['train'][-1]))\n",
    "print('test MSELoss: {}'.format(loss_hist['test'][-1]))\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "\n",
    "# load best model weights\n",
    "encoder.load_state_dict(best_encoder_wts)\n",
    "decoder.load_state_dict(best_decoder_wts)\n",
    "\n",
    "# compute best train MSELoss\n",
    "encoder.to('cpu').eval()\n",
    "decoder.to('cpu').eval()\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    train_inputs = torch.tensor(trainset)\n",
    "    train_targets = torch.tensor(trainset)\n",
    "    train_outputs = decoder(encoder(train_inputs))\n",
    "    train_loss = loss_func(train_outputs,train_targets).item()\n",
    "\n",
    "# print out training time and best results\n",
    "print()\n",
    "if epoch < num_epochs:\n",
    "    print('Early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "else:\n",
    "    print('No early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "print('-' * 10)\n",
    "print('Best train MSELoss: {}'.format(train_loss))\n",
    "print('Best test MSELoss: {}'.format(best_loss))\n",
    "\n",
    "# save models\n",
    "# print()\n",
    "# print(\"Saving after {}th training to\".format(epoch),\n",
    "#       file_name_AE_pkl)\n",
    "# torch.save((encoder,decoder),file_name_AE_pkl) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "checkpoint removed\n"
     ]
    }
   ],
   "source": [
    "# delete checkpoint\n",
    "try:\n",
    "    os.remove(PATH)\n",
    "    print()\n",
    "    print(\"checkpoint removed\")\n",
    "except:\n",
    "    print(\"no checkpoint exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and test loss\n",
    "plt.figure()\n",
    "plt.semilogy(loss_hist['train'])\n",
    "plt.semilogy(loss_hist['test'])\n",
    "plt.legend(['train','test'])\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load models\n",
    "# try:\n",
    "#     encoder,decoder = torch.load(file_name_AE_pkl,map_location='cpu')\n",
    "#     print(\"\\n--------model restored--------\\n\")\n",
    "# except:\n",
    "#     print(\"\\n--------model not restored--------\\n\")\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights and bias\n",
    "en_w1=encoder.full[0].weight.cpu().detach().numpy().astype('float32')\n",
    "en_b1=encoder.full[0].bias.cpu().detach().numpy().astype('float32')\n",
    "en_w2=encoder.full[2].weight.cpu().detach().numpy().astype('float32')\n",
    "\n",
    "de_w1=decoder.full[0].weight.cpu().detach().numpy().astype('float32')\n",
    "de_w2=decoder.full[2].weight.cpu().detach().numpy().astype('float32')\n",
    "\n",
    "de_w2_sp=sp.csr_matrix(de_w2,dtype='float32')\n",
    "\n",
    "de_w1T=de_w1.T\n",
    "de_w2T=de_w2.T\n",
    "\n",
    "de_w2T_sp=de_w2_sp.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy version of AE\n",
    "def sigmoid_np(input):\n",
    "    return (1.0/(1.0+np.exp(-input))).astype('float32')\n",
    "\n",
    "def encoder_np_forward(x):\n",
    "    z1 = en_w1.dot(x) + en_b1\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = en_w2.dot(a1)   \n",
    "    return y\n",
    "\n",
    "def decoder_np_forward(x):\n",
    "    z1 = de_w1.dot(x)\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = de_w2.dot(a1)  \n",
    "    return y\n",
    "\n",
    "def decoder_sp_forward(x):\n",
    "    z1 = de_w1.dot(x)\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = sp.csr_matrix.dot(de_w2_sp,a1)\n",
    "    return y\n",
    "\n",
    "def decoder_np_forward_backward(x):\n",
    "    z1 = de_w1.dot(x)\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = de_w2.dot(a1)\n",
    "\n",
    "    dout = de_w1T\n",
    "    dout = (s1 + a1*(1-s1))*dout\n",
    "    dydxT = dout.dot(de_w2T)   \n",
    "    return y,dydxT.T\n",
    "\n",
    "def decoder_sp_forward_backward(x):\n",
    "    z1 = de_w1.dot(x) \n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = sp.csr_matrix.dot(de_w2_sp,a1)\n",
    "\n",
    "    dout = de_w1T\n",
    "    dout = (s1 + a1*(1-s1))*dout\n",
    "    dydxT = sp.csr_matrix.dot(dout,de_w2T_sp)\n",
    "    return y,dydxT.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE: 3.25420315e-06\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (numpy version)\n",
    "comp_orig_data=np.zeros((nset*nt,f))\n",
    "rest_orig_data=np.zeros(solution_snapshot.shape)\n",
    "\n",
    "for k in range(nset*nt):\n",
    "    comp_orig_data[k]=encoder_np_forward(solution_snapshot[k])\n",
    "    rest_orig_data[k]=decoder_sp_forward(comp_orig_data[k])\n",
    "    \n",
    "print(\"MSELoss of AE: {:.8e}\".format(np.linalg.norm(solution_snapshot-rest_orig_data)**2/np.prod(solution_snapshot.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE: 3.25419728e-06\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (PyTorch model)\n",
    "input_data=torch.tensor(solution_snapshot)\n",
    "target_data=decoder(encoder(input_data))\n",
    "\n",
    "print(\"MSELoss of AE: {:.8e}\".format(torch.nn.functional.mse_loss(input_data,target_data).detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE (predictive case): 6.37528842e-07\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (predictive case)\n",
    "FOM_solution=pickle.load(open('./data/FOM.p','rb'))\n",
    "FOM_solution=FOM_solution.astype('float32')\n",
    "\n",
    "orig_data_FOM = FOM_solution[1:,:-1]\n",
    "ref=FOM_solution[0,:-1]\n",
    "\n",
    "input_FOM=torch.tensor(orig_data_FOM-ref)\n",
    "target_FOM=decoder(encoder(input_FOM))\n",
    "\n",
    "print(\"MSELoss of AE (predictive case): {:.8e}\"\\\n",
    "      .format(torch.nn.functional.mse_loss(input_FOM,target_FOM).detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights and bias   \n",
    "AE={'en_w1':en_w1,'en_b1':en_b1,'en_w2':en_w2,\n",
    "    'de_w1':de_w1,'de_w2':de_w2,\n",
    "    'de_w1T':de_w1T,'de_w2T':de_w2T,'de_w2_sp':de_w2_sp,'de_w2T_sp':de_w2T_sp}\n",
    "\n",
    "pickle.dump(AE,open(file_name_AE,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
