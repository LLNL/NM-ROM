{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.prune as prune\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "from scipy import sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import sys,time\n",
    "import os\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Aug 18 16:52:28 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.74       Driver Version: 418.74       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro M6000        On   | 00000000:02:00.0 Off |                  Off |\n",
      "| 25%   26C    P8    14W / 250W |     12MiB / 12212MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Quadro M6000        On   | 00000000:03:00.0 Off |                  Off |\n",
      "| 25%   26C    P8    14W / 250W |     12MiB / 12212MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Quadro M6000        On   | 00000000:81:00.0 Off |                  Off |\n",
      "| 25%   28C    P8    14W / 250W |     12MiB / 12212MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Quadro M6000        On   | 00000000:82:00.0 Off |                  Off |\n",
      "| 25%   28C    P8    14W / 250W |     12MiB / 12212MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose device that is not being used\n",
    "gpu_ids = \"0\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=gpu_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_v2(m,b,db):\n",
    "    '''\n",
    "    mask=create_mask_v2(m,b,db)  \n",
    "    '''\n",
    "    \n",
    "    M2 = b + db*(m-1)\n",
    "    mask = np.zeros((m,M2),dtype='int')\n",
    "    \n",
    "    block = np.ones(b,dtype='int')\n",
    "    ind = np.arange(b)\n",
    "    for row in range(m):\n",
    "        col = ind + row*db\n",
    "        mask[row,col] = block\n",
    "    \n",
    "    print(\n",
    "        \"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "            m, M2, (1.0-np.count_nonzero(mask)/mask.size)*100\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.spy(mask)\n",
    "    plt.show()\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def silu(input):\n",
    "    return input * torch.sigmoid(input)\n",
    "class SiLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return silu(input)\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,m,M1,f):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.full = nn.Sequential(\n",
    "            nn.Linear(m,M1),\n",
    "            SiLU(),\n",
    "            nn.Linear(M1,f,bias=False)\n",
    "        )\n",
    "                \n",
    "    def forward(self, y):     \n",
    "        y = y.view(-1,m)\n",
    "        T = self.full(y)\n",
    "        T = T.squeeze()\n",
    "        \n",
    "        return T\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,f,M2,m):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.full = nn.Sequential(\n",
    "            nn.Linear(f,M2,bias=False),\n",
    "            SiLU(),\n",
    "            nn.Linear(M2,m,bias=False)\n",
    "        )\n",
    "             \n",
    "    def forward(self,T):\n",
    "        T = T.view(-1,f)\n",
    "        y = self.full(T)\n",
    "        y = y.squeeze()\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([900, 1000]) torch.Size([100, 1000])\n"
     ]
    }
   ],
   "source": [
    "# load solution snapshot\n",
    "solution_snapshot_orig = pickle.load(open(\"./data/snapshot_full.p\", \"rb\"))\n",
    "nx=1001\n",
    "nt=500\n",
    "\n",
    "# substract IC -> centered on IC\n",
    "ndata=solution_snapshot_orig.shape[0]\n",
    "nset= round(ndata/(nt+1))\n",
    "\n",
    "solution_snapshot=np.array([])\n",
    "for foo in range(nset):\n",
    "    solution_snapshot=np.append(solution_snapshot,solution_snapshot_orig[foo*(nt+1)+1:(foo+1)*(nt+1)]\\\n",
    "    -solution_snapshot_orig[foo*(nt+1)])\n",
    "\n",
    "solution_snapshot=np.reshape(solution_snapshot,(-1,nx))\n",
    "\n",
    "# solution_snapshot_tmp1 = solution_snapshot[:501]-solution_snapshot[0]\n",
    "# solution_snapshot_tmp2 = solution_snapshot[501:]-solution_snapshot[501]\n",
    "# solution_snapshot = np.vstack((solution_snapshot_tmp1[1:],solution_snapshot_tmp2[1:]))\n",
    "\n",
    "# remove BC\n",
    "solution_snapshot = solution_snapshot[:,:-1].astype('float32')\n",
    "\n",
    "# define testset and trainset indices\n",
    "test_ind = np.random.permutation(np.arange(solution_snapshot.shape[0]))[:int(0.1*solution_snapshot.shape[0])]\n",
    "train_ind = np.setdiff1d(np.arange(solution_snapshot.shape[0]),test_ind)\n",
    "\n",
    "# set trainset and testset\n",
    "trainset = solution_snapshot[train_ind]\n",
    "testset = solution_snapshot[test_ind] \n",
    "\n",
    "# set dataset\n",
    "dataset = {'train':data_utils.TensorDataset(torch.tensor(trainset)),\n",
    "           'test':data_utils.TensorDataset(torch.tensor(testset))}\n",
    "print(dataset['train'].tensors[0].shape, dataset['test'].tensors[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 1000) (100, 1000)\n"
     ]
    }
   ],
   "source": [
    "# compute dataset shapes\n",
    "dataset_shapes = {'train':trainset.shape,\n",
    "                 'test':testset.shape}\n",
    "\n",
    "print(dataset_shapes['train'],dataset_shapes['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # when inputs and targets are different e.g. Kernel PCA + Decoder\n",
    "# mapped_solution_snapshot = loadmat('./data/mapped_solution_snaphost.mat')['mapped_solution_snapshot']\n",
    "\n",
    "# mapped_trainset = mapped_solution_snapshot[train_ind]\n",
    "# mapped_testset = mapped_solution_snapshot[test_ind]\n",
    "\n",
    "# inputs = {'train':mapped_trainset,'test':mapped_testset}\n",
    "# outputs = {'train':trainset,'test':testset}\n",
    "\n",
    "# dataset = {'train':data_utils.TensorDataset(inputs['train'], targets['train']),\n",
    "#            'test':data_utils.TensorDataset(inputs['test'], targets['test'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set batch_size, number of epochs, paitience for early stop\n",
    "batch_size = 20\n",
    "num_epochs = 10000\n",
    "num_epochs_print = num_epochs//100\n",
    "early_stop_patience = num_epochs//50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data loaders\n",
    "train_loader = DataLoader(dataset=dataset['train'], \n",
    "                          batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(dataset=dataset['test'], \n",
    "                         batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "data_loaders = {'train':train_loader, 'test':test_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # copy trainset to cpu (if inputs~=targets, replace 0 to 1 for targets)\n",
    "# trainset_inputs = data_loaders['train'].dataset.tensors[0].to('cpu')\n",
    "# trainset_targets = data_loaders['train'].dataset.tensors[0].to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set checkpoint\n",
    "PATH = './checkpoint_v2.tar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the number of nodes in each layer\n",
    "m = 1000\n",
    "f = 5\n",
    "b = 36\n",
    "db = 12\n",
    "M2 = b + (m-1)*db\n",
    "M1 = 2*m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in 1000 by 12024 mask: 99.70%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------checkpoint not restored--------\n",
      "\n",
      "Sparsity in 1000 by 12024 mask: 99.70%\n",
      "\n",
      "Start first training... m=1000, f=5, M1=2000, M2=12024, b=36, db=12\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "try:\n",
    "    checkpoint = torch.load(PATH, map_location=device)\n",
    "    \n",
    "    encoder = Encoder(m,M1,f).to(device)\n",
    "    decoder = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    mask = create_mask_v2(m,b,db)\n",
    "    prune.custom_from_mask(decoder.full[2], name='weight', mask=torch.tensor(mask).to(device))    \n",
    "    \n",
    "#     optimizer = torch.optim.LBFGS(list(encoder.parameters()) + list(decoder.parameters()), lr=1)\n",
    "#     scheduler = None     \n",
    "    optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    encoder.load_state_dict(checkpoint['encoder_state_dict'])\n",
    "    decoder.load_state_dict(checkpoint['decoder_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    last_epoch = checkpoint['epoch']\n",
    "    loss_hist = checkpoint['loss_hist']\n",
    "    best_loss = checkpoint['best_loss']\n",
    "    early_stop_counter = checkpoint['early_stop_counter']\n",
    "    best_encoder_wts = checkpoint['best_encoder_wts']\n",
    "    best_decoder_wts = checkpoint['best_decoder_wts']\n",
    "    \n",
    "    print(\"\\n--------checkpoint restored--------\\n\")\n",
    "    \n",
    "    # compute sparsity in mask\n",
    "    mask = decoder.state_dict()['full.2.weight_mask']\n",
    "    print(\"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "        mask.shape[0], mask.shape[1], 100. * float(torch.sum(mask == 0))/ float(mask.nelement())))\n",
    "\n",
    "    # resume training\n",
    "    print(\"\")\n",
    "    print('Re-start {}th training... m={}, f={}, M1={}, M2={}, b={}, db={}'.format(\n",
    "        last_epoch+1, m, f, M1, M2, b, db))\n",
    "except:\n",
    "    encoder = Encoder(m,M1,f).to(device)\n",
    "    decoder = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    mask = create_mask_v2(m,b,db)\n",
    "    prune.custom_from_mask(decoder.full[2], name='weight', mask=torch.tensor(mask).to(device))\n",
    "\n",
    "#     optimizer = torch.optim.LBFGS(list(encoder.parameters()) + list(decoder.parameters()), lr=1)\n",
    "#     scheduler = None \n",
    "    optimizer = torch.optim.Adam(list(encoder.parameters()) + list(decoder.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    last_epoch = 0\n",
    "    loss_hist = {'train':[],'test':[]}\n",
    "    best_loss = float(\"inf\")\n",
    "    early_stop_counter = 1\n",
    "    best_encoder_wts = copy.deepcopy(encoder.state_dict())\n",
    "    best_decoder_wts = copy.deepcopy(decoder.state_dict())\n",
    "    \n",
    "    print(\"\\n--------checkpoint not restored--------\\n\")\n",
    "    \n",
    "    # compute sparsity in mask\n",
    "    mask = decoder.state_dict()['full.2.weight_mask']\n",
    "    print(\"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "        mask.shape[0], mask.shape[1], 100. * float(torch.sum(mask == 0))/ float(mask.nelement())))\n",
    "\n",
    "    # start training\n",
    "    print(\"\")\n",
    "    print('Start first training... m={}, f={}, M1={}, M2={}, b={}, db={}'.format(\n",
    "        m, f, M1, M2, b, db))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 2.1590965641533127e-05\n",
      "test MSELoss: 2.043002132268157e-05\n",
      "\n",
      "Epoch 200/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 1.350925176666351e-05\n",
      "test MSELoss: 1.1320119483571034e-05\n",
      "\n",
      "Epoch 300/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 8.505026471539168e-06\n",
      "test MSELoss: 8.056842671066988e-06\n",
      "\n",
      "Epoch 400/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 7.698101823431595e-06\n",
      "test MSELoss: 7.111080049071461e-06\n",
      "\n",
      "Epoch 500/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 7.008924876572565e-06\n",
      "test MSELoss: 6.428326469176682e-06\n",
      "\n",
      "Epoch 600/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 6.326588936644839e-06\n",
      "test MSELoss: 5.79579345867387e-06\n",
      "\n",
      "Epoch 700/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 5.834431724199223e-06\n",
      "test MSELoss: 5.325911388354143e-06\n",
      "\n",
      "Epoch 800/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 5.379352983759923e-06\n",
      "test MSELoss: 4.99634406878613e-06\n",
      "\n",
      "Epoch 900/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 5.001777556875216e-06\n",
      "test MSELoss: 4.607894516084343e-06\n",
      "\n",
      "Epoch 1000/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 4.4495071961137e-06\n",
      "test MSELoss: 4.139090879107243e-06\n",
      "\n",
      "Epoch 1100/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 4.4097369482187785e-06\n",
      "test MSELoss: 4.110727741135634e-06\n",
      "\n",
      "Epoch 1200/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 4.409405892147333e-06\n",
      "test MSELoss: 4.111028647457715e-06\n",
      "\n",
      "Epoch 1220/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 4.4093359216882766e-06\n",
      "test MSELoss: 4.1109447010967415e-06\n",
      "\n",
      "Early stopping: 1220th training complete in 0h 7m 1s\n",
      "----------\n",
      "Best train MSELoss: 4.411565896589309e-06\n",
      "Best test MSELoss: 4.105663447262487e-06\n",
      "\n",
      "Saving after 1220th training to ./model/AE_v2_swish.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kim101/anaconda3/lib/python3.7/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type Encoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kim101/anaconda3/lib/python3.7/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type SiLU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "/home/kim101/anaconda3/lib/python3.7/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type Decoder. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "since = time.time()\n",
    "\n",
    "for epoch in range(last_epoch+1,num_epochs+1):   \n",
    "\n",
    "    if epoch%num_epochs_print == 0:\n",
    "        print()\n",
    "        if scheduler !=None:\n",
    "            print('Epoch {}/{}, Learning rate {}'.format(\n",
    "                epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "        else:\n",
    "            print('Epoch {}/{}'.format(\n",
    "                epoch, num_epochs))\n",
    "        print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and test phase\n",
    "    for phase in ['train', 'test']:\n",
    "        if phase == 'train':\n",
    "            encoder.train()  # Set model to training mode\n",
    "            decoder.train()  # Set model to training mode\n",
    "        else:\n",
    "            encoder.eval()   # Set model to evaluation mode\n",
    "            decoder.eval()   # Set model to evaluation mode\n",
    "            \n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Iterate over data\n",
    "        for data, in data_loaders[phase]:\n",
    "            inputs = data.to(device)\n",
    "            targets = data.to(device)\n",
    "\n",
    "            if phase == 'train':\n",
    "                if scheduler != None:\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    outputs = decoder(encoder(inputs))\n",
    "                    loss = loss_func(outputs, targets)\n",
    "\n",
    "                    # backward\n",
    "                    loss.backward()\n",
    "\n",
    "                    # optimize\n",
    "                    optimizer.step()  \n",
    "                    \n",
    "                    # add running loss\n",
    "                    running_loss += loss.item()*inputs.shape[0]\n",
    "                else:\n",
    "                    def closure():\n",
    "                        # zero the parameter gradients\n",
    "                        optimizer.zero_grad()\n",
    "\n",
    "                        # forward\n",
    "                        outputs = decoder(encoder(inputs))\n",
    "                        loss = loss_func(outputs,targets)\n",
    "\n",
    "                        # backward\n",
    "                        loss.backward()\n",
    "                        return loss\n",
    "\n",
    "                    # optimize\n",
    "                    optimizer.step(closure)\n",
    "                    \n",
    "                    # add running loss\n",
    "                    with torch.set_grad_enabled(False):\n",
    "                        outputs = decoder(encoder(inputs))\n",
    "                        running_loss += loss_func(outputs,targets).item()*inputs.shape[0]\n",
    "                    \n",
    "            else:\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    outputs = decoder(encoder(inputs))\n",
    "                    running_loss += loss_func(outputs,targets).item()*inputs.shape[0]\n",
    "\n",
    "        # compute epoch loss\n",
    "        epoch_loss = running_loss / dataset_shapes[phase][0]\n",
    "        loss_hist[phase].append(epoch_loss)\n",
    "            \n",
    "        # update learning rate\n",
    "        if phase == 'train' and scheduler != None:\n",
    "            scheduler.step(epoch_loss)\n",
    "\n",
    "        if epoch%num_epochs_print == 0:\n",
    "            print('{} MSELoss: {}'.format(\n",
    "                phase, epoch_loss))\n",
    "\n",
    "    # deep copy the model\n",
    "    if loss_hist['test'][-1] < best_loss:\n",
    "        best_loss = loss_hist['test'][-1]\n",
    "        early_stop_counter = 1\n",
    "        best_encoder_wts = copy.deepcopy(encoder.state_dict())\n",
    "        best_decoder_wts = copy.deepcopy(decoder.state_dict())\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= early_stop_patience:  \n",
    "            break\n",
    "    \n",
    "    # save checkpoint every num_epoch_print\n",
    "    if epoch%num_epochs_print== 0:\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'encoder_state_dict': encoder.state_dict(),\n",
    "                    'decoder_state_dict': decoder.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss_hist': loss_hist,\n",
    "                    'best_loss': best_loss,\n",
    "                    'early_stop_counter': early_stop_counter,\n",
    "                    'best_encoder_wts': best_encoder_wts,\n",
    "                    'best_decoder_wts': best_decoder_wts,\n",
    "                    }, PATH)        \n",
    "\n",
    "print()\n",
    "print('Epoch {}/{}, Learning rate {}'\\\n",
    "      .format(epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "print('-' * 10)\n",
    "print('train MSELoss: {}'.format(loss_hist['train'][-1]))\n",
    "print('test MSELoss: {}'.format(loss_hist['test'][-1]))\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "\n",
    "# load best model weights\n",
    "encoder.load_state_dict(best_encoder_wts)\n",
    "decoder.load_state_dict(best_decoder_wts)\n",
    "\n",
    "# compute best train MSELoss\n",
    "encoder.to('cpu').eval()\n",
    "decoder.to('cpu').eval()\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    train_inputs = torch.tensor(trainset)\n",
    "    train_targets = torch.tensor(trainset)\n",
    "    train_outputs = decoder(encoder(train_inputs))\n",
    "    train_loss = loss_func(train_outputs,train_targets).item()\n",
    "\n",
    "# print out training time and best results\n",
    "print()\n",
    "if epoch < num_epochs:\n",
    "    print('Early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "else:\n",
    "    print('No early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "print('-' * 10)\n",
    "print('Best train MSELoss: {}'.format(train_loss))\n",
    "print('Best test MSELoss: {}'.format(best_loss))\n",
    "\n",
    "# save models\n",
    "print()\n",
    "print(\"Saving after {}th training to\".format(epoch),\n",
    "      \"./model/AE_v2_swish.pkl\")\n",
    "# torch.save((encoder,decoder),\"./model/AE_v2_swish.pkl\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "checkpoint removed\n"
     ]
    }
   ],
   "source": [
    "# delete checkpoint\n",
    "try:\n",
    "    os.remove(PATH)\n",
    "    print()\n",
    "    print(\"checkpoint removed\")\n",
    "except:\n",
    "    print(\"no checkpoint exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and test loss\n",
    "plt.figure()\n",
    "plt.semilogy(loss_hist['train'])\n",
    "plt.semilogy(loss_hist['test'])\n",
    "plt.legend(['train','test'])\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------model restored--------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # load models\n",
    "# try:\n",
    "#     encoder,decoder = torch.load(\"./model/AE_v2_swish.pkl\",map_location='cpu')\n",
    "#     print(\"\\n--------model restored--------\\n\")\n",
    "# except:\n",
    "#     print(\"\\n--------model not restored--------\\n\")\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights and bias\n",
    "en_w1=encoder.full[0].weight.cpu().detach().numpy().astype('float32')\n",
    "en_b1=encoder.full[0].bias.cpu().detach().numpy().astype('float32')\n",
    "en_w2=encoder.full[2].weight.cpu().detach().numpy().astype('float32')\n",
    "\n",
    "de_w1=decoder.full[0].weight.cpu().detach().numpy().astype('float32')\n",
    "de_w2=decoder.full[2].weight.cpu().detach().numpy().astype('float32')\n",
    "\n",
    "de_w2_sp=sp.csr_matrix(de_w2,dtype='float32')\n",
    "\n",
    "de_w1T=de_w1.T\n",
    "de_w2T=de_w2.T\n",
    "\n",
    "de_w2T_sp=de_w2_sp.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy version of AE\n",
    "def sigmoid_np(input):\n",
    "    return (1.0/(1.0+np.exp(-input))).astype('float32')\n",
    "\n",
    "def encoder_np_forward(x):\n",
    "    z1 = en_w1.dot(x) + en_b1\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = en_w2.dot(a1)   \n",
    "    return y\n",
    "\n",
    "def decoder_np_forward(x):\n",
    "    z1 = de_w1.dot(x)\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = de_w2.dot(a1)  \n",
    "    return y\n",
    "\n",
    "def decoder_sp_forward(x):\n",
    "    z1 = de_w1.dot(x)\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = sp.csr_matrix.dot(de_w2_sp,a1)\n",
    "    return y\n",
    "\n",
    "def decoder_np_forward_backward(x):\n",
    "    z1 = de_w1.dot(x)\n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = de_w2.dot(a1)\n",
    "\n",
    "    dout = de_w1T\n",
    "    dout = (s1 + a1*(1-s1))*dout\n",
    "    dydxT = dout.dot(de_w2T)   \n",
    "    return y,dydxT.T\n",
    "\n",
    "def decoder_sp_forward_backward(x):\n",
    "    z1 = de_w1.dot(x) \n",
    "    s1 = sigmoid_np(z1)\n",
    "    a1 = z1*s1\n",
    "    y = sp.csr_matrix.dot(de_w2_sp,a1)\n",
    "\n",
    "    dout = de_w1T\n",
    "    dout = (s1 + a1*(1-s1))*dout\n",
    "    dydxT = sp.csr_matrix.dot(dout,de_w2T_sp)\n",
    "    return y,dydxT.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE: 4.05627680e-06\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (numpy version)\n",
    "comp_orig_data=np.zeros((nset*nt,f))\n",
    "rest_orig_data=np.zeros(solution_snapshot.shape)\n",
    "\n",
    "for k in range(nset*nt):\n",
    "    comp_orig_data[k]=encoder_np_forward(solution_snapshot[k])\n",
    "    rest_orig_data[k]=decoder_sp_forward(comp_orig_data[k])\n",
    "    \n",
    "print(\"MSELoss of AE: {:.8e}\".format(np.linalg.norm(solution_snapshot-rest_orig_data)**2/np.prod(solution_snapshot.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE: 4.05722767e-06\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (PyTorch model)\n",
    "input_data=torch.tensor(solution_snapshot)\n",
    "target_data=decoder(encoder(input_data))\n",
    "\n",
    "print(\"MSELoss of AE: {:.8e}\".format(torch.nn.functional.mse_loss(input_data,target_data).detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE (predictive case): 1.83162012e-06\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (predictive case)\n",
    "FOM_solution=pickle.load(open('./data/FOM.p','rb'))\n",
    "FOM_solution=FOM_solution.astype('float32')\n",
    "\n",
    "orig_data_FOM = FOM_solution[1:,:-1]\n",
    "ref=FOM_solution[0,:-1]\n",
    "\n",
    "input_FOM=torch.tensor(orig_data_FOM-ref)\n",
    "target_FOM=decoder(encoder(input_FOM))\n",
    "\n",
    "print(\"MSELoss of AE (predictive case): {:.8e}\"\\\n",
    "      .format(torch.nn.functional.mse_loss(input_FOM,target_FOM).detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights and bias   \n",
    "AE={'en_w1':en_w1,'en_b1':en_b1,'en_w2':en_w2,\n",
    "    'de_w1':de_w1,'de_w2':de_w2,\n",
    "    'de_w1T':de_w1T,'de_w2T':de_w2T,'de_w2_sp':de_w2_sp,'de_w2T_sp':de_w2T_sp}\n",
    "\n",
    "pickle.dump(AE,open(\"./model/AE_v2_swish.p\",'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
