{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.prune as prune\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "from scipy import sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import sys,time\n",
    "import os\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "redDim=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set print option\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "# Choose device that is not being used\n",
    "gpu_ids = \"0\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=gpu_ids\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given parameters\n",
    "nx = 60\n",
    "ny = 60\n",
    "m = (ny-2)*(nx-2) # 3364\n",
    "nt = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose either Re=10000 or Re=100\n",
    "Re = 10000 \n",
    "    \n",
    "# Choose data normalize option (option 1: -1<=X<=1 option 2: 0<=X<=1)\n",
    "option = 2\n",
    "\n",
    "# Choose activation function (sigmoid, swish)\n",
    "activation = 'sigmoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set batch_size, number of epochs, paitience for early stop\n",
    "batch_size = 480\n",
    "num_epochs = 10000\n",
    "num_epochs_print = num_epochs//100\n",
    "early_stop_patience = num_epochs//50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_mask(m,b,db):\n",
    "    \n",
    "#     M2 = b + db*(m-1)\n",
    "#     mask = np.zeros((m,M2),dtype='int8')\n",
    "    \n",
    "#     block = np.ones(b,dtype='int8')\n",
    "#     ind = np.arange(b)\n",
    "#     for row in range(m):\n",
    "#         col = ind + row*db\n",
    "#         mask[row,col] = block      \n",
    "\n",
    "# #     for row in range(nx-2,m):\n",
    "# #         col = ind + (row-1)*db\n",
    "# #         mask[row-(nx-2),col] = block    \n",
    "# #     for row in range(0,m-(nx-2)):\n",
    "# #         col = ind + (row+1)*db\n",
    "# #         mask[row+(nx-2),col] = block\n",
    "                   \n",
    "#     print(\n",
    "#         \"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "#             m, M2, (1.0-np.count_nonzero(mask)/mask.size)*100\n",
    "#         )\n",
    "#     )\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.spy(mask)\n",
    "#     plt.show()\n",
    "\n",
    "#     return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_2d(m,b,db):\n",
    "    \n",
    "    # local\n",
    "    Mb=sp.diags([np.ones(nx-2),np.ones(nx-2),np.ones(nx-2)],[0,-1,1],(nx-2,nx-2))\n",
    "    M=sp.kron(sp.eye(ny-2),Mb,format=\"csr\")\n",
    "\n",
    "    Ib=sp.eye(nx-2)\n",
    "    N=sp.kron(sp.diags([np.ones(ny-2),np.ones(ny-2),np.ones(ny-2)],[0,-1,1],(ny-2,ny-2)),Ib,format=\"csr\")\n",
    "\n",
    "    local=(M+N).astype('int8')\n",
    "    I,J,V=sp.find(local)\n",
    "    local[I,J]=1\n",
    "    \n",
    "#     col_ind=np.array([],dtype='int')\n",
    "#     row_ind=np.array([],dtype='int')\n",
    "\n",
    "#     for lin_ind in range(m):\n",
    "#         j,i=np.unravel_index(lin_ind,(ny-2,nx-2))\n",
    "\n",
    "#         E=np.ravel_multi_index((j,np.max((i-1,0))),(ny-2,nx-2))\n",
    "#         W=np.ravel_multi_index((j,np.min((i+1,nx-2-1))),(ny-2,nx-2))\n",
    "#         S=np.ravel_multi_index((np.max((j-1,0)),i),(ny-2,nx-2))\n",
    "#         N=np.ravel_multi_index((np.min((j+1,ny-2-1)),i),(ny-2,nx-2))\n",
    "\n",
    "#         col=np.unique([lin_ind,E,W,S,N])\n",
    "#         row=lin_ind*np.ones(col.size,dtype='int')\n",
    "\n",
    "#         col_ind=np.append(col_ind,col)\n",
    "#         row_ind=np.append(row_ind,row)\n",
    "\n",
    "#     data=np.ones(row_ind.size,dtype='int')\n",
    "#     local2=sp.csr_matrix((data,(row_ind,col_ind)),shape=(m,m))\n",
    "\n",
    "    # basis\n",
    "    M2 = int(b + db*(m-1))\n",
    "    basis = np.zeros((m,M2),dtype='int8')\n",
    "\n",
    "    block = np.ones(b,dtype='int8')\n",
    "    ind = np.arange(b)\n",
    "    for row in range(m):\n",
    "        col = ind + row*db\n",
    "        basis[row,col] = block\n",
    "    \n",
    "    # mask\n",
    "    col_ind=np.array([],dtype='int8')\n",
    "    row_ind=np.array([],dtype='int8')\n",
    "    for i in range(m):\n",
    "        col=basis[sp.find(local[i])[1]].sum(axis=0).nonzero()[0]\n",
    "        row=i*np.ones(col.size)\n",
    "\n",
    "        col_ind=np.append(col_ind,col)\n",
    "        row_ind=np.append(row_ind,row)\n",
    "\n",
    "    data=np.ones(row_ind.size,dtype='int8')\n",
    "    mask=sp.csr_matrix((data,(row_ind,col_ind)),shape=(m,M2)).toarray()\n",
    "    \n",
    "    print(\n",
    "        \"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "            m, M2, (1.0-np.count_nonzero(mask)/np.prod(mask.shape))*100\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.spy(mask)\n",
    "    plt.show()\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if activation=='sigmoid':\n",
    "    class Encoder(nn.Module):\n",
    "        def __init__(self,m,M1,f):\n",
    "            super(Encoder,self).__init__()\n",
    "            self.full = nn.Sequential(\n",
    "                nn.Linear(m,M1),\n",
    "                nn.Sigmoid(),\n",
    "                nn.Linear(M1,f,bias=False)\n",
    "            )\n",
    "\n",
    "        def forward(self, y):     \n",
    "            y = y.view(-1,m)\n",
    "            T = self.full(y)\n",
    "            T = T.squeeze()\n",
    "\n",
    "            return T\n",
    "\n",
    "    class Decoder(nn.Module):\n",
    "        def __init__(self,f,M2,m):\n",
    "            super(Decoder,self).__init__()\n",
    "            self.full = nn.Sequential(\n",
    "                nn.Linear(f,M2),\n",
    "                nn.Sigmoid(),\n",
    "                nn.Linear(M2,m,bias=False)\n",
    "            )\n",
    "\n",
    "        def forward(self,T):\n",
    "            T = T.view(-1,f)\n",
    "            y = self.full(T)\n",
    "            y = y.squeeze()\n",
    "\n",
    "            return y\n",
    "        \n",
    "elif activation=='swish':\n",
    "    def silu(input):\n",
    "        return input * torch.sigmoid(input)\n",
    "\n",
    "    class SiLU(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "        def forward(self, input):\n",
    "            return silu(input)\n",
    "        \n",
    "    class Encoder(nn.Module):\n",
    "        def __init__(self,m,M1,f):\n",
    "            super(Encoder,self).__init__()\n",
    "            self.full = nn.Sequential(\n",
    "                nn.Linear(m,M1),\n",
    "                SiLU(),\n",
    "                nn.Linear(M1,f,bias=False)\n",
    "            )\n",
    "\n",
    "        def forward(self, y):     \n",
    "            y = y.view(-1,m)\n",
    "            T = self.full(y)\n",
    "            T = T.squeeze()\n",
    "\n",
    "            return T\n",
    "\n",
    "    class Decoder(nn.Module):\n",
    "        def __init__(self,f,M2,m):\n",
    "            super(Decoder,self).__init__()\n",
    "            self.full = nn.Sequential(\n",
    "                nn.Linear(f,M2),\n",
    "                SiLU(),\n",
    "                nn.Linear(M2,m,bias=False)\n",
    "            )\n",
    "\n",
    "        def forward(self,T):\n",
    "            T = T.view(-1,f)\n",
    "            y = self.full(T)\n",
    "            y = y.squeeze()\n",
    "\n",
    "            return y\n",
    "else:\n",
    "    raise NameError('{} is given for option, but it must be either sigmoid or swish'.format(activation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "option 2: 0<=X<=1\n",
      "data shape\n",
      "(6004, 3364)\n",
      "(6004, 3364)\n",
      "maximum abs difference\n",
      "1.1920929e-07\n",
      "1.1920929e-07\n"
     ]
    }
   ],
   "source": [
    "# load snapshot\n",
    "if Re==10000:\n",
    "    file_name_snapshot=\"./data/snapshot_full_high_Re.p\"\n",
    "elif Re==100:\n",
    "    file_name_snapshot=\"./data/snapshot_full_low_Re.p\"\n",
    "else:\n",
    "    raise NameError('{} is given for Re, but it must be either 100 or 10000'.format(Re)) \n",
    "\n",
    "snapshot = pickle.load(open(file_name_snapshot,'rb'))\n",
    "snapshot_u = snapshot['u'].astype('float32')\n",
    "snapshot_v = snapshot['v'].astype('float32')\n",
    "\n",
    "# number of data points\n",
    "ndata = snapshot_u.shape[0]\n",
    "\n",
    "# remove BC\n",
    "multi_index_i,multi_index_j=np.meshgrid(np.arange(nx),np.arange(ny),indexing='xy')\n",
    "full_multi_index=(multi_index_j.flatten(),multi_index_i.flatten())\n",
    "free_multi_index=(multi_index_j[1:-1,1:-1].flatten(),multi_index_i[1:-1,1:-1].flatten())\n",
    "\n",
    "dims=(ny,nx)\n",
    "full_raveled_indicies=np.ravel_multi_index(full_multi_index,dims)\n",
    "free_raveled_indicies=np.ravel_multi_index(free_multi_index,dims)\n",
    "\n",
    "orig_data_u = snapshot_u[:,free_raveled_indicies]\n",
    "orig_data_v = snapshot_v[:,free_raveled_indicies]\n",
    "\n",
    "# normalize data\n",
    "if option==1: # option 1: -1<=X<=1\n",
    "    print(\"option {}: -1<=X<=1\".format(option))\n",
    "#     u_ref = np.mean(orig_data_u,axis=0)\n",
    "#     v_ref = np.mean(orig_data_v,axis=0)   \n",
    "\n",
    "#     u_scale = np.max(orig_data_u,axis=0)-np.min(orig_data_u,axis=0)\n",
    "#     v_scale = np.max(orig_data_v,axis=0)-np.min(orig_data_v,axis=0)   \n",
    "    u_ref = (np.max(orig_data_u,axis=0)+np.min(orig_data_u,axis=0))/2.0\n",
    "    v_ref = (np.max(orig_data_v,axis=0)+np.min(orig_data_v,axis=0))/2.0\n",
    "    \n",
    "    u_scale = (np.max(orig_data_u,axis=0)-np.min(orig_data_u,axis=0))/2.0\n",
    "    v_scale = (np.max(orig_data_v,axis=0)-np.min(orig_data_v,axis=0))/2.0\n",
    "    \n",
    "    u_scale = np.where(u_scale > np.finfo('float32').resolution, u_scale, 1)\n",
    "    v_scale = np.where(v_scale > np.finfo('float32').resolution, v_scale, 1)\n",
    "    \n",
    "    u_scale_reciprocal = np.reciprocal(u_scale)\n",
    "    v_scale_reciprocal = np.reciprocal(v_scale)\n",
    "    \n",
    "    data_u = u_scale_reciprocal*(orig_data_u-u_ref)\n",
    "    data_v = v_scale_reciprocal*(orig_data_v-v_ref)\n",
    "    \n",
    "elif option==2: # option 2: 0<=X<=1\n",
    "    print(\"option {}: 0<=X<=1\".format(option))\n",
    "    u_ref = np.min(orig_data_u,axis=0)\n",
    "    v_ref = np.min(orig_data_v,axis=0)\n",
    "    \n",
    "    u_scale = np.max(orig_data_u,axis=0)-np.min(orig_data_u,axis=0)\n",
    "    v_scale = np.max(orig_data_v,axis=0)-np.min(orig_data_v,axis=0)\n",
    "    \n",
    "    u_scale = np.where(u_scale > np.finfo('float32').resolution, u_scale, 1)\n",
    "    v_scale = np.where(v_scale > np.finfo('float32').resolution, v_scale, 1)\n",
    "    \n",
    "    u_scale_reciprocal = np.reciprocal(u_scale)\n",
    "    v_scale_reciprocal = np.reciprocal(v_scale)\n",
    "    \n",
    "    data_u = u_scale_reciprocal*(orig_data_u-u_ref)\n",
    "    data_v = v_scale_reciprocal*(orig_data_v-v_ref)\n",
    "else:\n",
    "    raise NameError('{} is given for option, but it must be either 1 or 2'.format(option))\n",
    "\n",
    "# check shapes of snapshot\n",
    "print('data shape')\n",
    "print(data_u.shape)\n",
    "print(data_v.shape)\n",
    "\n",
    "# restore data\n",
    "rest_data_u = u_ref + u_scale*data_u\n",
    "rest_data_v = v_ref + v_scale*data_v\n",
    "\n",
    "# check precision\n",
    "print('maximum abs difference')\n",
    "print(np.max(np.abs(orig_data_u-rest_data_u)))\n",
    "print(np.max(np.abs(orig_data_v-rest_data_v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # generate mesh grid\n",
    "# [xv,yv]=np.meshgrid(np.linspace(0,1,nx),np.linspace(0,1,ny),indexing='xy')\n",
    "# x=xv.flatten()\n",
    "# y=yv.flatten()\n",
    "\n",
    "# x_free=x[free_raveled_indicies]\n",
    "# y_free=y[free_raveled_indicies]\n",
    "\n",
    "# k=0\n",
    "\n",
    "# # plot original data\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_u[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_u[k].reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Original $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_v[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_v[k].reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Original $v$')\n",
    "# plt.show()\n",
    "\n",
    "# # plot preprocessed data\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), data_u[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), data_u[k].reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Preprocessed $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), data_v[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), data_v[k].reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Preprocessed $v$')\n",
    "# plt.show()\n",
    "\n",
    "# # plot restored data\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_data_u[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_data_u[k].reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Restored $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_data_v[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_data_v[k].reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Restored $v$')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5404, 3364]) torch.Size([600, 3364])\n",
      "torch.Size([5404, 3364]) torch.Size([600, 3364])\n"
     ]
    }
   ],
   "source": [
    "# define testset and trainset indices\n",
    "nset = round(ndata/(nt+1))\n",
    "test_ind = np.array([],dtype='int')\n",
    "for foo in range(nset):\n",
    "    rand_ind = np.random.permutation(np.arange(foo*(nt+1)+1,(foo+1)*(nt+1)))[:int(0.1*(nt+1))]\n",
    "    test_ind = np.append(test_ind,rand_ind)\n",
    "train_ind = np.setdiff1d(np.arange(ndata),test_ind)\n",
    "\n",
    "# set trainset and testset\n",
    "trainset_u = data_u[train_ind]\n",
    "trainset_v = data_v[train_ind]\n",
    "testset_u = data_u[test_ind] \n",
    "testset_v = data_v[test_ind] \n",
    "\n",
    "# set dataset\n",
    "dataset_u = {'train':data_utils.TensorDataset(torch.tensor(trainset_u,dtype=torch.float32)),\n",
    "           'test':data_utils.TensorDataset(torch.tensor(testset_u,dtype=torch.float32))}\n",
    "dataset_v = {'train':data_utils.TensorDataset(torch.tensor(trainset_v,dtype=torch.float32)),\n",
    "           'test':data_utils.TensorDataset(torch.tensor(testset_v,dtype=torch.float32))}\n",
    "\n",
    "print(dataset_u['train'].tensors[0].shape, dataset_u['test'].tensors[0].shape)\n",
    "print(dataset_v['train'].tensors[0].shape, dataset_v['test'].tensors[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5404, 3364) (600, 3364)\n",
      "(5404, 3364) (600, 3364)\n"
     ]
    }
   ],
   "source": [
    "# compute dataset shapes\n",
    "dataset_u_shapes = {'train':trainset_u.shape,\n",
    "                    'test':testset_u.shape}\n",
    "dataset_v_shapes = {'train':trainset_v.shape,\n",
    "                    'test':testset_v.shape}\n",
    "\n",
    "print(dataset_u_shapes['train'],dataset_u_shapes['test'])\n",
    "print(dataset_v_shapes['train'],dataset_v_shapes['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data loaders\n",
    "train_loader_u = DataLoader(dataset=dataset_u['train'], \n",
    "                          batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "train_loader_v = DataLoader(dataset=dataset_v['train'], \n",
    "                          batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader_u = DataLoader(dataset=dataset_u['test'], \n",
    "                         batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader_v = DataLoader(dataset=dataset_v['test'], \n",
    "                         batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "data_loaders_u = {'train':train_loader_u, 'test':test_loader_u}\n",
    "data_loaders_v = {'train':train_loader_v, 'test':test_loader_v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in 3364 by 33730 mask: 99.06%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder parameters:2.27742800e+07(0.08484GB) Decoder parameters:1.77205000e+06(0.4253GB)\n",
      "Data size:2.01974560e+07(0.07524GB)\n"
     ]
    }
   ],
   "source": [
    "# set the number of nodes in each layer\n",
    "a = 2\n",
    "b = int(100)\n",
    "db = int(10)\n",
    "\n",
    "M1 = int(a*m) # encoder hidden layer\n",
    "M2 = b + (m-1)*db # decoder hidden layer\n",
    "\n",
    "f = redDim # latent dimension\n",
    "\n",
    "# sparsity and shape of mask\n",
    "mask_2d=create_mask_2d(m,b,db)\n",
    "\n",
    "# number of parameters and memory\n",
    "en_para=m*M1+M1+M1*f\n",
    "de_para=f*M2+M2+np.count_nonzero(mask_2d)\n",
    "print('Encoder parameters:{:.8e}({:.4}GB)'.format(en_para,en_para*4/2**30),\\\n",
    "      'Decoder parameters:{:.8e}({:.4}GB)'.format(de_para,(f*M2+M2+M2*m)*4/2**30))\n",
    "\n",
    "# data size\n",
    "data_size=np.prod(orig_data_u.shape)\n",
    "print('Data size:{:.8e}({:.4}GB)'.format(data_size,data_size*4/2**30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file names\n",
    "if Re==10000:\n",
    "    file_name_AE_u=\"./model/AE_u_high_Re_v3_red-dim_{}pkl\".format(redDim)\n",
    "    file_name_AE_v=\"./model/AE_v_high_Re_v3_red-dim_{}.pkl\".format(redDim)\n",
    "    file_name_AE=\"./model/AE_high_Re_v3_red-dim_{}.p\".format(redDim)\n",
    "    \n",
    "    PATH_u = './checkpoint_u_high_Re_v3_red-dim_{}.tar'.format(redDim)\n",
    "    PATH_v = './checkpoint_v_high_Re_v3_red-dim_{}.tar'.format(redDim)\n",
    "elif Re==100:\n",
    "    file_name_AE_u=\"./model/AE_u_low_Re_v3_red-dim_{}.pkl\".format(redDim)\n",
    "    file_name_AE_v=\"./model/AE_v_low_Re_v3_red-dim_{}.pkl\".format(redDim)\n",
    "    file_name_AE=\"./model/AE_low_Re_v_3_red-dim_{}.p\".format(redDim)\n",
    "    \n",
    "    PATH_u = './checkpoint_u_low_Re_v3_red-dim_{}.tar'.format(redDim)\n",
    "    PATH_v = './checkpoint_v_low_Re_v3_red-dim_{}.tar'.format(redDim)\n",
    "else:\n",
    "    raise NameError('{} is given for Re, but it must be either 100 or 10000'.format(Re))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------checkpoint not restored--------\n",
      "\n",
      "\n",
      "Start first training... m=3364, f=20, a=2, b=100, db=10\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "try:\n",
    "    checkpoint = torch.load(PATH_u, map_location=device)\n",
    "    \n",
    "    encoder_u = Encoder(m,M1,f).to(device)\n",
    "    decoder_u = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    prune.custom_from_mask(decoder_u.full[2], name='weight', mask=torch.tensor(mask_2d).to(device))    \n",
    "       \n",
    "    optimizer = torch.optim.Adam(list(encoder_u.parameters()) + list(decoder_u.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    encoder_u.load_state_dict(checkpoint['encoder_u_state_dict'])\n",
    "    decoder_u.load_state_dict(checkpoint['decoder_u_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    last_epoch = checkpoint['epoch']\n",
    "    loss_hist = checkpoint['loss_hist']\n",
    "    best_loss = checkpoint['best_loss']\n",
    "    early_stop_counter = checkpoint['early_stop_counter']\n",
    "    best_encoder_u_wts = checkpoint['best_encoder_u_wts']\n",
    "    best_decoder_u_wts = checkpoint['best_decoder_u_wts']\n",
    "    \n",
    "    print(\"\\n--------checkpoint restored--------\\n\")\n",
    "\n",
    "    # resume training\n",
    "    print(\"\")\n",
    "    print('Re-start {}th training... m={}, f={},a={}, b={}, db={}'.format(\n",
    "        last_epoch+1, m, f, a, b, db))\n",
    "except:\n",
    "    encoder_u = Encoder(m,M1,f).to(device)\n",
    "    decoder_u = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    prune.custom_from_mask(decoder_u.full[2], name='weight', mask=torch.tensor(mask_2d).to(device))\n",
    "\n",
    "    optimizer = torch.optim.Adam(list(encoder_u.parameters()) + list(decoder_u.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    last_epoch = 0\n",
    "    loss_hist = {'train':[],'test':[]}\n",
    "    best_loss = float(\"inf\")\n",
    "    early_stop_counter = 1\n",
    "    best_encoder_u_wts = copy.deepcopy(encoder_u.state_dict())\n",
    "    best_decoder_u_wts = copy.deepcopy(decoder_u.state_dict())\n",
    "    \n",
    "    print(\"\\n--------checkpoint not restored--------\\n\")\n",
    "\n",
    "    # start training\n",
    "    print(\"\")\n",
    "    print('Start first training... m={}, f={}, a={}, b={}, db={}'\\\n",
    "          .format(m, f, a, b, db))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 2.8601520930630776e-06\n",
      "test MSELoss: 2.2758598788641392e-06\n",
      "\n",
      "Epoch 200/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 1.425994273692247e-06\n",
      "test MSELoss: 1.4271624422690365e-06\n",
      "\n",
      "Epoch 300/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 9.407135691010213e-07\n",
      "test MSELoss: 9.457172382099088e-07\n",
      "\n",
      "Epoch 400/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 6.03842072615723e-07\n",
      "test MSELoss: 6.092403395996371e-07\n",
      "\n",
      "Epoch 500/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 4.509209798408085e-07\n",
      "test MSELoss: 4.416372235027666e-07\n",
      "\n",
      "Epoch 600/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 3.0536015333685177e-07\n",
      "test MSELoss: 3.123140515981504e-07\n",
      "\n",
      "Epoch 700/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.818457950355734e-07\n",
      "test MSELoss: 2.882666024106584e-07\n",
      "\n",
      "Epoch 800/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.525740778357598e-07\n",
      "test MSELoss: 2.6012601779257237e-07\n",
      "\n",
      "Epoch 900/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.2413479736196091e-07\n",
      "test MSELoss: 2.2901795944108015e-07\n",
      "\n",
      "Epoch 1000/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.9353224450499286e-07\n",
      "test MSELoss: 1.9997769413748755e-07\n",
      "\n",
      "Epoch 1100/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.6947396034336245e-07\n",
      "test MSELoss: 1.7615330705211818e-07\n",
      "\n",
      "Epoch 1200/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.5031257860899833e-07\n",
      "test MSELoss: 1.5548121723441e-07\n",
      "\n",
      "Epoch 1300/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.3552813028135016e-07\n",
      "test MSELoss: 1.4029302803919562e-07\n",
      "\n",
      "Epoch 1400/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.2217167538376e-07\n",
      "test MSELoss: 1.269161458594681e-07\n",
      "\n",
      "Epoch 1500/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.1123082087403413e-07\n",
      "test MSELoss: 1.1577315319755144e-07\n",
      "\n",
      "Epoch 1600/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.0242779145093347e-07\n",
      "test MSELoss: 1.0660709790499822e-07\n",
      "\n",
      "Epoch 1700/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 9.490140058288043e-08\n",
      "test MSELoss: 1.001936226430189e-07\n",
      "\n",
      "Epoch 1800/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 8.776494114172312e-08\n",
      "test MSELoss: 9.488468037943676e-08\n",
      "\n",
      "Epoch 1900/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 7.934726714511217e-08\n",
      "test MSELoss: 8.248294278700996e-08\n",
      "\n",
      "Epoch 2000/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 7.880327293906918e-08\n",
      "test MSELoss: 8.180490596032541e-08\n",
      "\n",
      "Epoch 2100/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 7.837561038331808e-08\n",
      "test MSELoss: 8.152414778805906e-08\n",
      "\n",
      "Epoch 2200/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 7.837034990042251e-08\n",
      "test MSELoss: 8.151659756094886e-08\n",
      "\n",
      "Epoch 2215/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 7.836954912770026e-08\n",
      "test MSELoss: 8.1519135619601e-08\n",
      "\n",
      "Early stopping: 2215th training complete in 1h 11m 17s\n",
      "----------\n",
      "Best train MSELoss: 7.839501847684005e-08\n",
      "Best test MSELoss: 8.154591313314086e-08\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "since = time.time()\n",
    "\n",
    "for epoch in range(last_epoch+1,num_epochs+1):   \n",
    "\n",
    "    if epoch%num_epochs_print == 0:\n",
    "        print()\n",
    "        print('Epoch {}/{}, Learning rate {}'.format(\n",
    "            epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "        print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and test phase\n",
    "    for phase in ['train', 'test']:\n",
    "        if phase == 'train':\n",
    "            encoder_u.train()  # Set model to training mode\n",
    "            decoder_u.train()  # Set model to training mode\n",
    "        else:\n",
    "            encoder_u.eval()   # Set model to evaluation mode\n",
    "            decoder_u.eval()   # Set model to evaluation mode\n",
    "            \n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Iterate over data\n",
    "        for data, in data_loaders_u[phase]:\n",
    "            inputs = data.to(device)\n",
    "            targets = data.to(device)\n",
    "\n",
    "            if phase == 'train':\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = decoder_u(encoder_u(inputs))\n",
    "                loss = loss_func(outputs, targets)\n",
    "\n",
    "                # backward\n",
    "                loss.backward()\n",
    "\n",
    "                # optimize\n",
    "                optimizer.step()  \n",
    "\n",
    "                # add running loss\n",
    "                running_loss += loss.item()*inputs.shape[0]\n",
    "            else:\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    outputs = decoder_u(encoder_u(inputs))\n",
    "                    running_loss += loss_func(outputs,targets).item()*inputs.shape[0]\n",
    "\n",
    "        # compute epoch loss\n",
    "        epoch_loss = running_loss / dataset_u_shapes[phase][0]\n",
    "        loss_hist[phase].append(epoch_loss)\n",
    "            \n",
    "        # update learning rate\n",
    "        if phase == 'train':\n",
    "            scheduler.step(epoch_loss)\n",
    "\n",
    "        if epoch%num_epochs_print == 0:\n",
    "            print('{} MSELoss: {}'.format(\n",
    "                phase, epoch_loss))\n",
    "\n",
    "    # deep copy the model\n",
    "    if round(loss_hist['test'][-1],10) < round(best_loss,10):\n",
    "        best_loss = loss_hist['test'][-1]\n",
    "        early_stop_counter = 1\n",
    "        best_encoder_u_wts = copy.deepcopy(encoder_u.state_dict())\n",
    "        best_decoder_u_wts = copy.deepcopy(decoder_u.state_dict())\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= early_stop_patience:  \n",
    "            break\n",
    "    \n",
    "    # save checkpoint every num_epoch_print\n",
    "    if epoch%num_epochs_print== 0:\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'encoder_u_state_dict': encoder_u.state_dict(),\n",
    "                    'decoder_u_state_dict': decoder_u.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss_hist': loss_hist,\n",
    "                    'best_loss': best_loss,\n",
    "                    'early_stop_counter': early_stop_counter,\n",
    "                    'best_encoder_u_wts': best_encoder_u_wts,\n",
    "                    'best_decoder_u_wts': best_decoder_u_wts,\n",
    "                    }, PATH_u)        \n",
    "\n",
    "print()\n",
    "print('Epoch {}/{}, Learning rate {}'\\\n",
    "      .format(epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "print('-' * 10)\n",
    "print('train MSELoss: {}'.format(loss_hist['train'][-1]))\n",
    "print('test MSELoss: {}'.format(loss_hist['test'][-1]))\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "\n",
    "# load best model weights\n",
    "encoder_u.load_state_dict(best_encoder_u_wts)\n",
    "decoder_u.load_state_dict(best_decoder_u_wts)\n",
    "\n",
    "# compute best train MSELoss\n",
    "encoder_u.to('cpu').eval()\n",
    "decoder_u.to('cpu').eval()\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    train_inputs = torch.tensor(data_u[train_ind])\n",
    "    train_targets = torch.tensor(data_u[train_ind])\n",
    "    train_outputs = decoder_u(encoder_u(train_inputs))\n",
    "    train_loss = loss_func(train_outputs,train_targets).item()\n",
    "\n",
    "# print out training time and best results\n",
    "print()\n",
    "if epoch < num_epochs:\n",
    "    print('Early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "else:\n",
    "    print('No early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "print('-' * 10)\n",
    "print('Best train MSELoss: {}'.format(train_loss))\n",
    "print('Best test MSELoss: {}'.format(best_loss))\n",
    "\n",
    "# # save models\n",
    "# print()\n",
    "# print(\"Saving after {}th training to\".format(epoch),file_name_AE_u)\n",
    "# torch.save((encoder_u,decoder_u),file_name_AE_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "checkpoint removed\n"
     ]
    }
   ],
   "source": [
    "# delete checkpoint\n",
    "try:\n",
    "    os.remove(PATH_u)\n",
    "    print()\n",
    "    print(\"checkpoint removed\")\n",
    "except:\n",
    "    print(\"no checkpoint exists\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and test loss\n",
    "plt.figure()\n",
    "plt.semilogy(loss_hist['train'])\n",
    "plt.semilogy(loss_hist['test'])\n",
    "plt.legend(['train','test'])\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------checkpoint not restored--------\n",
      "\n",
      "\n",
      "Start first training... m=3364, f=20, a=2, b=100, db=10\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "try:\n",
    "    checkpoint = torch.load(PATH_v, map_location=device)\n",
    "    \n",
    "    encoder_v = Encoder(m,M1,f).to(device)\n",
    "    decoder_v = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    prune.custom_from_mask(decoder_v.full[2], name='weight', mask=torch.tensor(mask_2d).to(device))    \n",
    "       \n",
    "    optimizer = torch.optim.Adam(list(encoder_v.parameters()) + list(decoder_v.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    encoder_v.load_state_dict(checkpoint['encoder_v_state_dict'])\n",
    "    decoder_v.load_state_dict(checkpoint['decoder_v_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    last_epoch = checkpoint['epoch']\n",
    "    loss_hist = checkpoint['loss_hist']\n",
    "    best_loss = checkpoint['best_loss']\n",
    "    early_stop_counter = checkpoint['early_stop_counter']\n",
    "    best_encoder_v_wts = checkpoint['best_encoder_v_wts']\n",
    "    best_decoder_v_wts = checkpoint['best_decoder_v_wts']\n",
    "    \n",
    "    print(\"\\n--------checkpoint restored--------\\n\")\n",
    "    \n",
    "    # resume training\n",
    "    print(\"\")\n",
    "    print('Re-start {}th training... m={}, f={}, a={}, b={}, db={}'.format(\n",
    "        last_epoch+1, m, f, a, b, db))\n",
    "except:\n",
    "    encoder_v = Encoder(m,M1,f).to(device)\n",
    "    decoder_v = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    prune.custom_from_mask(decoder_v.full[2], name='weight', mask=torch.tensor(mask_2d).to(device))\n",
    "\n",
    "    optimizer = torch.optim.Adam(list(encoder_v.parameters()) + list(decoder_v.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    last_epoch = 0\n",
    "    loss_hist = {'train':[],'test':[]}\n",
    "    best_loss = float(\"inf\")\n",
    "    early_stop_counter = 1\n",
    "    best_encoder_v_wts = copy.deepcopy(encoder_v.state_dict())\n",
    "    best_decoder_v_wts = copy.deepcopy(decoder_v.state_dict())\n",
    "    \n",
    "    print(\"\\n--------checkpoint not restored--------\\n\")\n",
    "\n",
    "    # start training\n",
    "    print(\"\")\n",
    "    print('Start first training... m={}, f={}, a={}, b={}, db={}'.format(\n",
    "        m, f, a, b, db))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 2.9268838044043003e-06\n",
      "test MSELoss: 2.9480805551429513e-06\n",
      "\n",
      "Epoch 200/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 1.917986443764382e-06\n",
      "test MSELoss: 1.9259803593740797e-06\n",
      "\n",
      "Epoch 300/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 1.1345384762186386e-06\n",
      "test MSELoss: 1.1492133808133077e-06\n",
      "\n",
      "Epoch 400/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 6.693695372366732e-07\n",
      "test MSELoss: 6.656232699242537e-07\n",
      "\n",
      "Epoch 500/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 4.457258029228201e-07\n",
      "test MSELoss: 4.544238095149922e-07\n",
      "\n",
      "Epoch 600/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 4.1122337558838256e-07\n",
      "test MSELoss: 4.195569715648162e-07\n",
      "\n",
      "Epoch 700/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 3.680754961247667e-07\n",
      "test MSELoss: 3.7630444467140477e-07\n",
      "\n",
      "Epoch 800/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 3.184675398747886e-07\n",
      "test MSELoss: 3.2495977961843894e-07\n",
      "\n",
      "Epoch 900/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.7202454766366477e-07\n",
      "test MSELoss: 2.777811346277304e-07\n",
      "\n",
      "Epoch 1000/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.3344556943732667e-07\n",
      "test MSELoss: 2.4050269757935895e-07\n",
      "\n",
      "Epoch 1100/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.0203011234280874e-07\n",
      "test MSELoss: 2.0929593063101494e-07\n",
      "\n",
      "Epoch 1200/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.786857958275937e-07\n",
      "test MSELoss: 1.8419365517274854e-07\n",
      "\n",
      "Epoch 1300/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.5942752101458808e-07\n",
      "test MSELoss: 1.651119021062186e-07\n",
      "\n",
      "Epoch 1400/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.4493535378387187e-07\n",
      "test MSELoss: 1.4857290580039263e-07\n",
      "\n",
      "Epoch 1500/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.3141317271905689e-07\n",
      "test MSELoss: 1.3782911310045164e-07\n",
      "\n",
      "Epoch 1600/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.1907785125176688e-07\n",
      "test MSELoss: 1.2392513042414067e-07\n",
      "\n",
      "Epoch 1700/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.1015463353017177e-07\n",
      "test MSELoss: 1.1589084749630275e-07\n",
      "\n",
      "Epoch 1800/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.0218955732174164e-07\n",
      "test MSELoss: 1.0624260653457895e-07\n",
      "\n",
      "Epoch 1900/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 9.49048840041792e-08\n",
      "test MSELoss: 9.849420052887581e-08\n",
      "\n",
      "Epoch 2000/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 9.414002841779619e-08\n",
      "test MSELoss: 9.773310551963733e-08\n",
      "\n",
      "Epoch 2100/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 9.32460881854883e-08\n",
      "test MSELoss: 9.6808835792217e-08\n",
      "\n",
      "Epoch 2200/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 9.23943675294816e-08\n",
      "test MSELoss: 9.582907409821927e-08\n",
      "\n",
      "Epoch 2300/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 9.137427721904447e-08\n",
      "test MSELoss: 9.480424409957777e-08\n",
      "\n",
      "Epoch 2400/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 9.050539120746279e-08\n",
      "test MSELoss: 9.396771503134004e-08\n",
      "\n",
      "Epoch 2500/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 8.958450655822947e-08\n",
      "test MSELoss: 9.309468111950991e-08\n",
      "\n",
      "Epoch 2600/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 8.868364700711504e-08\n",
      "test MSELoss: 9.205070909956703e-08\n",
      "\n",
      "Epoch 2700/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 8.786232274873689e-08\n",
      "test MSELoss: 9.122459090349367e-08\n",
      "\n",
      "Epoch 2800/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 8.697238301929408e-08\n",
      "test MSELoss: 9.032286811816448e-08\n",
      "\n",
      "Epoch 2900/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 8.619841551912157e-08\n",
      "test MSELoss: 8.948216816406784e-08\n",
      "\n",
      "Epoch 3000/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 8.534866904641217e-08\n",
      "test MSELoss: 8.860693725409874e-08\n",
      "\n",
      "Epoch 3100/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 8.450218952928784e-08\n",
      "test MSELoss: 8.781963600767995e-08\n",
      "\n",
      "Epoch 3200/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 8.372601614366982e-08\n",
      "test MSELoss: 8.701244524900176e-08\n",
      "\n",
      "Epoch 3300/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 8.29377828282226e-08\n",
      "test MSELoss: 8.619046667490693e-08\n",
      "\n",
      "Epoch 3400/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 8.20174624161897e-08\n",
      "test MSELoss: 8.541130398498354e-08\n",
      "\n",
      "Epoch 3500/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 8.200999896154717e-08\n",
      "test MSELoss: 8.540291673853062e-08\n",
      "\n",
      "Epoch 3563/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 8.200669687327908e-08\n",
      "test MSELoss: 8.539559956943776e-08\n",
      "\n",
      "Early stopping: 3563th training complete in 1h 58m 8s\n",
      "----------\n",
      "Best train MSELoss: 8.204536072753399e-08\n",
      "Best test MSELoss: 8.543127165694386e-08\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "since = time.time()\n",
    "\n",
    "for epoch in range(last_epoch+1,num_epochs+1):   \n",
    "\n",
    "    if epoch%num_epochs_print == 0:\n",
    "        print()\n",
    "        print('Epoch {}/{}, Learning rate {}'.format(\n",
    "            epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "        print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and test phase\n",
    "    for phase in ['train', 'test']:\n",
    "        if phase == 'train':\n",
    "            encoder_v.train()  # Set model to training mode\n",
    "            decoder_v.train()  # Set model to training mode\n",
    "        else:\n",
    "            encoder_v.eval()   # Set model to evaluation mode\n",
    "            decoder_v.eval()   # Set model to evaluation mode\n",
    "            \n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Iterate over data\n",
    "        for data, in data_loaders_v[phase]:\n",
    "            inputs = data.to(device)\n",
    "            targets = data.to(device)\n",
    "\n",
    "            if phase == 'train':\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = decoder_v(encoder_v(inputs))\n",
    "                loss = loss_func(outputs, targets)\n",
    "\n",
    "                # backward\n",
    "                loss.backward()\n",
    "\n",
    "                # optimize\n",
    "                optimizer.step()  \n",
    "\n",
    "                # add running loss\n",
    "                running_loss += loss.item()*inputs.shape[0]\n",
    "            else:\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    outputs = decoder_v(encoder_v(inputs))\n",
    "                    running_loss += loss_func(outputs,targets).item()*inputs.shape[0]\n",
    "\n",
    "        # compute epoch loss\n",
    "        epoch_loss = running_loss / dataset_v_shapes[phase][0]\n",
    "        loss_hist[phase].append(epoch_loss)\n",
    "            \n",
    "        # update learning rate\n",
    "        if phase == 'train':\n",
    "            scheduler.step(epoch_loss)\n",
    "\n",
    "        if epoch%num_epochs_print == 0:\n",
    "            print('{} MSELoss: {}'.format(\n",
    "                phase, epoch_loss))\n",
    "\n",
    "    # deep copy the model\n",
    "    if round(loss_hist['test'][-1],10) < round(best_loss,10):\n",
    "        best_loss = loss_hist['test'][-1]\n",
    "        early_stop_counter = 1\n",
    "        best_encoder_v_wts = copy.deepcopy(encoder_v.state_dict())\n",
    "        best_decoder_v_wts = copy.deepcopy(decoder_v.state_dict())\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= early_stop_patience:  \n",
    "            break\n",
    "    \n",
    "    # save checkpoint every num_epoch_print\n",
    "    if epoch%num_epochs_print== 0:\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'encoder_v_state_dict': encoder_v.state_dict(),\n",
    "                    'decoder_v_state_dict': decoder_v.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss_hist': loss_hist,\n",
    "                    'best_loss': best_loss,\n",
    "                    'early_stop_counter': early_stop_counter,\n",
    "                    'best_encoder_v_wts': best_encoder_v_wts,\n",
    "                    'best_decoder_v_wts': best_decoder_v_wts,\n",
    "                    }, PATH_v)        \n",
    "\n",
    "print()\n",
    "print('Epoch {}/{}, Learning rate {}'\\\n",
    "      .format(epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "print('-' * 10)\n",
    "print('train MSELoss: {}'.format(loss_hist['train'][-1]))\n",
    "print('test MSELoss: {}'.format(loss_hist['test'][-1]))\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "\n",
    "# load best model weights\n",
    "encoder_v.load_state_dict(best_encoder_v_wts)\n",
    "decoder_v.load_state_dict(best_decoder_v_wts)\n",
    "\n",
    "# compute best train MSELoss\n",
    "encoder_v.to('cpu').eval()\n",
    "decoder_v.to('cpu').eval()\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    train_inputs = torch.tensor(data_v[train_ind])\n",
    "    train_targets = torch.tensor(data_v[train_ind])\n",
    "    train_outputs = decoder_v(encoder_v(train_inputs))\n",
    "    train_loss = loss_func(train_outputs,train_targets).item()\n",
    "\n",
    "# print out training time and best results\n",
    "print()\n",
    "if epoch < num_epochs:\n",
    "    print('Early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "else:\n",
    "    print('No early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "print('-' * 10)\n",
    "print('Best train MSELoss: {}'.format(train_loss))\n",
    "print('Best test MSELoss: {}'.format(best_loss))\n",
    "\n",
    "# # save models\n",
    "# print()\n",
    "# print(\"Saving after {}th training to\".format(epoch),file_name_AE_v)\n",
    "# torch.save((encoder_v,decoder_v),file_name_AE_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "checkpoint removed\n"
     ]
    }
   ],
   "source": [
    "# delete checkpoint\n",
    "try:\n",
    "    os.remove(PATH_v)\n",
    "    print()\n",
    "    print(\"checkpoint removed\")\n",
    "except:\n",
    "    print(\"no checkpoint exists\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and test loss\n",
    "plt.figure()\n",
    "plt.semilogy(loss_hist['train'])\n",
    "plt.semilogy(loss_hist['test'])\n",
    "plt.legend(['train','test'])\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load models\n",
    "# try:\n",
    "#     encoder_u,decoder_u = torch.load(file_name_AE_u,map_location='cpu')\n",
    "#     encoder_v,decoder_v = torch.load(file_name_AE_v,map_location='cpu')\n",
    "#     print(\"\\n--------model restored--------\\n\")\n",
    "# except:\n",
    "#     print(\"\\n--------model not restored--------\\n\")\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights and bias\n",
    "en_wu1_s=encoder_u.full[0].weight.detach().numpy().astype('float32')\n",
    "en_bu1=encoder_u.full[0].bias.detach().numpy().astype('float32')\n",
    "en_wu2=encoder_u.full[2].weight.detach().numpy().astype('float32')\n",
    "\n",
    "en_wv1_s=encoder_v.full[0].weight.detach().numpy().astype('float32')\n",
    "en_bv1=encoder_v.full[0].bias.detach().numpy().astype('float32')\n",
    "en_wv2=encoder_v.full[2].weight.detach().numpy().astype('float32')\n",
    "\n",
    "de_wu1=decoder_u.full[0].weight.detach().numpy().astype('float32')\n",
    "de_bu1=decoder_u.full[0].bias.detach().numpy().astype('float32')\n",
    "de_wu2_s=decoder_u.full[2].weight.detach().numpy().astype('float32')\n",
    "\n",
    "de_wv1=decoder_v.full[0].weight.detach().numpy().astype('float32')\n",
    "de_bv1=decoder_v.full[0].bias.detach().numpy().astype('float32')\n",
    "de_wv2_s=decoder_v.full[2].weight.detach().numpy().astype('float32')\n",
    "\n",
    "de_wu2_s_sp=sp.csr_matrix(de_wu2_s,dtype='float32')\n",
    "de_wv2_s_sp=sp.csr_matrix(de_wv2_s,dtype='float32')\n",
    "\n",
    "# rescale weights\n",
    "en_wu1=en_wu1_s*u_scale_reciprocal\n",
    "en_wv1=en_wv1_s*v_scale_reciprocal\n",
    "\n",
    "de_wu1T=de_wu1.T\n",
    "de_wv1T=de_wv1.T\n",
    "\n",
    "de_wu2T=u_scale*de_wu2_s.T\n",
    "de_wv2T=v_scale*de_wv2_s.T\n",
    "\n",
    "de_wu2=de_wu2T.T\n",
    "de_wv2=de_wv2T.T\n",
    "\n",
    "de_wu2_sp=sp.csr_matrix(de_wu2,dtype='float32')\n",
    "de_wv2_sp=sp.csr_matrix(de_wv2,dtype='float32')\n",
    "\n",
    "de_wu2T_sp=de_wu2_sp.T\n",
    "de_wv2T_sp=de_wv2_sp.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy version of AE\n",
    "def sigmoid_np(input):\n",
    "    return (1.0/(1.0+np.exp(-input))).astype('float32')\n",
    "\n",
    "def encoder_u_np_forward(x):\n",
    "    z1 = en_wu1.dot(x) + en_bu1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = en_wu2.dot(a1)   \n",
    "    return y\n",
    "\n",
    "def decoder_u_np_forward(x):\n",
    "    z1 = de_wu1.dot(x) + de_bu1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = de_wu2.dot(a1)  \n",
    "    return y\n",
    "\n",
    "def decoder_u_sp_forward(x):\n",
    "    z1 = de_wu1.dot(x) + de_bu1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = sp.csr_matrix.dot(de_wu2_sp,a1)\n",
    "    return y\n",
    "\n",
    "def encoder_v_np_forward(x):\n",
    "    z1 = en_wv1.dot(x) + en_bv1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = en_wv2.dot(a1)   \n",
    "    return y\n",
    "\n",
    "def decoder_v_np_forward(x):\n",
    "    z1 = de_wv1.dot(x) + de_bv1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = de_wv2.dot(a1)   \n",
    "    return y\n",
    "\n",
    "def decoder_v_sp_forward(x):\n",
    "    z1 = de_wv1.dot(x) + de_bv1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = sp.csr_matrix.dot(de_wv2_sp,a1)\n",
    "    return y\n",
    "\n",
    "def decoder_u_np_forward_backwardT(x):\n",
    "    z1 = de_wu1.dot(x) + de_bu1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = de_wu2.dot(a1)\n",
    "\n",
    "    dout = de_wu1T\n",
    "    dout = (a1*(1-a1))*dout\n",
    "    dydxT = dout.dot(de_wu2T)   \n",
    "    return y,dydxT\n",
    "\n",
    "def decoder_u_sp_forward_backwardT(x):\n",
    "    z1 = de_wu1.dot(x) + de_bu1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = sp.csr_matrix.dot(de_wu2_sp,a1)\n",
    "\n",
    "    dout = de_wu1T\n",
    "    dout = (a1*(1-a1))*dout\n",
    "    dydxT = sp.csr_matrix.dot(dout,de_wu2T_sp)\n",
    "    return y,dydxT\n",
    "\n",
    "def decoder_v_np_forward_backwardT(x):\n",
    "    z1 = de_wv1.dot(x) + de_bv1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = de_wv2.dot(a1)\n",
    "\n",
    "    dout = de_wv1T\n",
    "    dout = (a1*(1-a1))*dout\n",
    "    dydxT = dout.dot(de_wv2T)   \n",
    "    return y,dydxT\n",
    "\n",
    "def decoder_v_sp_forward_backwardT(x):\n",
    "    z1 = de_wv1.dot(x) + de_bv1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = sp.csr_matrix.dot(de_wv2_sp,a1)\n",
    "\n",
    "    dout = de_wv1T\n",
    "    dout = (a1*(1-a1))*dout\n",
    "    dydxT = sp.csr_matrix.dot(dout,de_wv2T_sp)\n",
    "    return y,dydxT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE u: 2.52325571e-08\n",
      "MSELoss of AE v: 2.62807714e-08\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss\n",
    "comp_orig_data_u=np.zeros((ndata,f))\n",
    "comp_orig_data_v=np.zeros((ndata,f))\n",
    "\n",
    "rest_orig_data_u=np.zeros(orig_data_u.shape)\n",
    "rest_orig_data_v=np.zeros(orig_data_u.shape)\n",
    "\n",
    "for k in range(ndata):\n",
    "    comp_orig_data_u[k]=encoder_u_np_forward(orig_data_u[k]-u_ref)\n",
    "    comp_orig_data_v[k]=encoder_v_np_forward(orig_data_v[k]-v_ref)\n",
    "    \n",
    "    rest_orig_data_u[k]=decoder_u_sp_forward(comp_orig_data_u[k]) + u_ref\n",
    "    rest_orig_data_v[k]=decoder_v_sp_forward(comp_orig_data_v[k]) + v_ref\n",
    "    \n",
    "print(\"MSELoss of AE u: {:.8e}\".format(np.linalg.norm(orig_data_u-rest_orig_data_u)**2/np.prod(orig_data_u.shape)))\n",
    "print(\"MSELoss of AE v: {:.8e}\".format(np.linalg.norm(orig_data_v-rest_orig_data_v)**2/np.prod(orig_data_v.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale AE\n",
    "en_weight_u_s=encoder_u.full[0].weight.data\n",
    "en_weight_u=en_weight_u_s*torch.tensor(u_scale_reciprocal)\n",
    "encoder_u.full[0].weight=nn.Parameter(en_weight_u)\n",
    "\n",
    "de_weight_u_s=decoder_u.full[2].weight.data\n",
    "de_weight_u=(torch.tensor(u_scale)*de_weight_u_s.T).T\n",
    "de_weight_u_mask=decoder_u.full[2].weight_mask.data\n",
    "prune.remove(decoder_u.full[2],'weight');\n",
    "decoder_u.full[2].weight=nn.Parameter(de_weight_u)\n",
    "prune.custom_from_mask(decoder_u.full[2], name='weight', mask=de_weight_u_mask);\n",
    "\n",
    "en_weight_v_s=encoder_v.full[0].weight.data\n",
    "en_weight_v=en_weight_v_s*torch.tensor(v_scale_reciprocal)\n",
    "encoder_v.full[0].weight=nn.Parameter(en_weight_v)\n",
    "\n",
    "de_weight_v_s=decoder_v.full[2].weight.data\n",
    "de_weight_v=(torch.tensor(v_scale)*de_weight_v_s.T).T\n",
    "de_weight_v_mask=decoder_v.full[2].weight_mask.data\n",
    "prune.remove(decoder_v.full[2],'weight');\n",
    "decoder_v.full[2].weight=nn.Parameter(de_weight_v)\n",
    "prune.custom_from_mask(decoder_v.full[2], name='weight', mask=de_weight_v_mask);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE u: 2.52319055e-08\n",
      "MSELoss of AE v: 2.62801052e-08\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss\n",
    "input_u=torch.tensor(orig_data_u-u_ref)\n",
    "target_u=decoder_u(encoder_u(input_u))\n",
    "\n",
    "input_v=torch.tensor(orig_data_v-v_ref)\n",
    "target_v=decoder_v(encoder_v(input_v))\n",
    "\n",
    "print(\"MSELoss of AE u: {:.8e}\".format(torch.nn.functional.mse_loss(input_u,target_u).detach().item()))\n",
    "print(\"MSELoss of AE v: {:.8e}\".format(torch.nn.functional.mse_loss(input_v,target_v).detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE u (predictive case): 4.02093079e-08\n",
      "MSELoss of AE v (predictive case): 4.17061479e-08\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (predictive case)\n",
    "if Re==10000:\n",
    "    FOM_solution=pickle.load(open('./data/FOM_high_Re.p','rb'))\n",
    "elif Re==100:\n",
    "    FOM_solution=pickle.load(open('./data/FOM_loq_Re.p','rb'))\n",
    "else:\n",
    "    raise NameError('{} is given for Re, but it must be either 100 or 10000'.format(Re))\n",
    "    \n",
    "u_full=FOM_solution['u'].astype('float32')\n",
    "v_full=FOM_solution['v'].astype('float32')\n",
    "\n",
    "orig_data_u_FOM = u_full[:,free_raveled_indicies]\n",
    "orig_data_v_FOM = v_full[:,free_raveled_indicies]\n",
    "\n",
    "input_u_FOM=torch.tensor(orig_data_u_FOM-u_ref)\n",
    "target_u_FOM=decoder_u(encoder_u(input_u_FOM))\n",
    "\n",
    "input_v_FOM=torch.tensor(orig_data_v_FOM-v_ref)\n",
    "target_v_FOM=decoder_v(encoder_v(input_v_FOM))\n",
    "\n",
    "print(\"MSELoss of AE u (predictive case): {:.8e}\"\\\n",
    "      .format(torch.nn.functional.mse_loss(input_u_FOM,target_u_FOM).detach().item()))\n",
    "print(\"MSELoss of AE v (predictive case): {:.8e}\"\\\n",
    "      .format(torch.nn.functional.mse_loss(input_v_FOM,target_v_FOM).detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # generate mesh grid\n",
    "# [xv,yv]=np.meshgrid(np.linspace(0,1,nx),np.linspace(0,1,ny),indexing='xy')\n",
    "# x=xv.flatten()\n",
    "# y=yv.flatten()\n",
    "\n",
    "# x_free=x[free_raveled_indicies]\n",
    "# y_free=y[free_raveled_indicies]\n",
    "\n",
    "# k=-1\n",
    "\n",
    "# # plot origianl data\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_u[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_u[k].reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Original $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_v[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_v[k].reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Original $v$')\n",
    "# plt.show()\n",
    "\n",
    "# # plot compressed data\n",
    "# plt.figure()\n",
    "# plt.plot(comp_orig_data_u[k])\n",
    "# plt.title('Compressed $u$')\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(comp_orig_data_v[k])\n",
    "# plt.title('Compressed $v$')\n",
    "# plt.show()\n",
    "\n",
    "# # plot restored data\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_orig_data_u[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_orig_data_u[k].reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Restored $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_orig_data_v[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_orig_data_v[k].reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Restored $v$')\n",
    "# plt.show()\n",
    "\n",
    "# # plot relative error\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), (orig_data_u[k]-rest_orig_data_u[k]).reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), (orig_data_u[k]-rest_orig_data_u[k]).reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Difference $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), (orig_data_v[k]-rest_orig_data_v[k]).reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), (orig_data_v[k]-rest_orig_data_v[k]).reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Difference $v$')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights and references   \n",
    "AE={'en_wu1':en_wu1,'en_bu1':en_bu1,'en_wu2':en_wu2,\n",
    "    'de_wu1':de_wu1,'de_bu1':de_bu1,'de_wu2':de_wu2,\n",
    "    'de_wu1T':de_wu1T,'de_wu2T':de_wu2T,'de_wu2_sp':de_wu2_sp,'de_wu2T_sp':de_wu2T_sp,'u_ref':u_ref,\n",
    "    'en_wv1':en_wv1,'en_bv1':en_bv1,'en_wv2':en_wv2,\n",
    "    'de_wv1':de_wv1,'de_bv1':de_bv1,'de_wv2':de_wv2,\n",
    "    'de_wv1T':de_wv1T,'de_wv2T':de_wv2T,'de_wv2_sp':de_wv2_sp,'de_wv2T_sp':de_wv2T_sp,'v_ref':v_ref}\n",
    "\n",
    "pickle.dump(AE,open(file_name_AE,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
