{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.prune as prune\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "from scipy import sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import sys,time\n",
    "import os\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "redDim=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set print option\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "# Choose device that is not being used\n",
    "gpu_ids = \"3\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=gpu_ids\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given parameters\n",
    "nx = 60\n",
    "ny = 60\n",
    "m = (ny-2)*(nx-2) # 3364\n",
    "nt = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose either Re=10000 or Re=100\n",
    "Re = 10000 \n",
    "    \n",
    "# Choose data normalize option (option 1: -1<=X<=1 option 2: 0<=X<=1)\n",
    "option = 2\n",
    "\n",
    "# Choose activation function (sigmoid, swish)\n",
    "activation = 'sigmoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set batch_size, number of epochs, paitience for early stop\n",
    "batch_size = 480\n",
    "num_epochs = 10000\n",
    "num_epochs_print = num_epochs//100\n",
    "early_stop_patience = num_epochs//50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_mask(m,b,db):\n",
    "    \n",
    "#     M2 = b + db*(m-1)\n",
    "#     mask = np.zeros((m,M2),dtype='int8')\n",
    "    \n",
    "#     block = np.ones(b,dtype='int8')\n",
    "#     ind = np.arange(b)\n",
    "#     for row in range(m):\n",
    "#         col = ind + row*db\n",
    "#         mask[row,col] = block      \n",
    "\n",
    "# #     for row in range(nx-2,m):\n",
    "# #         col = ind + (row-1)*db\n",
    "# #         mask[row-(nx-2),col] = block    \n",
    "# #     for row in range(0,m-(nx-2)):\n",
    "# #         col = ind + (row+1)*db\n",
    "# #         mask[row+(nx-2),col] = block\n",
    "                   \n",
    "#     print(\n",
    "#         \"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "#             m, M2, (1.0-np.count_nonzero(mask)/mask.size)*100\n",
    "#         )\n",
    "#     )\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.spy(mask)\n",
    "#     plt.show()\n",
    "\n",
    "#     return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_2d(m,b,db):\n",
    "    \n",
    "    # local\n",
    "    Mb=sp.diags([np.ones(nx-2),np.ones(nx-2),np.ones(nx-2)],[0,-1,1],(nx-2,nx-2))\n",
    "    M=sp.kron(sp.eye(ny-2),Mb,format=\"csr\")\n",
    "\n",
    "    Ib=sp.eye(nx-2)\n",
    "    N=sp.kron(sp.diags([np.ones(ny-2),np.ones(ny-2),np.ones(ny-2)],[0,-1,1],(ny-2,ny-2)),Ib,format=\"csr\")\n",
    "\n",
    "    local=(M+N).astype('int8')\n",
    "    I,J,V=sp.find(local)\n",
    "    local[I,J]=1\n",
    "    \n",
    "#     col_ind=np.array([],dtype='int')\n",
    "#     row_ind=np.array([],dtype='int')\n",
    "\n",
    "#     for lin_ind in range(m):\n",
    "#         j,i=np.unravel_index(lin_ind,(ny-2,nx-2))\n",
    "\n",
    "#         E=np.ravel_multi_index((j,np.max((i-1,0))),(ny-2,nx-2))\n",
    "#         W=np.ravel_multi_index((j,np.min((i+1,nx-2-1))),(ny-2,nx-2))\n",
    "#         S=np.ravel_multi_index((np.max((j-1,0)),i),(ny-2,nx-2))\n",
    "#         N=np.ravel_multi_index((np.min((j+1,ny-2-1)),i),(ny-2,nx-2))\n",
    "\n",
    "#         col=np.unique([lin_ind,E,W,S,N])\n",
    "#         row=lin_ind*np.ones(col.size,dtype='int')\n",
    "\n",
    "#         col_ind=np.append(col_ind,col)\n",
    "#         row_ind=np.append(row_ind,row)\n",
    "\n",
    "#     data=np.ones(row_ind.size,dtype='int')\n",
    "#     local2=sp.csr_matrix((data,(row_ind,col_ind)),shape=(m,m))\n",
    "\n",
    "    # basis\n",
    "    M2 = int(b + db*(m-1))\n",
    "    basis = np.zeros((m,M2),dtype='int8')\n",
    "\n",
    "    block = np.ones(b,dtype='int8')\n",
    "    ind = np.arange(b)\n",
    "    for row in range(m):\n",
    "        col = ind + row*db\n",
    "        basis[row,col] = block\n",
    "    \n",
    "    # mask\n",
    "    col_ind=np.array([],dtype='int8')\n",
    "    row_ind=np.array([],dtype='int8')\n",
    "    for i in range(m):\n",
    "        col=basis[sp.find(local[i])[1]].sum(axis=0).nonzero()[0]\n",
    "        row=i*np.ones(col.size)\n",
    "\n",
    "        col_ind=np.append(col_ind,col)\n",
    "        row_ind=np.append(row_ind,row)\n",
    "\n",
    "    data=np.ones(row_ind.size,dtype='int8')\n",
    "    mask=sp.csr_matrix((data,(row_ind,col_ind)),shape=(m,M2)).toarray()\n",
    "    \n",
    "    print(\n",
    "        \"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "            m, M2, (1.0-np.count_nonzero(mask)/np.prod(mask.shape))*100\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.spy(mask)\n",
    "    plt.show()\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if activation=='sigmoid':\n",
    "    class Encoder(nn.Module):\n",
    "        def __init__(self,m,M1,f):\n",
    "            super(Encoder,self).__init__()\n",
    "            self.full = nn.Sequential(\n",
    "                nn.Linear(m,M1),\n",
    "                nn.Sigmoid(),\n",
    "                nn.Linear(M1,f,bias=False)\n",
    "            )\n",
    "\n",
    "        def forward(self, y):     \n",
    "            y = y.view(-1,m)\n",
    "            T = self.full(y)\n",
    "            T = T.squeeze()\n",
    "\n",
    "            return T\n",
    "\n",
    "    class Decoder(nn.Module):\n",
    "        def __init__(self,f,M2,m):\n",
    "            super(Decoder,self).__init__()\n",
    "            self.full = nn.Sequential(\n",
    "                nn.Linear(f,M2),\n",
    "                nn.Sigmoid(),\n",
    "                nn.Linear(M2,m,bias=False)\n",
    "            )\n",
    "\n",
    "        def forward(self,T):\n",
    "            T = T.view(-1,f)\n",
    "            y = self.full(T)\n",
    "            y = y.squeeze()\n",
    "\n",
    "            return y\n",
    "        \n",
    "elif activation=='swish':\n",
    "    def silu(input):\n",
    "        return input * torch.sigmoid(input)\n",
    "\n",
    "    class SiLU(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "        def forward(self, input):\n",
    "            return silu(input)\n",
    "        \n",
    "    class Encoder(nn.Module):\n",
    "        def __init__(self,m,M1,f):\n",
    "            super(Encoder,self).__init__()\n",
    "            self.full = nn.Sequential(\n",
    "                nn.Linear(m,M1),\n",
    "                SiLU(),\n",
    "                nn.Linear(M1,f,bias=False)\n",
    "            )\n",
    "\n",
    "        def forward(self, y):     \n",
    "            y = y.view(-1,m)\n",
    "            T = self.full(y)\n",
    "            T = T.squeeze()\n",
    "\n",
    "            return T\n",
    "\n",
    "    class Decoder(nn.Module):\n",
    "        def __init__(self,f,M2,m):\n",
    "            super(Decoder,self).__init__()\n",
    "            self.full = nn.Sequential(\n",
    "                nn.Linear(f,M2),\n",
    "                SiLU(),\n",
    "                nn.Linear(M2,m,bias=False)\n",
    "            )\n",
    "\n",
    "        def forward(self,T):\n",
    "            T = T.view(-1,f)\n",
    "            y = self.full(T)\n",
    "            y = y.squeeze()\n",
    "\n",
    "            return y\n",
    "else:\n",
    "    raise NameError('{} is given for option, but it must be either sigmoid or swish'.format(activation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "option 2: 0<=X<=1\n",
      "data shape\n",
      "(6004, 3364)\n",
      "(6004, 3364)\n",
      "maximum abs difference\n",
      "1.1920929e-07\n",
      "1.1920929e-07\n"
     ]
    }
   ],
   "source": [
    "# load snapshot\n",
    "if Re==10000:\n",
    "    file_name_snapshot=\"./data/snapshot_full_high_Re.p\"\n",
    "elif Re==100:\n",
    "    file_name_snapshot=\"./data/snapshot_full_low_Re.p\"\n",
    "else:\n",
    "    raise NameError('{} is given for Re, but it must be either 100 or 10000'.format(Re)) \n",
    "\n",
    "snapshot = pickle.load(open(file_name_snapshot,'rb'))\n",
    "snapshot_u = snapshot['u'].astype('float32')\n",
    "snapshot_v = snapshot['v'].astype('float32')\n",
    "\n",
    "# number of data points\n",
    "ndata = snapshot_u.shape[0]\n",
    "\n",
    "# remove BC\n",
    "multi_index_i,multi_index_j=np.meshgrid(np.arange(nx),np.arange(ny),indexing='xy')\n",
    "full_multi_index=(multi_index_j.flatten(),multi_index_i.flatten())\n",
    "free_multi_index=(multi_index_j[1:-1,1:-1].flatten(),multi_index_i[1:-1,1:-1].flatten())\n",
    "\n",
    "dims=(ny,nx)\n",
    "full_raveled_indicies=np.ravel_multi_index(full_multi_index,dims)\n",
    "free_raveled_indicies=np.ravel_multi_index(free_multi_index,dims)\n",
    "\n",
    "orig_data_u = snapshot_u[:,free_raveled_indicies]\n",
    "orig_data_v = snapshot_v[:,free_raveled_indicies]\n",
    "\n",
    "# normalize data\n",
    "if option==1: # option 1: -1<=X<=1\n",
    "    print(\"option {}: -1<=X<=1\".format(option))\n",
    "#     u_ref = np.mean(orig_data_u,axis=0)\n",
    "#     v_ref = np.mean(orig_data_v,axis=0)   \n",
    "\n",
    "#     u_scale = np.max(orig_data_u,axis=0)-np.min(orig_data_u,axis=0)\n",
    "#     v_scale = np.max(orig_data_v,axis=0)-np.min(orig_data_v,axis=0)   \n",
    "    u_ref = (np.max(orig_data_u,axis=0)+np.min(orig_data_u,axis=0))/2.0\n",
    "    v_ref = (np.max(orig_data_v,axis=0)+np.min(orig_data_v,axis=0))/2.0\n",
    "    \n",
    "    u_scale = (np.max(orig_data_u,axis=0)-np.min(orig_data_u,axis=0))/2.0\n",
    "    v_scale = (np.max(orig_data_v,axis=0)-np.min(orig_data_v,axis=0))/2.0\n",
    "    \n",
    "    u_scale = np.where(u_scale > np.finfo('float32').resolution, u_scale, 1)\n",
    "    v_scale = np.where(v_scale > np.finfo('float32').resolution, v_scale, 1)\n",
    "    \n",
    "    u_scale_reciprocal = np.reciprocal(u_scale)\n",
    "    v_scale_reciprocal = np.reciprocal(v_scale)\n",
    "    \n",
    "    data_u = u_scale_reciprocal*(orig_data_u-u_ref)\n",
    "    data_v = v_scale_reciprocal*(orig_data_v-v_ref)\n",
    "    \n",
    "elif option==2: # option 2: 0<=X<=1\n",
    "    print(\"option {}: 0<=X<=1\".format(option))\n",
    "    u_ref = np.min(orig_data_u,axis=0)\n",
    "    v_ref = np.min(orig_data_v,axis=0)\n",
    "    \n",
    "    u_scale = np.max(orig_data_u,axis=0)-np.min(orig_data_u,axis=0)\n",
    "    v_scale = np.max(orig_data_v,axis=0)-np.min(orig_data_v,axis=0)\n",
    "    \n",
    "    u_scale = np.where(u_scale > np.finfo('float32').resolution, u_scale, 1)\n",
    "    v_scale = np.where(v_scale > np.finfo('float32').resolution, v_scale, 1)\n",
    "    \n",
    "    u_scale_reciprocal = np.reciprocal(u_scale)\n",
    "    v_scale_reciprocal = np.reciprocal(v_scale)\n",
    "    \n",
    "    data_u = u_scale_reciprocal*(orig_data_u-u_ref)\n",
    "    data_v = v_scale_reciprocal*(orig_data_v-v_ref)\n",
    "else:\n",
    "    raise NameError('{} is given for option, but it must be either 1 or 2'.format(option))\n",
    "\n",
    "# check shapes of snapshot\n",
    "print('data shape')\n",
    "print(data_u.shape)\n",
    "print(data_v.shape)\n",
    "\n",
    "# restore data\n",
    "rest_data_u = u_ref + u_scale*data_u\n",
    "rest_data_v = v_ref + v_scale*data_v\n",
    "\n",
    "# check precision\n",
    "print('maximum abs difference')\n",
    "print(np.max(np.abs(orig_data_u-rest_data_u)))\n",
    "print(np.max(np.abs(orig_data_v-rest_data_v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # generate mesh grid\n",
    "# [xv,yv]=np.meshgrid(np.linspace(0,1,nx),np.linspace(0,1,ny),indexing='xy')\n",
    "# x=xv.flatten()\n",
    "# y=yv.flatten()\n",
    "\n",
    "# x_free=x[free_raveled_indicies]\n",
    "# y_free=y[free_raveled_indicies]\n",
    "\n",
    "# k=0\n",
    "\n",
    "# # plot original data\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_u[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_u[k].reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Original $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_v[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_v[k].reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Original $v$')\n",
    "# plt.show()\n",
    "\n",
    "# # plot preprocessed data\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), data_u[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), data_u[k].reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Preprocessed $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), data_v[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), data_v[k].reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Preprocessed $v$')\n",
    "# plt.show()\n",
    "\n",
    "# # plot restored data\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_data_u[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_data_u[k].reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Restored $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_data_v[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_data_v[k].reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Restored $v$')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5404, 3364]) torch.Size([600, 3364])\n",
      "torch.Size([5404, 3364]) torch.Size([600, 3364])\n"
     ]
    }
   ],
   "source": [
    "# define testset and trainset indices\n",
    "nset = round(ndata/(nt+1))\n",
    "test_ind = np.array([],dtype='int')\n",
    "for foo in range(nset):\n",
    "    rand_ind = np.random.permutation(np.arange(foo*(nt+1)+1,(foo+1)*(nt+1)))[:int(0.1*(nt+1))]\n",
    "    test_ind = np.append(test_ind,rand_ind)\n",
    "train_ind = np.setdiff1d(np.arange(ndata),test_ind)\n",
    "\n",
    "# set trainset and testset\n",
    "trainset_u = data_u[train_ind]\n",
    "trainset_v = data_v[train_ind]\n",
    "testset_u = data_u[test_ind] \n",
    "testset_v = data_v[test_ind] \n",
    "\n",
    "# set dataset\n",
    "dataset_u = {'train':data_utils.TensorDataset(torch.tensor(trainset_u,dtype=torch.float32)),\n",
    "           'test':data_utils.TensorDataset(torch.tensor(testset_u,dtype=torch.float32))}\n",
    "dataset_v = {'train':data_utils.TensorDataset(torch.tensor(trainset_v,dtype=torch.float32)),\n",
    "           'test':data_utils.TensorDataset(torch.tensor(testset_v,dtype=torch.float32))}\n",
    "\n",
    "print(dataset_u['train'].tensors[0].shape, dataset_u['test'].tensors[0].shape)\n",
    "print(dataset_v['train'].tensors[0].shape, dataset_v['test'].tensors[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5404, 3364) (600, 3364)\n",
      "(5404, 3364) (600, 3364)\n"
     ]
    }
   ],
   "source": [
    "# compute dataset shapes\n",
    "dataset_u_shapes = {'train':trainset_u.shape,\n",
    "                    'test':testset_u.shape}\n",
    "dataset_v_shapes = {'train':trainset_v.shape,\n",
    "                    'test':testset_v.shape}\n",
    "\n",
    "print(dataset_u_shapes['train'],dataset_u_shapes['test'])\n",
    "print(dataset_v_shapes['train'],dataset_v_shapes['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data loaders\n",
    "train_loader_u = DataLoader(dataset=dataset_u['train'], \n",
    "                          batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "train_loader_v = DataLoader(dataset=dataset_v['train'], \n",
    "                          batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader_u = DataLoader(dataset=dataset_u['test'], \n",
    "                         batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader_v = DataLoader(dataset=dataset_v['test'], \n",
    "                         batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "data_loaders_u = {'train':train_loader_u, 'test':test_loader_u}\n",
    "data_loaders_v = {'train':train_loader_v, 'test':test_loader_v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in 3364 by 33730 mask: 99.06%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAABECAYAAABte+WAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAALRklEQVR4nO3db4xcVRnH8e/PAgUF+VtI0xaBUomlKaXd1CKCIih/fAEYwJYgGCUYBYQXvmiDIqK80AhGQBEUIoLKn6DCCxErikhigC0U2korRQtWKi0iUJUghccX5yw7TGdm73Z3Zu6d+X2Szdw9e6dznt7MOTPnOfccRQRmZtYf3tbtCpiZWee40Tcz6yNu9M3M+ogbfTOzPuJG38ysj7jRNzPrI6Vt9CUdJ2mNpLWSFne7PvUkrZO0QtJySYO5bA9JSyU9mR93rzl/SY5ljaRja8rn5X9nraQrJanN9b5B0kZJK2vKxq3ekiZKujWXPyhpvw7GcYmkv+drslzSCWWOQ9I0Sb+T9ISkVZIuyOWVuh4t4qjM9ZC0o6SHJD2WY/hKLq/UtSgkIkr3A0wAngIOAHYAHgNmdrtedXVcB+xVV/YNYHE+Xgx8PR/PzDFMBPbPsU3If3sIOAwQcDdwfJvrfSQwF1jZjnoDnwO+l48XArd2MI5LgC80OLeUcQCTgbn5eBfgz7mulboeLeKozPXIr7dzPt4eeBBYULVrUSjWbrxogQtwGHBPze9LgCXdrlddHdexdaO/BpicjycDaxrVH7gnxzgZWF1Tvgi4tgN134+3NpbjVu+hc/LxdsDzgDoUR7NGptRx1Lz+ncCHq3o9GsRRyesBvB14BHhv1a9Fo5+yDu9MAf5W8/v6XFYmAfxa0jJJ5+SyfSJiA0B+3DuXN4tnSj6uL++08az3m8+JiC3AS8Cebav51s6T9Hge/hn6Kl76OPJX/UNJnzArez3q4oAKXQ9JEyQtBzYCSyOi0teimbI2+o3Gtcu2XsThETEXOB44V9KRLc5tFk/Z49yWenczpmuA6cAcYANw+Qh1KkUcknYG7gAujIiXW53apE5ljaNS1yMiXo+IOcBUYL6kWS1OL2UMRZS10V8PTKv5fSrwbJfq0lBEPJsfNwI/B+YDz0maDJAfN+bTm8WzPh/Xl3faeNb7zedI2g7YFXihbTWvERHP5TfuG8D3SdfkLXWqq2/X45C0Pamh/HFE/CwXV+56NIqjitcj1/tF4D7gOCp4LUZS1kb/YWCGpP0l7UBKetzV5Tq9SdI7JO0ydAx8BFhJquNZ+bSzSGOb5PKFOXu/PzADeCh/XdwsaUHO8J9Z85xOGs961/5bpwC/jTyI2W5Db87sZNI1GapT6eLIr3k98EREXFHzp0pdj2ZxVOl6SJokabd8vBNwDLCail2LQjqdRBhFMuUE0iyAp4CLul2furodQMrcPwasGqofaXzuXuDJ/LhHzXMuyrGsoWaGDjBAejM8BVxN+5NsPyV91X6N9Mnj0+NZb2BH4HZgLWkWwwEdjOMmYAXwOOkNNrnMcQDvJ329fxxYnn9OqNr1aBFHZa4HMBt4NNd1JXDxeL+nO/XeGOlnqDJmZtYHyjq8Y2ZmbeBG38ysj7jRNzPrI270zcz6SMcbfZV8ITUzs17W0UZf0gTgO6S7WGcCiyTNHOE557T6exX0QgzgOMqkF2KA3oijajF0+pP+fGBtRPwlIv4H3AKcOMJzKvUf2kQvxACOo0x6IQbojTgqFUOnG/0qLKRmZtazOnpzlqRTgWMj4uz8+yeA+RFxft1555B7z4kTJ86bNavVukewbNky5s2bV6i82bnttGnTJiZNmtTR12wHx1EevRAD9EYcZY1h2bJlz0fEVhXbbiz/qKR1wGbgdWBLRAxI2gO4lbTW+TrgtIj4V37Kh4DTJR0BfJ4mC4xFxHXAdQADAwMxODg4lmrW1pf6Ti5vatOw3Hcrm1lVSXq6Ufl4DO8cFRFzImIg/74YuDciZpDWqlicKzATeB/wD+Bs4Lt0eCG1Ro14zXoZb2rVOdRrVm5mVkbtGNM/EbgxH98InFRTfgtwHmlFvsnAHyNiVRvqMCbNOodarb4hNOLOwczKYKyN/qh3j4qIX0bEu0mrJP5mjK/fNc2Gftw5mFmZjWlMn7R71LOS9gaWSlrd4tzCu8bUJnL33XffMVaxu0bTORQdampVbmbWyoif9PPelhslrawp20PSUuD3+fE1hnePek3SX/Ndt4sY3mnmDeCb+U7cK2mxS1REXBcRAxExUMaseDu045uDvzWYWb0iwzs/JG0bVmsxcD8wl5Ss/RJp96iXSZ/ef5CfczXDidoPkmb6HEzasGA2aSMBG4XRfnOoL3PnYNbfRhzeiYj7lXa4r3UiaRuwB/K/cSBwKWmXmWtJUzM/mc9dmrdN257UgfwJ2Al4NCJeH2sA1ljRZLSHlMz6y7YmcveJiAcj4pCIOBj4b0RcRkrWromIo/OUzV8A78zl6yPisoiYDnycNNxjXeRktFn/Ge8pm82StYWTuJASuZIGJQ1u2rRp3Cpn28adg1nvKJTIBQZJQzhDtkjaIGl5TvD+J5evB87Iydo1wCGkZO16YLqkFZLWkjYUbpjEhf5M5PYCdw5m5Vc0kXtWXdka4JGImAPcDPwkl68EPgAcSrrr9hBgMM/XnwR8G5gBzCN1BNaHxtI5OBltNjZF5ul/FjgamChpPfBlUgL3Y5KeBJ4BTs3nziLN6lkObAEeBwbyGj3PAxcCS4BHSFM2zZoqkowGr6lkNhojftKPiEWk+ferImJqRFwPvEKajfMK8DTD4/NTgJsiYnpEHERq/Kfkn7URMSsncr+Gl1S2cVJkTSUPKZkl25rIvQaYDswBNgCX53Incq2UnG8wS4okcqeR1sk5UNIqSRdExHPArsA9wOnAaZJ2J43TT5O0JCdsFwLTcvlUSfMkrQBuB/ZTk3eME7nWLe4crNcV+aS/hTQcsxZYAJwr6UjyEsrAlcBT+fe7SEnfRcBHgX8C55OWYtgM/Ii0ps6jwKtsfaevWSW4c7CqKtLoX0FaVuEg4AnS9MyLgQtId+UelR9PysskP00ar78L+Ayps5gPfJE07fNmUidxOcPLLpv1JM9UsrIpsgzDoqHjvBzD/aRpmc9ExMyavw0tofwkKZl7cy4/hdQJrAP+EBHH5PIjcDLXDPBMJeucwolcSTsDdwAXRsTLrU5tUDaqZK4TuWaNeaaSjVWhRK6k+0jbHE4hJWahjXflOpFrtu2cb7BWiiZy/00a159BSuTOxHflmlWaO4f+VOSO3OmkmTgrSGvi7wOcjO/KNesL3v2ttxS5I/eBiFBEzCbNtnkJuArflWtmNTxTqRrGksht2125TuSa9a4iyWhoPVOpnjuH4ookcneU9DAp6TqFNEYPaV/cX5HG9o8k3bgFTuSa2Tgouvtbq/J67hyKfdJ/lTT3/gbSzJ3jJC0Avgrcm3fIeonhT/JO5JpZRzgZPXpFErmHk5ZVWEHaTGUGcBhwBvCspNNJwzvb5/OdyDWzUnEyelihRC6pc3iDNIZ/VUR8K/0p3hMRsyPiWNKm6OBErplVVDu+OZTtW0OhRG5EvJ7n408F5kua1eJ0J3LNrKeN9ptDfVk3O4dRracfES8C95FWx3xO0mSA/Lgxn7ae4bt2IXUUQ4ncqQ3KG72OE7lmVnllnKlUZPbOJEm75eOdgGOA1Qwvo0x+vDMf3wUslDRR0v6kHMBDOZG7WdKCvI7+mTXPMTPrW+2YqdSMRkpCSJoN3AhMIHUSt0XEpZL2BG4D9iXfkRsRL+TnXAR8ipTIvTAi7s7lA6SN1ncC7gbOjxEqIGkzaVpole1FSmJXneMoj16IAXojjrLG8K6I2GqoZMRGv9skDUbEQLfrMRa9EAM4jjLphRigN+KoWgzbukeumZlVkBt9M7M+UoVG/7puV2Ac9EIM4DjKpBdigN6Io1IxlH5M38zMxk8VPumbmdk4caNvZtZH3OibmfURN/pmZn3Ejb6ZWR/5P71+ZTg7BJElAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder parameters:2.27406400e+07(0.08472GB) Decoder parameters:1.60340000e+06(0.4247GB)\n",
      "Data size:2.01974560e+07(0.07524GB)\n"
     ]
    }
   ],
   "source": [
    "# set the number of nodes in each layer\n",
    "a = 2\n",
    "b = int(100)\n",
    "db = int(10)\n",
    "\n",
    "M1 = int(a*m) # encoder hidden layer\n",
    "M2 = b + (m-1)*db # decoder hidden layer\n",
    "\n",
    "f = redDim # latent dimension\n",
    "\n",
    "# sparsity and shape of mask\n",
    "mask_2d=create_mask_2d(m,b,db)\n",
    "\n",
    "# number of parameters and memory\n",
    "en_para=m*M1+M1+M1*f\n",
    "de_para=f*M2+M2+np.count_nonzero(mask_2d)\n",
    "print('Encoder parameters:{:.8e}({:.4}GB)'.format(en_para,en_para*4/2**30),\\\n",
    "      'Decoder parameters:{:.8e}({:.4}GB)'.format(de_para,(f*M2+M2+M2*m)*4/2**30))\n",
    "\n",
    "# data size\n",
    "data_size=np.prod(orig_data_u.shape)\n",
    "print('Data size:{:.8e}({:.4}GB)'.format(data_size,data_size*4/2**30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file names\n",
    "if Re==10000:\n",
    "    file_name_AE_u=\"./model/AE_u_high_Re_v3_red-dim_{}pkl\".format(redDim)\n",
    "    file_name_AE_v=\"./model/AE_v_high_Re_v3_red-dim_{}.pkl\".format(redDim)\n",
    "    file_name_AE=\"./model/AE_high_Re_v3_red-dim_{}.p\".format(redDim)\n",
    "    \n",
    "    PATH_u = './checkpoint_u_high_Re_v3_red-dim_{}.tar'.format(redDim)\n",
    "    PATH_v = './checkpoint_v_high_Re_v3_red-dim_{}.tar'.format(redDim)\n",
    "elif Re==100:\n",
    "    file_name_AE_u=\"./model/AE_u_low_Re_v3_red-dim_{}.pkl\".format(redDim)\n",
    "    file_name_AE_v=\"./model/AE_v_low_Re_v3_red-dim_{}.pkl\".format(redDim)\n",
    "    file_name_AE=\"./model/AE_low_Re_v_3_red-dim_{}.p\".format(redDim)\n",
    "    \n",
    "    PATH_u = './checkpoint_u_low_Re_v3_red-dim_{}.tar'.format(redDim)\n",
    "    PATH_v = './checkpoint_v_low_Re_v3_red-dim_{}.tar'.format(redDim)\n",
    "else:\n",
    "    raise NameError('{} is given for Re, but it must be either 100 or 10000'.format(Re))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------checkpoint restored--------\n",
      "\n",
      "\n",
      "Re-start 2101th training... m=3364, f=15,a=2, b=100, db=10\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "try:\n",
    "    checkpoint = torch.load(PATH_u, map_location=device)\n",
    "    \n",
    "    encoder_u = Encoder(m,M1,f).to(device)\n",
    "    decoder_u = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    prune.custom_from_mask(decoder_u.full[2], name='weight', mask=torch.tensor(mask_2d).to(device))    \n",
    "       \n",
    "    optimizer = torch.optim.Adam(list(encoder_u.parameters()) + list(decoder_u.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    encoder_u.load_state_dict(checkpoint['encoder_u_state_dict'])\n",
    "    decoder_u.load_state_dict(checkpoint['decoder_u_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    last_epoch = checkpoint['epoch']\n",
    "    loss_hist = checkpoint['loss_hist']\n",
    "    best_loss = checkpoint['best_loss']\n",
    "    early_stop_counter = checkpoint['early_stop_counter']\n",
    "    best_encoder_u_wts = checkpoint['best_encoder_u_wts']\n",
    "    best_decoder_u_wts = checkpoint['best_decoder_u_wts']\n",
    "    \n",
    "    print(\"\\n--------checkpoint restored--------\\n\")\n",
    "\n",
    "    # resume training\n",
    "    print(\"\")\n",
    "    print('Re-start {}th training... m={}, f={},a={}, b={}, db={}'.format(\n",
    "        last_epoch+1, m, f, a, b, db))\n",
    "except:\n",
    "    encoder_u = Encoder(m,M1,f).to(device)\n",
    "    decoder_u = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    prune.custom_from_mask(decoder_u.full[2], name='weight', mask=torch.tensor(mask_2d).to(device))\n",
    "\n",
    "    optimizer = torch.optim.Adam(list(encoder_u.parameters()) + list(decoder_u.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    last_epoch = 0\n",
    "    loss_hist = {'train':[],'test':[]}\n",
    "    best_loss = float(\"inf\")\n",
    "    early_stop_counter = 1\n",
    "    best_encoder_u_wts = copy.deepcopy(encoder_u.state_dict())\n",
    "    best_decoder_u_wts = copy.deepcopy(decoder_u.state_dict())\n",
    "    \n",
    "    print(\"\\n--------checkpoint not restored--------\\n\")\n",
    "\n",
    "    # start training\n",
    "    print(\"\")\n",
    "    print('Start first training... m={}, f={}, a={}, b={}, db={}'\\\n",
    "          .format(m, f, a, b, db))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2200/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 9.945408446323291e-08\n",
      "test MSELoss: 9.506244680324016e-08\n",
      "\n",
      "Epoch 2300/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 9.943611798255698e-08\n",
      "test MSELoss: 9.511180820709342e-08\n",
      "\n",
      "Epoch 2300/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 9.943611798255698e-08\n",
      "test MSELoss: 9.511180820709342e-08\n",
      "\n",
      "Early stopping: 200th training complete in 0h 5m 58s\n",
      "----------\n",
      "Best train MSELoss: 9.948158208317182e-08\n",
      "Best test MSELoss: 9.491738097722192e-08\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "since = time.time()\n",
    "\n",
    "for epoch in range(last_epoch+1,num_epochs+1):   \n",
    "\n",
    "    if epoch%num_epochs_print == 0:\n",
    "        print()\n",
    "        print('Epoch {}/{}, Learning rate {}'.format(\n",
    "            epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "        print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and test phase\n",
    "    for phase in ['train', 'test']:\n",
    "        if phase == 'train':\n",
    "            encoder_u.train()  # Set model to training mode\n",
    "            decoder_u.train()  # Set model to training mode\n",
    "        else:\n",
    "            encoder_u.eval()   # Set model to evaluation mode\n",
    "            decoder_u.eval()   # Set model to evaluation mode\n",
    "            \n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Iterate over data\n",
    "        for data, in data_loaders_u[phase]:\n",
    "            inputs = data.to(device)\n",
    "            targets = data.to(device)\n",
    "\n",
    "            if phase == 'train':\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = decoder_u(encoder_u(inputs))\n",
    "                loss = loss_func(outputs, targets)\n",
    "\n",
    "                # backward\n",
    "                loss.backward()\n",
    "\n",
    "                # optimize\n",
    "                optimizer.step()  \n",
    "\n",
    "                # add running loss\n",
    "                running_loss += loss.item()*inputs.shape[0]\n",
    "            else:\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    outputs = decoder_u(encoder_u(inputs))\n",
    "                    running_loss += loss_func(outputs,targets).item()*inputs.shape[0]\n",
    "\n",
    "        # compute epoch loss\n",
    "        epoch_loss = running_loss / dataset_u_shapes[phase][0]\n",
    "        loss_hist[phase].append(epoch_loss)\n",
    "            \n",
    "        # update learning rate\n",
    "        if phase == 'train':\n",
    "            scheduler.step(epoch_loss)\n",
    "\n",
    "        if epoch%num_epochs_print == 0:\n",
    "            print('{} MSELoss: {}'.format(\n",
    "                phase, epoch_loss))\n",
    "\n",
    "    # deep copy the model\n",
    "    if round(loss_hist['test'][-1],10) < round(best_loss,10):\n",
    "        best_loss = loss_hist['test'][-1]\n",
    "        early_stop_counter = 1\n",
    "        best_encoder_u_wts = copy.deepcopy(encoder_u.state_dict())\n",
    "        best_decoder_u_wts = copy.deepcopy(decoder_u.state_dict())\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= early_stop_patience:  \n",
    "            break\n",
    "    \n",
    "    # save checkpoint every num_epoch_print\n",
    "    if epoch%num_epochs_print== 0:\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'encoder_u_state_dict': encoder_u.state_dict(),\n",
    "                    'decoder_u_state_dict': decoder_u.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss_hist': loss_hist,\n",
    "                    'best_loss': best_loss,\n",
    "                    'early_stop_counter': early_stop_counter,\n",
    "                    'best_encoder_u_wts': best_encoder_u_wts,\n",
    "                    'best_decoder_u_wts': best_decoder_u_wts,\n",
    "                    }, PATH_u)        \n",
    "\n",
    "print()\n",
    "print('Epoch {}/{}, Learning rate {}'\\\n",
    "      .format(epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "print('-' * 10)\n",
    "print('train MSELoss: {}'.format(loss_hist['train'][-1]))\n",
    "print('test MSELoss: {}'.format(loss_hist['test'][-1]))\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "\n",
    "# load best model weights\n",
    "encoder_u.load_state_dict(best_encoder_u_wts)\n",
    "decoder_u.load_state_dict(best_decoder_u_wts)\n",
    "\n",
    "# compute best train MSELoss\n",
    "encoder_u.to('cpu').eval()\n",
    "decoder_u.to('cpu').eval()\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    train_inputs = torch.tensor(data_u[train_ind])\n",
    "    train_targets = torch.tensor(data_u[train_ind])\n",
    "    train_outputs = decoder_u(encoder_u(train_inputs))\n",
    "    train_loss = loss_func(train_outputs,train_targets).item()\n",
    "\n",
    "# print out training time and best results\n",
    "print()\n",
    "if epoch < num_epochs:\n",
    "    print('Early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "else:\n",
    "    print('No early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "print('-' * 10)\n",
    "print('Best train MSELoss: {}'.format(train_loss))\n",
    "print('Best test MSELoss: {}'.format(best_loss))\n",
    "\n",
    "# # save models\n",
    "# print()\n",
    "# print(\"Saving after {}th training to\".format(epoch),file_name_AE_u)\n",
    "# torch.save((encoder_u,decoder_u),file_name_AE_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "checkpoint removed\n"
     ]
    }
   ],
   "source": [
    "# delete checkpoint\n",
    "try:\n",
    "    os.remove(PATH_u)\n",
    "    print()\n",
    "    print(\"checkpoint removed\")\n",
    "except:\n",
    "    print(\"no checkpoint exists\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and test loss\n",
    "plt.figure()\n",
    "plt.semilogy(loss_hist['train'])\n",
    "plt.semilogy(loss_hist['test'])\n",
    "plt.legend(['train','test'])\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------checkpoint not restored--------\n",
      "\n",
      "\n",
      "Start first training... m=3364, f=15, a=2, b=100, db=10\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "try:\n",
    "    checkpoint = torch.load(PATH_v, map_location=device)\n",
    "    \n",
    "    encoder_v = Encoder(m,M1,f).to(device)\n",
    "    decoder_v = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    prune.custom_from_mask(decoder_v.full[2], name='weight', mask=torch.tensor(mask_2d).to(device))    \n",
    "       \n",
    "    optimizer = torch.optim.Adam(list(encoder_v.parameters()) + list(decoder_v.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    encoder_v.load_state_dict(checkpoint['encoder_v_state_dict'])\n",
    "    decoder_v.load_state_dict(checkpoint['decoder_v_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    last_epoch = checkpoint['epoch']\n",
    "    loss_hist = checkpoint['loss_hist']\n",
    "    best_loss = checkpoint['best_loss']\n",
    "    early_stop_counter = checkpoint['early_stop_counter']\n",
    "    best_encoder_v_wts = checkpoint['best_encoder_v_wts']\n",
    "    best_decoder_v_wts = checkpoint['best_decoder_v_wts']\n",
    "    \n",
    "    print(\"\\n--------checkpoint restored--------\\n\")\n",
    "    \n",
    "    # resume training\n",
    "    print(\"\")\n",
    "    print('Re-start {}th training... m={}, f={}, a={}, b={}, db={}'.format(\n",
    "        last_epoch+1, m, f, a, b, db))\n",
    "except:\n",
    "    encoder_v = Encoder(m,M1,f).to(device)\n",
    "    decoder_v = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    prune.custom_from_mask(decoder_v.full[2], name='weight', mask=torch.tensor(mask_2d).to(device))\n",
    "\n",
    "    optimizer = torch.optim.Adam(list(encoder_v.parameters()) + list(decoder_v.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    last_epoch = 0\n",
    "    loss_hist = {'train':[],'test':[]}\n",
    "    best_loss = float(\"inf\")\n",
    "    early_stop_counter = 1\n",
    "    best_encoder_v_wts = copy.deepcopy(encoder_v.state_dict())\n",
    "    best_decoder_v_wts = copy.deepcopy(decoder_v.state_dict())\n",
    "    \n",
    "    print(\"\\n--------checkpoint not restored--------\\n\")\n",
    "\n",
    "    # start training\n",
    "    print(\"\")\n",
    "    print('Start first training... m={}, f={}, a={}, b={}, db={}'.format(\n",
    "        m, f, a, b, db))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 4.000403554107943e-06\n",
      "test MSELoss: 3.914536046067952e-06\n",
      "\n",
      "Epoch 200/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 2.4592980650166734e-06\n",
      "test MSELoss: 2.405353234280483e-06\n",
      "\n",
      "Epoch 300/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 1.3809910612005366e-06\n",
      "test MSELoss: 1.349328954347584e-06\n",
      "\n",
      "Epoch 400/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 7.864925715777448e-07\n",
      "test MSELoss: 7.52580774587841e-07\n",
      "\n",
      "Epoch 500/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 4.795707872689767e-07\n",
      "test MSELoss: 4.70763870907831e-07\n",
      "\n",
      "Epoch 600/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 4.454007319879325e-07\n",
      "test MSELoss: 4.359119088803709e-07\n",
      "\n",
      "Epoch 700/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 4.000502471039501e-07\n",
      "test MSELoss: 3.937116900942783e-07\n",
      "\n",
      "Epoch 800/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 3.4854711883596965e-07\n",
      "test MSELoss: 3.424210319735721e-07\n",
      "\n",
      "Epoch 900/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.9992760295099586e-07\n",
      "test MSELoss: 2.926230763478088e-07\n",
      "\n",
      "Epoch 1000/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.558842318105166e-07\n",
      "test MSELoss: 2.5265082967962373e-07\n",
      "\n",
      "Epoch 1100/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.2345425679094715e-07\n",
      "test MSELoss: 2.1934613414487103e-07\n",
      "\n",
      "Epoch 1200/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.9628072679616425e-07\n",
      "test MSELoss: 1.9249272327215293e-07\n",
      "\n",
      "Epoch 1300/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.7494421133787028e-07\n",
      "test MSELoss: 1.7294522933752887e-07\n",
      "\n",
      "Epoch 1400/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.5653341700263244e-07\n",
      "test MSELoss: 1.5423525496771616e-07\n",
      "\n",
      "Epoch 1500/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.4294167756970523e-07\n",
      "test MSELoss: 1.4339802305585182e-07\n",
      "\n",
      "Epoch 1600/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.3145253244236706e-07\n",
      "test MSELoss: 1.2987742081804754e-07\n",
      "\n",
      "Epoch 1700/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.209422524250599e-07\n",
      "test MSELoss: 1.196147479731735e-07\n",
      "\n",
      "Epoch 1800/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 1.1045433872577814e-07\n",
      "test MSELoss: 1.0953792610735036e-07\n",
      "\n",
      "Epoch 1900/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 1.0950147090182116e-07\n",
      "test MSELoss: 1.0866630475447892e-07\n",
      "\n",
      "Epoch 2000/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 1.0850790931188245e-07\n",
      "test MSELoss: 1.07597435317075e-07\n",
      "\n",
      "Epoch 2100/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 1.0737163371454197e-07\n",
      "test MSELoss: 1.065640972797155e-07\n",
      "\n",
      "Epoch 2200/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 1.062902093972291e-07\n",
      "test MSELoss: 1.0528786731356377e-07\n",
      "\n",
      "Epoch 2300/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 1.0508737756687423e-07\n",
      "test MSELoss: 1.0426716130496061e-07\n",
      "\n",
      "Epoch 2400/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 1.0398873776154111e-07\n",
      "test MSELoss: 1.031138793905484e-07\n",
      "\n",
      "Epoch 2500/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 1.029835664082009e-07\n",
      "test MSELoss: 1.0209295595586809e-07\n",
      "\n",
      "Epoch 2600/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 1.0183006523534227e-07\n",
      "test MSELoss: 1.0095597815507063e-07\n",
      "\n",
      "Epoch 2700/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 1.0080820626780345e-07\n",
      "test MSELoss: 9.991453708835252e-08\n",
      "\n",
      "Epoch 2800/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 9.987673406898153e-08\n",
      "test MSELoss: 9.913741934042264e-08\n",
      "\n",
      "Epoch 2900/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 9.88163855168662e-08\n",
      "test MSELoss: 9.802900962085914e-08\n",
      "\n",
      "Epoch 3000/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 9.782435947236613e-08\n",
      "test MSELoss: 9.704005492494616e-08\n",
      "\n",
      "Epoch 3100/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 9.693506695216076e-08\n",
      "test MSELoss: 9.606077071566687e-08\n",
      "\n",
      "Epoch 3200/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 9.63122094658724e-08\n",
      "test MSELoss: 9.564116822957658e-08\n",
      "\n",
      "Epoch 3300/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 9.630424694305266e-08\n",
      "test MSELoss: 9.563240439547372e-08\n",
      "\n",
      "Epoch 3330/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 9.630156291125824e-08\n",
      "test MSELoss: 9.562810561192237e-08\n",
      "\n",
      "Early stopping: 3330th training complete in 1h 50m 51s\n",
      "----------\n",
      "Best train MSELoss: 9.63304032097767e-08\n",
      "Best test MSELoss: 9.564520553340117e-08\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "since = time.time()\n",
    "\n",
    "for epoch in range(last_epoch+1,num_epochs+1):   \n",
    "\n",
    "    if epoch%num_epochs_print == 0:\n",
    "        print()\n",
    "        print('Epoch {}/{}, Learning rate {}'.format(\n",
    "            epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "        print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and test phase\n",
    "    for phase in ['train', 'test']:\n",
    "        if phase == 'train':\n",
    "            encoder_v.train()  # Set model to training mode\n",
    "            decoder_v.train()  # Set model to training mode\n",
    "        else:\n",
    "            encoder_v.eval()   # Set model to evaluation mode\n",
    "            decoder_v.eval()   # Set model to evaluation mode\n",
    "            \n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Iterate over data\n",
    "        for data, in data_loaders_v[phase]:\n",
    "            inputs = data.to(device)\n",
    "            targets = data.to(device)\n",
    "\n",
    "            if phase == 'train':\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = decoder_v(encoder_v(inputs))\n",
    "                loss = loss_func(outputs, targets)\n",
    "\n",
    "                # backward\n",
    "                loss.backward()\n",
    "\n",
    "                # optimize\n",
    "                optimizer.step()  \n",
    "\n",
    "                # add running loss\n",
    "                running_loss += loss.item()*inputs.shape[0]\n",
    "            else:\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    outputs = decoder_v(encoder_v(inputs))\n",
    "                    running_loss += loss_func(outputs,targets).item()*inputs.shape[0]\n",
    "\n",
    "        # compute epoch loss\n",
    "        epoch_loss = running_loss / dataset_v_shapes[phase][0]\n",
    "        loss_hist[phase].append(epoch_loss)\n",
    "            \n",
    "        # update learning rate\n",
    "        if phase == 'train':\n",
    "            scheduler.step(epoch_loss)\n",
    "\n",
    "        if epoch%num_epochs_print == 0:\n",
    "            print('{} MSELoss: {}'.format(\n",
    "                phase, epoch_loss))\n",
    "\n",
    "    # deep copy the model\n",
    "    if round(loss_hist['test'][-1],10) < round(best_loss,10):\n",
    "        best_loss = loss_hist['test'][-1]\n",
    "        early_stop_counter = 1\n",
    "        best_encoder_v_wts = copy.deepcopy(encoder_v.state_dict())\n",
    "        best_decoder_v_wts = copy.deepcopy(decoder_v.state_dict())\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= early_stop_patience:  \n",
    "            break\n",
    "    \n",
    "    # save checkpoint every num_epoch_print\n",
    "    if epoch%num_epochs_print== 0:\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'encoder_v_state_dict': encoder_v.state_dict(),\n",
    "                    'decoder_v_state_dict': decoder_v.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss_hist': loss_hist,\n",
    "                    'best_loss': best_loss,\n",
    "                    'early_stop_counter': early_stop_counter,\n",
    "                    'best_encoder_v_wts': best_encoder_v_wts,\n",
    "                    'best_decoder_v_wts': best_decoder_v_wts,\n",
    "                    }, PATH_v)        \n",
    "\n",
    "print()\n",
    "print('Epoch {}/{}, Learning rate {}'\\\n",
    "      .format(epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "print('-' * 10)\n",
    "print('train MSELoss: {}'.format(loss_hist['train'][-1]))\n",
    "print('test MSELoss: {}'.format(loss_hist['test'][-1]))\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "\n",
    "# load best model weights\n",
    "encoder_v.load_state_dict(best_encoder_v_wts)\n",
    "decoder_v.load_state_dict(best_decoder_v_wts)\n",
    "\n",
    "# compute best train MSELoss\n",
    "encoder_v.to('cpu').eval()\n",
    "decoder_v.to('cpu').eval()\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    train_inputs = torch.tensor(data_v[train_ind])\n",
    "    train_targets = torch.tensor(data_v[train_ind])\n",
    "    train_outputs = decoder_v(encoder_v(train_inputs))\n",
    "    train_loss = loss_func(train_outputs,train_targets).item()\n",
    "\n",
    "# print out training time and best results\n",
    "print()\n",
    "if epoch < num_epochs:\n",
    "    print('Early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "else:\n",
    "    print('No early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "print('-' * 10)\n",
    "print('Best train MSELoss: {}'.format(train_loss))\n",
    "print('Best test MSELoss: {}'.format(best_loss))\n",
    "\n",
    "# # save models\n",
    "# print()\n",
    "# print(\"Saving after {}th training to\".format(epoch),file_name_AE_v)\n",
    "# torch.save((encoder_v,decoder_v),file_name_AE_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "checkpoint removed\n"
     ]
    }
   ],
   "source": [
    "# delete checkpoint\n",
    "try:\n",
    "    os.remove(PATH_v)\n",
    "    print()\n",
    "    print(\"checkpoint removed\")\n",
    "except:\n",
    "    print(\"no checkpoint exists\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and test loss\n",
    "plt.figure()\n",
    "plt.semilogy(loss_hist['train'])\n",
    "plt.semilogy(loss_hist['test'])\n",
    "plt.legend(['train','test'])\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load models\n",
    "# try:\n",
    "#     encoder_u,decoder_u = torch.load(file_name_AE_u,map_location='cpu')\n",
    "#     encoder_v,decoder_v = torch.load(file_name_AE_v,map_location='cpu')\n",
    "#     print(\"\\n--------model restored--------\\n\")\n",
    "# except:\n",
    "#     print(\"\\n--------model not restored--------\\n\")\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights and bias\n",
    "en_wu1_s=encoder_u.full[0].weight.detach().numpy().astype('float32')\n",
    "en_bu1=encoder_u.full[0].bias.detach().numpy().astype('float32')\n",
    "en_wu2=encoder_u.full[2].weight.detach().numpy().astype('float32')\n",
    "\n",
    "en_wv1_s=encoder_v.full[0].weight.detach().numpy().astype('float32')\n",
    "en_bv1=encoder_v.full[0].bias.detach().numpy().astype('float32')\n",
    "en_wv2=encoder_v.full[2].weight.detach().numpy().astype('float32')\n",
    "\n",
    "de_wu1=decoder_u.full[0].weight.detach().numpy().astype('float32')\n",
    "de_bu1=decoder_u.full[0].bias.detach().numpy().astype('float32')\n",
    "de_wu2_s=decoder_u.full[2].weight.detach().numpy().astype('float32')\n",
    "\n",
    "de_wv1=decoder_v.full[0].weight.detach().numpy().astype('float32')\n",
    "de_bv1=decoder_v.full[0].bias.detach().numpy().astype('float32')\n",
    "de_wv2_s=decoder_v.full[2].weight.detach().numpy().astype('float32')\n",
    "\n",
    "de_wu2_s_sp=sp.csr_matrix(de_wu2_s,dtype='float32')\n",
    "de_wv2_s_sp=sp.csr_matrix(de_wv2_s,dtype='float32')\n",
    "\n",
    "# rescale weights\n",
    "en_wu1=en_wu1_s*u_scale_reciprocal\n",
    "en_wv1=en_wv1_s*v_scale_reciprocal\n",
    "\n",
    "de_wu1T=de_wu1.T\n",
    "de_wv1T=de_wv1.T\n",
    "\n",
    "de_wu2T=u_scale*de_wu2_s.T\n",
    "de_wv2T=v_scale*de_wv2_s.T\n",
    "\n",
    "de_wu2=de_wu2T.T\n",
    "de_wv2=de_wv2T.T\n",
    "\n",
    "de_wu2_sp=sp.csr_matrix(de_wu2,dtype='float32')\n",
    "de_wv2_sp=sp.csr_matrix(de_wv2,dtype='float32')\n",
    "\n",
    "de_wu2T_sp=de_wu2_sp.T\n",
    "de_wv2T_sp=de_wv2_sp.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy version of AE\n",
    "def sigmoid_np(input):\n",
    "    return (1.0/(1.0+np.exp(-input))).astype('float32')\n",
    "\n",
    "def encoder_u_np_forward(x):\n",
    "    z1 = en_wu1.dot(x) + en_bu1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = en_wu2.dot(a1)   \n",
    "    return y\n",
    "\n",
    "def decoder_u_np_forward(x):\n",
    "    z1 = de_wu1.dot(x) + de_bu1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = de_wu2.dot(a1)  \n",
    "    return y\n",
    "\n",
    "def decoder_u_sp_forward(x):\n",
    "    z1 = de_wu1.dot(x) + de_bu1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = sp.csr_matrix.dot(de_wu2_sp,a1)\n",
    "    return y\n",
    "\n",
    "def encoder_v_np_forward(x):\n",
    "    z1 = en_wv1.dot(x) + en_bv1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = en_wv2.dot(a1)   \n",
    "    return y\n",
    "\n",
    "def decoder_v_np_forward(x):\n",
    "    z1 = de_wv1.dot(x) + de_bv1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = de_wv2.dot(a1)   \n",
    "    return y\n",
    "\n",
    "def decoder_v_sp_forward(x):\n",
    "    z1 = de_wv1.dot(x) + de_bv1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = sp.csr_matrix.dot(de_wv2_sp,a1)\n",
    "    return y\n",
    "\n",
    "def decoder_u_np_forward_backwardT(x):\n",
    "    z1 = de_wu1.dot(x) + de_bu1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = de_wu2.dot(a1)\n",
    "\n",
    "    dout = de_wu1T\n",
    "    dout = (a1*(1-a1))*dout\n",
    "    dydxT = dout.dot(de_wu2T)   \n",
    "    return y,dydxT\n",
    "\n",
    "def decoder_u_sp_forward_backwardT(x):\n",
    "    z1 = de_wu1.dot(x) + de_bu1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = sparse.csr_matrix.dot(de_wu2_sp,a1)\n",
    "\n",
    "    dout = de_wu1T\n",
    "    dout = (a1*(1-a1))*dout\n",
    "    dydxT = sp.csr_matrix.dot(dout,de_wu2T_sp)\n",
    "    return y,dydxT\n",
    "\n",
    "def decoder_v_np_forward_backwardT(x):\n",
    "    z1 = de_wv1.dot(x) + de_bv1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = de_wv2.dot(a1)\n",
    "\n",
    "    dout = de_wv1T\n",
    "    dout = (a1*(1-a1))*dout\n",
    "    dydxT = dout.dot(de_wv2T)   \n",
    "    return y,dydxT\n",
    "\n",
    "def decoder_v_sp_forward_backwardT(x):\n",
    "    z1 = de_wv1.dot(x) + de_bv1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = sp.csr_matrix.dot(de_wv2_sp,a1)\n",
    "\n",
    "    dout = de_wv1T\n",
    "    dout = (a1*(1-a1))*dout\n",
    "    dydxT = sp.csr_matrix.dot(dout,de_wv2T_sp)\n",
    "    return y,dydxT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE u: 3.11533540e-08\n",
      "MSELoss of AE v: 3.03391934e-08\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss\n",
    "comp_orig_data_u=np.zeros((ndata,f))\n",
    "comp_orig_data_v=np.zeros((ndata,f))\n",
    "\n",
    "rest_orig_data_u=np.zeros(orig_data_u.shape)\n",
    "rest_orig_data_v=np.zeros(orig_data_u.shape)\n",
    "\n",
    "for k in range(ndata):\n",
    "    comp_orig_data_u[k]=encoder_u_np_forward(orig_data_u[k]-u_ref)\n",
    "    comp_orig_data_v[k]=encoder_v_np_forward(orig_data_v[k]-v_ref)\n",
    "    \n",
    "    rest_orig_data_u[k]=decoder_u_sp_forward(comp_orig_data_u[k]) + u_ref\n",
    "    rest_orig_data_v[k]=decoder_v_sp_forward(comp_orig_data_v[k]) + v_ref\n",
    "    \n",
    "print(\"MSELoss of AE u: {:.8e}\".format(np.linalg.norm(orig_data_u-rest_orig_data_u)**2/np.prod(orig_data_u.shape)))\n",
    "print(\"MSELoss of AE v: {:.8e}\".format(np.linalg.norm(orig_data_v-rest_orig_data_v)**2/np.prod(orig_data_v.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale AE\n",
    "en_weight_u_s=encoder_u.full[0].weight.data\n",
    "en_weight_u=en_weight_u_s*torch.tensor(u_scale_reciprocal)\n",
    "encoder_u.full[0].weight=nn.Parameter(en_weight_u)\n",
    "\n",
    "de_weight_u_s=decoder_u.full[2].weight.data\n",
    "de_weight_u=(torch.tensor(u_scale)*de_weight_u_s.T).T\n",
    "de_weight_u_mask=decoder_u.full[2].weight_mask.data\n",
    "prune.remove(decoder_u.full[2],'weight');\n",
    "decoder_u.full[2].weight=nn.Parameter(de_weight_u)\n",
    "prune.custom_from_mask(decoder_u.full[2], name='weight', mask=de_weight_u_mask);\n",
    "\n",
    "en_weight_v_s=encoder_v.full[0].weight.data\n",
    "en_weight_v=en_weight_v_s*torch.tensor(v_scale_reciprocal)\n",
    "encoder_v.full[0].weight=nn.Parameter(en_weight_v)\n",
    "\n",
    "de_weight_v_s=decoder_v.full[2].weight.data\n",
    "de_weight_v=(torch.tensor(v_scale)*de_weight_v_s.T).T\n",
    "de_weight_v_mask=decoder_v.full[2].weight_mask.data\n",
    "prune.remove(decoder_v.full[2],'weight');\n",
    "decoder_v.full[2].weight=nn.Parameter(de_weight_v)\n",
    "prune.custom_from_mask(decoder_v.full[2], name='weight', mask=de_weight_v_mask);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE u: 3.11526307e-08\n",
      "MSELoss of AE v: 3.03384624e-08\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss\n",
    "input_u=torch.tensor(orig_data_u-u_ref)\n",
    "target_u=decoder_u(encoder_u(input_u))\n",
    "\n",
    "input_v=torch.tensor(orig_data_v-v_ref)\n",
    "target_v=decoder_v(encoder_v(input_v))\n",
    "\n",
    "print(\"MSELoss of AE u: {:.8e}\".format(torch.nn.functional.mse_loss(input_u,target_u).detach().item()))\n",
    "print(\"MSELoss of AE v: {:.8e}\".format(torch.nn.functional.mse_loss(input_v,target_v).detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE u (predictive case): 4.54463134e-08\n",
      "MSELoss of AE v (predictive case): 4.58674272e-08\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (predictive case)\n",
    "if Re==10000:\n",
    "    FOM_solution=pickle.load(open('./data/FOM_high_Re.p','rb'))\n",
    "elif Re==100:\n",
    "    FOM_solution=pickle.load(open('./data/FOM_loq_Re.p','rb'))\n",
    "else:\n",
    "    raise NameError('{} is given for Re, but it must be either 100 or 10000'.format(Re))\n",
    "    \n",
    "u_full=FOM_solution['u'].astype('float32')\n",
    "v_full=FOM_solution['v'].astype('float32')\n",
    "\n",
    "orig_data_u_FOM = u_full[:,free_raveled_indicies]\n",
    "orig_data_v_FOM = v_full[:,free_raveled_indicies]\n",
    "\n",
    "input_u_FOM=torch.tensor(orig_data_u_FOM-u_ref)\n",
    "target_u_FOM=decoder_u(encoder_u(input_u_FOM))\n",
    "\n",
    "input_v_FOM=torch.tensor(orig_data_v_FOM-v_ref)\n",
    "target_v_FOM=decoder_v(encoder_v(input_v_FOM))\n",
    "\n",
    "print(\"MSELoss of AE u (predictive case): {:.8e}\"\\\n",
    "      .format(torch.nn.functional.mse_loss(input_u_FOM,target_u_FOM).detach().item()))\n",
    "print(\"MSELoss of AE v (predictive case): {:.8e}\"\\\n",
    "      .format(torch.nn.functional.mse_loss(input_v_FOM,target_v_FOM).detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # generate mesh grid\n",
    "# [xv,yv]=np.meshgrid(np.linspace(0,1,nx),np.linspace(0,1,ny),indexing='xy')\n",
    "# x=xv.flatten()\n",
    "# y=yv.flatten()\n",
    "\n",
    "# x_free=x[free_raveled_indicies]\n",
    "# y_free=y[free_raveled_indicies]\n",
    "\n",
    "# k=-1\n",
    "\n",
    "# # plot origianl data\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_u[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_u[k].reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Original $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_v[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_v[k].reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Original $v$')\n",
    "# plt.show()\n",
    "\n",
    "# # plot compressed data\n",
    "# plt.figure()\n",
    "# plt.plot(comp_orig_data_u[k])\n",
    "# plt.title('Compressed $u$')\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(comp_orig_data_v[k])\n",
    "# plt.title('Compressed $v$')\n",
    "# plt.show()\n",
    "\n",
    "# # plot restored data\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_orig_data_u[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_orig_data_u[k].reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Restored $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_orig_data_v[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_orig_data_v[k].reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Restored $v$')\n",
    "# plt.show()\n",
    "\n",
    "# # plot relative error\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), (orig_data_u[k]-rest_orig_data_u[k]).reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), (orig_data_u[k]-rest_orig_data_u[k]).reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Difference $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), (orig_data_v[k]-rest_orig_data_v[k]).reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), (orig_data_v[k]-rest_orig_data_v[k]).reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Difference $v$')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights and references   \n",
    "AE={'en_wu1':en_wu1,'en_bu1':en_bu1,'en_wu2':en_wu2,\n",
    "    'de_wu1':de_wu1,'de_bu1':de_bu1,'de_wu2':de_wu2,\n",
    "    'de_wu1T':de_wu1T,'de_wu2T':de_wu2T,'de_wu2_sp':de_wu2_sp,'de_wu2T_sp':de_wu2T_sp,'u_ref':u_ref,\n",
    "    'en_wv1':en_wv1,'en_bv1':en_bv1,'en_wv2':en_wv2,\n",
    "    'de_wv1':de_wv1,'de_bv1':de_bv1,'de_wv2':de_wv2,\n",
    "    'de_wv1T':de_wv1T,'de_wv2T':de_wv2T,'de_wv2_sp':de_wv2_sp,'de_wv2T_sp':de_wv2T_sp,'v_ref':v_ref}\n",
    "\n",
    "pickle.dump(AE,open(file_name_AE,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
