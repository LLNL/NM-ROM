{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.prune as prune\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "from scipy import sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import sys,time\n",
    "import os\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "redDim=35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set print option\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "# Choose device that is not being used\n",
    "gpu_ids = \"2\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=gpu_ids\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given parameters\n",
    "nx = 60\n",
    "ny = 60\n",
    "m = (ny-2)*(nx-2) # 3364\n",
    "nt = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose either Re=10000 or Re=100\n",
    "Re = 10000 \n",
    "    \n",
    "# Choose data normalize option (option 1: -1<=X<=1 option 2: 0<=X<=1)\n",
    "option = 2\n",
    "\n",
    "# Choose activation function (sigmoid, swish)\n",
    "activation = 'sigmoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set batch_size, number of epochs, paitience for early stop\n",
    "batch_size = 480\n",
    "num_epochs = 10000\n",
    "num_epochs_print = num_epochs//100\n",
    "early_stop_patience = num_epochs//50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_mask(m,b,db):\n",
    "    \n",
    "#     M2 = b + db*(m-1)\n",
    "#     mask = np.zeros((m,M2),dtype='int8')\n",
    "    \n",
    "#     block = np.ones(b,dtype='int8')\n",
    "#     ind = np.arange(b)\n",
    "#     for row in range(m):\n",
    "#         col = ind + row*db\n",
    "#         mask[row,col] = block      \n",
    "\n",
    "# #     for row in range(nx-2,m):\n",
    "# #         col = ind + (row-1)*db\n",
    "# #         mask[row-(nx-2),col] = block    \n",
    "# #     for row in range(0,m-(nx-2)):\n",
    "# #         col = ind + (row+1)*db\n",
    "# #         mask[row+(nx-2),col] = block\n",
    "                   \n",
    "#     print(\n",
    "#         \"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "#             m, M2, (1.0-np.count_nonzero(mask)/mask.size)*100\n",
    "#         )\n",
    "#     )\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.spy(mask)\n",
    "#     plt.show()\n",
    "\n",
    "#     return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_2d(m,b,db):\n",
    "    \n",
    "    # local\n",
    "    Mb=sp.diags([np.ones(nx-2),np.ones(nx-2),np.ones(nx-2)],[0,-1,1],(nx-2,nx-2))\n",
    "    M=sp.kron(sp.eye(ny-2),Mb,format=\"csr\")\n",
    "\n",
    "    Ib=sp.eye(nx-2)\n",
    "    N=sp.kron(sp.diags([np.ones(ny-2),np.ones(ny-2),np.ones(ny-2)],[0,-1,1],(ny-2,ny-2)),Ib,format=\"csr\")\n",
    "\n",
    "    local=(M+N).astype('int8')\n",
    "    I,J,V=sp.find(local)\n",
    "    local[I,J]=1\n",
    "    \n",
    "#     col_ind=np.array([],dtype='int')\n",
    "#     row_ind=np.array([],dtype='int')\n",
    "\n",
    "#     for lin_ind in range(m):\n",
    "#         j,i=np.unravel_index(lin_ind,(ny-2,nx-2))\n",
    "\n",
    "#         E=np.ravel_multi_index((j,np.max((i-1,0))),(ny-2,nx-2))\n",
    "#         W=np.ravel_multi_index((j,np.min((i+1,nx-2-1))),(ny-2,nx-2))\n",
    "#         S=np.ravel_multi_index((np.max((j-1,0)),i),(ny-2,nx-2))\n",
    "#         N=np.ravel_multi_index((np.min((j+1,ny-2-1)),i),(ny-2,nx-2))\n",
    "\n",
    "#         col=np.unique([lin_ind,E,W,S,N])\n",
    "#         row=lin_ind*np.ones(col.size,dtype='int')\n",
    "\n",
    "#         col_ind=np.append(col_ind,col)\n",
    "#         row_ind=np.append(row_ind,row)\n",
    "\n",
    "#     data=np.ones(row_ind.size,dtype='int')\n",
    "#     local2=sp.csr_matrix((data,(row_ind,col_ind)),shape=(m,m))\n",
    "\n",
    "    # basis\n",
    "    M2 = int(b + db*(m-1))\n",
    "    basis = np.zeros((m,M2),dtype='int8')\n",
    "\n",
    "    block = np.ones(b,dtype='int8')\n",
    "    ind = np.arange(b)\n",
    "    for row in range(m):\n",
    "        col = ind + row*db\n",
    "        basis[row,col] = block\n",
    "    \n",
    "    # mask\n",
    "    col_ind=np.array([],dtype='int8')\n",
    "    row_ind=np.array([],dtype='int8')\n",
    "    for i in range(m):\n",
    "        col=basis[sp.find(local[i])[1]].sum(axis=0).nonzero()[0]\n",
    "        row=i*np.ones(col.size)\n",
    "\n",
    "        col_ind=np.append(col_ind,col)\n",
    "        row_ind=np.append(row_ind,row)\n",
    "\n",
    "    data=np.ones(row_ind.size,dtype='int8')\n",
    "    mask=sp.csr_matrix((data,(row_ind,col_ind)),shape=(m,M2)).toarray()\n",
    "    \n",
    "    print(\n",
    "        \"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "            m, M2, (1.0-np.count_nonzero(mask)/np.prod(mask.shape))*100\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.spy(mask)\n",
    "    plt.show()\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if activation=='sigmoid':\n",
    "    class Encoder(nn.Module):\n",
    "        def __init__(self,m,M1,f):\n",
    "            super(Encoder,self).__init__()\n",
    "            self.full = nn.Sequential(\n",
    "                nn.Linear(m,M1),\n",
    "                nn.Sigmoid(),\n",
    "                nn.Linear(M1,f,bias=False)\n",
    "            )\n",
    "\n",
    "        def forward(self, y):     \n",
    "            y = y.view(-1,m)\n",
    "            T = self.full(y)\n",
    "            T = T.squeeze()\n",
    "\n",
    "            return T\n",
    "\n",
    "    class Decoder(nn.Module):\n",
    "        def __init__(self,f,M2,m):\n",
    "            super(Decoder,self).__init__()\n",
    "            self.full = nn.Sequential(\n",
    "                nn.Linear(f,M2),\n",
    "                nn.Sigmoid(),\n",
    "                nn.Linear(M2,m,bias=False)\n",
    "            )\n",
    "\n",
    "        def forward(self,T):\n",
    "            T = T.view(-1,f)\n",
    "            y = self.full(T)\n",
    "            y = y.squeeze()\n",
    "\n",
    "            return y\n",
    "        \n",
    "elif activation=='swish':\n",
    "    def silu(input):\n",
    "        return input * torch.sigmoid(input)\n",
    "\n",
    "    class SiLU(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "        def forward(self, input):\n",
    "            return silu(input)\n",
    "        \n",
    "    class Encoder(nn.Module):\n",
    "        def __init__(self,m,M1,f):\n",
    "            super(Encoder,self).__init__()\n",
    "            self.full = nn.Sequential(\n",
    "                nn.Linear(m,M1),\n",
    "                SiLU(),\n",
    "                nn.Linear(M1,f,bias=False)\n",
    "            )\n",
    "\n",
    "        def forward(self, y):     \n",
    "            y = y.view(-1,m)\n",
    "            T = self.full(y)\n",
    "            T = T.squeeze()\n",
    "\n",
    "            return T\n",
    "\n",
    "    class Decoder(nn.Module):\n",
    "        def __init__(self,f,M2,m):\n",
    "            super(Decoder,self).__init__()\n",
    "            self.full = nn.Sequential(\n",
    "                nn.Linear(f,M2),\n",
    "                SiLU(),\n",
    "                nn.Linear(M2,m,bias=False)\n",
    "            )\n",
    "\n",
    "        def forward(self,T):\n",
    "            T = T.view(-1,f)\n",
    "            y = self.full(T)\n",
    "            y = y.squeeze()\n",
    "\n",
    "            return y\n",
    "else:\n",
    "    raise NameError('{} is given for option, but it must be either sigmoid or swish'.format(activation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "option 2: 0<=X<=1\n",
      "data shape\n",
      "(6004, 3364)\n",
      "(6004, 3364)\n",
      "maximum abs difference\n",
      "1.1920929e-07\n",
      "1.1920929e-07\n"
     ]
    }
   ],
   "source": [
    "# load snapshot\n",
    "if Re==10000:\n",
    "    file_name_snapshot=\"./data/snapshot_full_high_Re.p\"\n",
    "elif Re==100:\n",
    "    file_name_snapshot=\"./data/snapshot_full_low_Re.p\"\n",
    "else:\n",
    "    raise NameError('{} is given for Re, but it must be either 100 or 10000'.format(Re)) \n",
    "\n",
    "snapshot = pickle.load(open(file_name_snapshot,'rb'))\n",
    "snapshot_u = snapshot['u'].astype('float32')\n",
    "snapshot_v = snapshot['v'].astype('float32')\n",
    "\n",
    "# number of data points\n",
    "ndata = snapshot_u.shape[0]\n",
    "\n",
    "# remove BC\n",
    "multi_index_i,multi_index_j=np.meshgrid(np.arange(nx),np.arange(ny),indexing='xy')\n",
    "full_multi_index=(multi_index_j.flatten(),multi_index_i.flatten())\n",
    "free_multi_index=(multi_index_j[1:-1,1:-1].flatten(),multi_index_i[1:-1,1:-1].flatten())\n",
    "\n",
    "dims=(ny,nx)\n",
    "full_raveled_indicies=np.ravel_multi_index(full_multi_index,dims)\n",
    "free_raveled_indicies=np.ravel_multi_index(free_multi_index,dims)\n",
    "\n",
    "orig_data_u = snapshot_u[:,free_raveled_indicies]\n",
    "orig_data_v = snapshot_v[:,free_raveled_indicies]\n",
    "\n",
    "# normalize data\n",
    "if option==1: # option 1: -1<=X<=1\n",
    "    print(\"option {}: -1<=X<=1\".format(option))\n",
    "#     u_ref = np.mean(orig_data_u,axis=0)\n",
    "#     v_ref = np.mean(orig_data_v,axis=0)   \n",
    "\n",
    "#     u_scale = np.max(orig_data_u,axis=0)-np.min(orig_data_u,axis=0)\n",
    "#     v_scale = np.max(orig_data_v,axis=0)-np.min(orig_data_v,axis=0)   \n",
    "    u_ref = (np.max(orig_data_u,axis=0)+np.min(orig_data_u,axis=0))/2.0\n",
    "    v_ref = (np.max(orig_data_v,axis=0)+np.min(orig_data_v,axis=0))/2.0\n",
    "    \n",
    "    u_scale = (np.max(orig_data_u,axis=0)-np.min(orig_data_u,axis=0))/2.0\n",
    "    v_scale = (np.max(orig_data_v,axis=0)-np.min(orig_data_v,axis=0))/2.0\n",
    "    \n",
    "    u_scale = np.where(u_scale > np.finfo('float32').resolution, u_scale, 1)\n",
    "    v_scale = np.where(v_scale > np.finfo('float32').resolution, v_scale, 1)\n",
    "    \n",
    "    u_scale_reciprocal = np.reciprocal(u_scale)\n",
    "    v_scale_reciprocal = np.reciprocal(v_scale)\n",
    "    \n",
    "    data_u = u_scale_reciprocal*(orig_data_u-u_ref)\n",
    "    data_v = v_scale_reciprocal*(orig_data_v-v_ref)\n",
    "    \n",
    "elif option==2: # option 2: 0<=X<=1\n",
    "    print(\"option {}: 0<=X<=1\".format(option))\n",
    "    u_ref = np.min(orig_data_u,axis=0)\n",
    "    v_ref = np.min(orig_data_v,axis=0)\n",
    "    \n",
    "    u_scale = np.max(orig_data_u,axis=0)-np.min(orig_data_u,axis=0)\n",
    "    v_scale = np.max(orig_data_v,axis=0)-np.min(orig_data_v,axis=0)\n",
    "    \n",
    "    u_scale = np.where(u_scale > np.finfo('float32').resolution, u_scale, 1)\n",
    "    v_scale = np.where(v_scale > np.finfo('float32').resolution, v_scale, 1)\n",
    "    \n",
    "    u_scale_reciprocal = np.reciprocal(u_scale)\n",
    "    v_scale_reciprocal = np.reciprocal(v_scale)\n",
    "    \n",
    "    data_u = u_scale_reciprocal*(orig_data_u-u_ref)\n",
    "    data_v = v_scale_reciprocal*(orig_data_v-v_ref)\n",
    "else:\n",
    "    raise NameError('{} is given for option, but it must be either 1 or 2'.format(option))\n",
    "\n",
    "# check shapes of snapshot\n",
    "print('data shape')\n",
    "print(data_u.shape)\n",
    "print(data_v.shape)\n",
    "\n",
    "# restore data\n",
    "rest_data_u = u_ref + u_scale*data_u\n",
    "rest_data_v = v_ref + v_scale*data_v\n",
    "\n",
    "# check precision\n",
    "print('maximum abs difference')\n",
    "print(np.max(np.abs(orig_data_u-rest_data_u)))\n",
    "print(np.max(np.abs(orig_data_v-rest_data_v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # generate mesh grid\n",
    "# [xv,yv]=np.meshgrid(np.linspace(0,1,nx),np.linspace(0,1,ny),indexing='xy')\n",
    "# x=xv.flatten()\n",
    "# y=yv.flatten()\n",
    "\n",
    "# x_free=x[free_raveled_indicies]\n",
    "# y_free=y[free_raveled_indicies]\n",
    "\n",
    "# k=0\n",
    "\n",
    "# # plot original data\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_u[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_u[k].reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Original $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_v[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_v[k].reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Original $v$')\n",
    "# plt.show()\n",
    "\n",
    "# # plot preprocessed data\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), data_u[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), data_u[k].reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Preprocessed $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), data_v[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), data_v[k].reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Preprocessed $v$')\n",
    "# plt.show()\n",
    "\n",
    "# # plot restored data\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_data_u[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_data_u[k].reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Restored $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_data_v[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_data_v[k].reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Restored $v$')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5404, 3364]) torch.Size([600, 3364])\n",
      "torch.Size([5404, 3364]) torch.Size([600, 3364])\n"
     ]
    }
   ],
   "source": [
    "# define testset and trainset indices\n",
    "nset = round(ndata/(nt+1))\n",
    "test_ind = np.array([],dtype='int')\n",
    "for foo in range(nset):\n",
    "    rand_ind = np.random.permutation(np.arange(foo*(nt+1)+1,(foo+1)*(nt+1)))[:int(0.1*(nt+1))]\n",
    "    test_ind = np.append(test_ind,rand_ind)\n",
    "train_ind = np.setdiff1d(np.arange(ndata),test_ind)\n",
    "\n",
    "# set trainset and testset\n",
    "trainset_u = data_u[train_ind]\n",
    "trainset_v = data_v[train_ind]\n",
    "testset_u = data_u[test_ind] \n",
    "testset_v = data_v[test_ind] \n",
    "\n",
    "# set dataset\n",
    "dataset_u = {'train':data_utils.TensorDataset(torch.tensor(trainset_u,dtype=torch.float32)),\n",
    "           'test':data_utils.TensorDataset(torch.tensor(testset_u,dtype=torch.float32))}\n",
    "dataset_v = {'train':data_utils.TensorDataset(torch.tensor(trainset_v,dtype=torch.float32)),\n",
    "           'test':data_utils.TensorDataset(torch.tensor(testset_v,dtype=torch.float32))}\n",
    "\n",
    "print(dataset_u['train'].tensors[0].shape, dataset_u['test'].tensors[0].shape)\n",
    "print(dataset_v['train'].tensors[0].shape, dataset_v['test'].tensors[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5404, 3364) (600, 3364)\n",
      "(5404, 3364) (600, 3364)\n"
     ]
    }
   ],
   "source": [
    "# compute dataset shapes\n",
    "dataset_u_shapes = {'train':trainset_u.shape,\n",
    "                    'test':testset_u.shape}\n",
    "dataset_v_shapes = {'train':trainset_v.shape,\n",
    "                    'test':testset_v.shape}\n",
    "\n",
    "print(dataset_u_shapes['train'],dataset_u_shapes['test'])\n",
    "print(dataset_v_shapes['train'],dataset_v_shapes['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data loaders\n",
    "train_loader_u = DataLoader(dataset=dataset_u['train'], \n",
    "                          batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "train_loader_v = DataLoader(dataset=dataset_v['train'], \n",
    "                          batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader_u = DataLoader(dataset=dataset_u['test'], \n",
    "                         batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader_v = DataLoader(dataset=dataset_v['test'], \n",
    "                         batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "data_loaders_u = {'train':train_loader_u, 'test':test_loader_u}\n",
    "data_loaders_v = {'train':train_loader_v, 'test':test_loader_v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in 3364 by 33730 mask: 99.06%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder parameters:2.28752000e+07(0.08522GB) Decoder parameters:2.27800000e+06(0.4272GB)\n",
      "Data size:2.01974560e+07(0.07524GB)\n"
     ]
    }
   ],
   "source": [
    "# set the number of nodes in each layer\n",
    "a = 2\n",
    "b = int(100)\n",
    "db = int(10)\n",
    "\n",
    "M1 = int(a*m) # encoder hidden layer\n",
    "M2 = b + (m-1)*db # decoder hidden layer\n",
    "\n",
    "f = redDim # latent dimension\n",
    "\n",
    "# sparsity and shape of mask\n",
    "mask_2d=create_mask_2d(m,b,db)\n",
    "\n",
    "# number of parameters and memory\n",
    "en_para=m*M1+M1+M1*f\n",
    "de_para=f*M2+M2+np.count_nonzero(mask_2d)\n",
    "print('Encoder parameters:{:.8e}({:.4}GB)'.format(en_para,en_para*4/2**30),\\\n",
    "      'Decoder parameters:{:.8e}({:.4}GB)'.format(de_para,(f*M2+M2+M2*m)*4/2**30))\n",
    "\n",
    "# data size\n",
    "data_size=np.prod(orig_data_u.shape)\n",
    "print('Data size:{:.8e}({:.4}GB)'.format(data_size,data_size*4/2**30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file names\n",
    "if Re==10000:\n",
    "    file_name_AE_u=\"./model/AE_u_high_Re_v3_red-dim_{}pkl\".format(redDim)\n",
    "    file_name_AE_v=\"./model/AE_v_high_Re_v3_red-dim_{}.pkl\".format(redDim)\n",
    "    file_name_AE=\"./model/AE_high_Re_v3_red-dim_{}.p\".format(redDim)\n",
    "    \n",
    "    PATH_u = './checkpoint_u_high_Re_v3_red-dim_{}.tar'.format(redDim)\n",
    "    PATH_v = './checkpoint_v_high_Re_v3_red-dim_{}.tar'.format(redDim)\n",
    "elif Re==100:\n",
    "    file_name_AE_u=\"./model/AE_u_low_Re_v3_red-dim_{}.pkl\".format(redDim)\n",
    "    file_name_AE_v=\"./model/AE_v_low_Re_v3_red-dim_{}.pkl\".format(redDim)\n",
    "    file_name_AE=\"./model/AE_low_Re_v_3_red-dim_{}.p\".format(redDim)\n",
    "    \n",
    "    PATH_u = './checkpoint_u_low_Re_v3_red-dim_{}.tar'.format(redDim)\n",
    "    PATH_v = './checkpoint_v_low_Re_v3_red-dim_{}.tar'.format(redDim)\n",
    "else:\n",
    "    raise NameError('{} is given for Re, but it must be either 100 or 10000'.format(Re))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------checkpoint not restored--------\n",
      "\n",
      "\n",
      "Start first training... m=3364, f=35, a=2, b=100, db=10\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "try:\n",
    "    checkpoint = torch.load(PATH_u, map_location=device)\n",
    "    \n",
    "    encoder_u = Encoder(m,M1,f).to(device)\n",
    "    decoder_u = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    prune.custom_from_mask(decoder_u.full[2], name='weight', mask=torch.tensor(mask_2d).to(device))    \n",
    "       \n",
    "    optimizer = torch.optim.Adam(list(encoder_u.parameters()) + list(decoder_u.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    encoder_u.load_state_dict(checkpoint['encoder_u_state_dict'])\n",
    "    decoder_u.load_state_dict(checkpoint['decoder_u_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    last_epoch = checkpoint['epoch']\n",
    "    loss_hist = checkpoint['loss_hist']\n",
    "    best_loss = checkpoint['best_loss']\n",
    "    early_stop_counter = checkpoint['early_stop_counter']\n",
    "    best_encoder_u_wts = checkpoint['best_encoder_u_wts']\n",
    "    best_decoder_u_wts = checkpoint['best_decoder_u_wts']\n",
    "    \n",
    "    print(\"\\n--------checkpoint restored--------\\n\")\n",
    "\n",
    "    # resume training\n",
    "    print(\"\")\n",
    "    print('Re-start {}th training... m={}, f={},a={}, b={}, db={}'.format(\n",
    "        last_epoch+1, m, f, a, b, db))\n",
    "except:\n",
    "    encoder_u = Encoder(m,M1,f).to(device)\n",
    "    decoder_u = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    prune.custom_from_mask(decoder_u.full[2], name='weight', mask=torch.tensor(mask_2d).to(device))\n",
    "\n",
    "    optimizer = torch.optim.Adam(list(encoder_u.parameters()) + list(decoder_u.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    last_epoch = 0\n",
    "    loss_hist = {'train':[],'test':[]}\n",
    "    best_loss = float(\"inf\")\n",
    "    early_stop_counter = 1\n",
    "    best_encoder_u_wts = copy.deepcopy(encoder_u.state_dict())\n",
    "    best_decoder_u_wts = copy.deepcopy(decoder_u.state_dict())\n",
    "    \n",
    "    print(\"\\n--------checkpoint not restored--------\\n\")\n",
    "\n",
    "    # start training\n",
    "    print(\"\")\n",
    "    print('Start first training... m={}, f={}, a={}, b={}, db={}'\\\n",
    "          .format(m, f, a, b, db))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 5.180479858075858e-06\n",
      "test MSELoss: 2.252065678476356e-06\n",
      "\n",
      "Epoch 200/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 1.1340378975043747e-06\n",
      "test MSELoss: 1.1803150300693233e-06\n",
      "\n",
      "Epoch 300/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 7.527581814675532e-07\n",
      "test MSELoss: 7.883692319410329e-07\n",
      "\n",
      "Epoch 400/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 4.800647649728535e-07\n",
      "test MSELoss: 4.941485201470641e-07\n",
      "\n",
      "Epoch 500/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.8864358814546606e-07\n",
      "test MSELoss: 3.0301179663183577e-07\n",
      "\n",
      "Epoch 600/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.7221702145745574e-07\n",
      "test MSELoss: 2.857831759683904e-07\n",
      "\n",
      "Epoch 700/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.4963796718942954e-07\n",
      "test MSELoss: 2.6255237912664596e-07\n",
      "\n",
      "Epoch 800/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.2080450568042112e-07\n",
      "test MSELoss: 2.3366920345324616e-07\n",
      "\n",
      "Epoch 900/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.9278821751381176e-07\n",
      "test MSELoss: 2.0609750208677725e-07\n",
      "\n",
      "Epoch 1000/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.669851776774302e-07\n",
      "test MSELoss: 1.7727820420532225e-07\n",
      "\n",
      "Epoch 1100/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.4526418710302823e-07\n",
      "test MSELoss: 1.560608126283114e-07\n",
      "\n",
      "Epoch 1200/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.2891504692630961e-07\n",
      "test MSELoss: 1.3872082149646303e-07\n",
      "\n",
      "Epoch 1300/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.14822691200822e-07\n",
      "test MSELoss: 1.2218729352753144e-07\n",
      "\n",
      "Epoch 1400/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.0391868612635192e-07\n",
      "test MSELoss: 1.1096354910478112e-07\n",
      "\n",
      "Epoch 1500/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 9.454433125787219e-08\n",
      "test MSELoss: 1.020559210473948e-07\n",
      "\n",
      "Epoch 1600/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 8.64456771963292e-08\n",
      "test MSELoss: 9.379003245157946e-08\n",
      "\n",
      "Epoch 1700/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 8.012465441752209e-08\n",
      "test MSELoss: 8.666953306146752e-08\n",
      "\n",
      "Epoch 1800/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 7.443617317032819e-08\n",
      "test MSELoss: 8.058834453095187e-08\n",
      "\n",
      "Epoch 1900/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 6.989283748683661e-08\n",
      "test MSELoss: 7.521881855154788e-08\n",
      "\n",
      "Epoch 2000/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 6.525562566496643e-08\n",
      "test MSELoss: 7.231042928879105e-08\n",
      "\n",
      "Epoch 2100/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 6.110617558132476e-08\n",
      "test MSELoss: 6.65969693613988e-08\n",
      "\n",
      "Epoch 2200/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 5.8349344165817174e-08\n",
      "test MSELoss: 6.38817695630678e-08\n",
      "\n",
      "Epoch 2300/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 5.474884419757521e-08\n",
      "test MSELoss: 5.91336686284194e-08\n",
      "\n",
      "Epoch 2400/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 5.4396524850755526e-08\n",
      "test MSELoss: 5.871533161894149e-08\n",
      "\n",
      "Epoch 2500/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 5.399920935435463e-08\n",
      "test MSELoss: 5.842425707669463e-08\n",
      "\n",
      "Epoch 2600/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 5.3552474648214404e-08\n",
      "test MSELoss: 5.789442099057851e-08\n",
      "\n",
      "Epoch 2700/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 5.306099196440119e-08\n",
      "test MSELoss: 5.7440334444436306e-08\n",
      "\n",
      "Epoch 2800/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 5.305773962464337e-08\n",
      "test MSELoss: 5.7439477529896975e-08\n",
      "\n",
      "Epoch 2846/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 5.305598353746869e-08\n",
      "test MSELoss: 5.7426047561648376e-08\n",
      "\n",
      "Early stopping: 2846th training complete in 1h 31m 12s\n",
      "----------\n",
      "Best train MSELoss: 5.309676964770915e-08\n",
      "Best test MSELoss: 5.7425768318353223e-08\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "since = time.time()\n",
    "\n",
    "for epoch in range(last_epoch+1,num_epochs+1):   \n",
    "\n",
    "    if epoch%num_epochs_print == 0:\n",
    "        print()\n",
    "        print('Epoch {}/{}, Learning rate {}'.format(\n",
    "            epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "        print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and test phase\n",
    "    for phase in ['train', 'test']:\n",
    "        if phase == 'train':\n",
    "            encoder_u.train()  # Set model to training mode\n",
    "            decoder_u.train()  # Set model to training mode\n",
    "        else:\n",
    "            encoder_u.eval()   # Set model to evaluation mode\n",
    "            decoder_u.eval()   # Set model to evaluation mode\n",
    "            \n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Iterate over data\n",
    "        for data, in data_loaders_u[phase]:\n",
    "            inputs = data.to(device)\n",
    "            targets = data.to(device)\n",
    "\n",
    "            if phase == 'train':\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = decoder_u(encoder_u(inputs))\n",
    "                loss = loss_func(outputs, targets)\n",
    "\n",
    "                # backward\n",
    "                loss.backward()\n",
    "\n",
    "                # optimize\n",
    "                optimizer.step()  \n",
    "\n",
    "                # add running loss\n",
    "                running_loss += loss.item()*inputs.shape[0]\n",
    "            else:\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    outputs = decoder_u(encoder_u(inputs))\n",
    "                    running_loss += loss_func(outputs,targets).item()*inputs.shape[0]\n",
    "\n",
    "        # compute epoch loss\n",
    "        epoch_loss = running_loss / dataset_u_shapes[phase][0]\n",
    "        loss_hist[phase].append(epoch_loss)\n",
    "            \n",
    "        # update learning rate\n",
    "        if phase == 'train':\n",
    "            scheduler.step(epoch_loss)\n",
    "\n",
    "        if epoch%num_epochs_print == 0:\n",
    "            print('{} MSELoss: {}'.format(\n",
    "                phase, epoch_loss))\n",
    "\n",
    "    # deep copy the model\n",
    "    if round(loss_hist['test'][-1],10) < round(best_loss,10):\n",
    "        best_loss = loss_hist['test'][-1]\n",
    "        early_stop_counter = 1\n",
    "        best_encoder_u_wts = copy.deepcopy(encoder_u.state_dict())\n",
    "        best_decoder_u_wts = copy.deepcopy(decoder_u.state_dict())\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= early_stop_patience:  \n",
    "            break\n",
    "    \n",
    "    # save checkpoint every num_epoch_print\n",
    "    if epoch%num_epochs_print== 0:\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'encoder_u_state_dict': encoder_u.state_dict(),\n",
    "                    'decoder_u_state_dict': decoder_u.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss_hist': loss_hist,\n",
    "                    'best_loss': best_loss,\n",
    "                    'early_stop_counter': early_stop_counter,\n",
    "                    'best_encoder_u_wts': best_encoder_u_wts,\n",
    "                    'best_decoder_u_wts': best_decoder_u_wts,\n",
    "                    }, PATH_u)        \n",
    "\n",
    "print()\n",
    "print('Epoch {}/{}, Learning rate {}'\\\n",
    "      .format(epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "print('-' * 10)\n",
    "print('train MSELoss: {}'.format(loss_hist['train'][-1]))\n",
    "print('test MSELoss: {}'.format(loss_hist['test'][-1]))\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "\n",
    "# load best model weights\n",
    "encoder_u.load_state_dict(best_encoder_u_wts)\n",
    "decoder_u.load_state_dict(best_decoder_u_wts)\n",
    "\n",
    "# compute best train MSELoss\n",
    "encoder_u.to('cpu').eval()\n",
    "decoder_u.to('cpu').eval()\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    train_inputs = torch.tensor(data_u[train_ind])\n",
    "    train_targets = torch.tensor(data_u[train_ind])\n",
    "    train_outputs = decoder_u(encoder_u(train_inputs))\n",
    "    train_loss = loss_func(train_outputs,train_targets).item()\n",
    "\n",
    "# print out training time and best results\n",
    "print()\n",
    "if epoch < num_epochs:\n",
    "    print('Early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "else:\n",
    "    print('No early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "print('-' * 10)\n",
    "print('Best train MSELoss: {}'.format(train_loss))\n",
    "print('Best test MSELoss: {}'.format(best_loss))\n",
    "\n",
    "# # save models\n",
    "# print()\n",
    "# print(\"Saving after {}th training to\".format(epoch),file_name_AE_u)\n",
    "# torch.save((encoder_u,decoder_u),file_name_AE_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "checkpoint removed\n"
     ]
    }
   ],
   "source": [
    "# delete checkpoint\n",
    "try:\n",
    "    os.remove(PATH_u)\n",
    "    print()\n",
    "    print(\"checkpoint removed\")\n",
    "except:\n",
    "    print(\"no checkpoint exists\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and test loss\n",
    "plt.figure()\n",
    "plt.semilogy(loss_hist['train'])\n",
    "plt.semilogy(loss_hist['test'])\n",
    "plt.legend(['train','test'])\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------checkpoint not restored--------\n",
      "\n",
      "\n",
      "Start first training... m=3364, f=35, a=2, b=100, db=10\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "try:\n",
    "    checkpoint = torch.load(PATH_v, map_location=device)\n",
    "    \n",
    "    encoder_v = Encoder(m,M1,f).to(device)\n",
    "    decoder_v = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    prune.custom_from_mask(decoder_v.full[2], name='weight', mask=torch.tensor(mask_2d).to(device))    \n",
    "       \n",
    "    optimizer = torch.optim.Adam(list(encoder_v.parameters()) + list(decoder_v.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    encoder_v.load_state_dict(checkpoint['encoder_v_state_dict'])\n",
    "    decoder_v.load_state_dict(checkpoint['decoder_v_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    last_epoch = checkpoint['epoch']\n",
    "    loss_hist = checkpoint['loss_hist']\n",
    "    best_loss = checkpoint['best_loss']\n",
    "    early_stop_counter = checkpoint['early_stop_counter']\n",
    "    best_encoder_v_wts = checkpoint['best_encoder_v_wts']\n",
    "    best_decoder_v_wts = checkpoint['best_decoder_v_wts']\n",
    "    \n",
    "    print(\"\\n--------checkpoint restored--------\\n\")\n",
    "    \n",
    "    # resume training\n",
    "    print(\"\")\n",
    "    print('Re-start {}th training... m={}, f={}, a={}, b={}, db={}'.format(\n",
    "        last_epoch+1, m, f, a, b, db))\n",
    "except:\n",
    "    encoder_v = Encoder(m,M1,f).to(device)\n",
    "    decoder_v = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    prune.custom_from_mask(decoder_v.full[2], name='weight', mask=torch.tensor(mask_2d).to(device))\n",
    "\n",
    "    optimizer = torch.optim.Adam(list(encoder_v.parameters()) + list(decoder_v.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    last_epoch = 0\n",
    "    loss_hist = {'train':[],'test':[]}\n",
    "    best_loss = float(\"inf\")\n",
    "    early_stop_counter = 1\n",
    "    best_encoder_v_wts = copy.deepcopy(encoder_v.state_dict())\n",
    "    best_decoder_v_wts = copy.deepcopy(decoder_v.state_dict())\n",
    "    \n",
    "    print(\"\\n--------checkpoint not restored--------\\n\")\n",
    "\n",
    "    # start training\n",
    "    print(\"\")\n",
    "    print('Start first training... m={}, f={}, a={}, b={}, db={}'.format(\n",
    "        m, f, a, b, db))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 3.775729811301085e-06\n",
      "test MSELoss: 3.865471444441937e-06\n",
      "\n",
      "Epoch 200/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 2.1022625153917767e-06\n",
      "test MSELoss: 2.149779993487755e-06\n",
      "\n",
      "Epoch 300/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 1.1067144647767136e-06\n",
      "test MSELoss: 1.1365792715878342e-06\n",
      "\n",
      "Epoch 400/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 6.507633509912009e-07\n",
      "test MSELoss: 6.53621634683077e-07\n",
      "\n",
      "Epoch 500/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 4.0441873642289807e-07\n",
      "test MSELoss: 4.262879031102784e-07\n",
      "\n",
      "Epoch 600/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 3.711349749771171e-07\n",
      "test MSELoss: 3.905901678535884e-07\n",
      "\n",
      "Epoch 700/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 3.2682268793039943e-07\n",
      "test MSELoss: 3.4598626257320576e-07\n",
      "\n",
      "Epoch 800/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.798555732266857e-07\n",
      "test MSELoss: 2.9529865628319387e-07\n",
      "\n",
      "Epoch 900/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.3533004360594582e-07\n",
      "test MSELoss: 2.5004209476264804e-07\n",
      "\n",
      "Epoch 1000/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.9898924604960424e-07\n",
      "test MSELoss: 2.147862204537887e-07\n",
      "\n",
      "Epoch 1100/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.707549100099568e-07\n",
      "test MSELoss: 1.836518606523896e-07\n",
      "\n",
      "Epoch 1200/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.4920989558408585e-07\n",
      "test MSELoss: 1.6053703575380495e-07\n",
      "\n",
      "Epoch 1300/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.3212413938217947e-07\n",
      "test MSELoss: 1.407496654337592e-07\n",
      "\n",
      "Epoch 1400/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.177352531828589e-07\n",
      "test MSELoss: 1.2781968621311536e-07\n",
      "\n",
      "Epoch 1500/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.0640685924023391e-07\n",
      "test MSELoss: 1.1590629327429269e-07\n",
      "\n",
      "Epoch 1600/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 9.710680646727743e-08\n",
      "test MSELoss: 1.045895629658844e-07\n",
      "\n",
      "Epoch 1700/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 9.006486446744826e-08\n",
      "test MSELoss: 9.655061319335801e-08\n",
      "\n",
      "Epoch 1800/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 8.402420469606252e-08\n",
      "test MSELoss: 8.980399144320472e-08\n",
      "\n",
      "Epoch 1900/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 7.752710993223488e-08\n",
      "test MSELoss: 8.507295916615476e-08\n",
      "\n",
      "Epoch 2000/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 7.252137920174447e-08\n",
      "test MSELoss: 7.817681080268812e-08\n",
      "\n",
      "Epoch 2100/10000, Learning rate 1.0000000000000002e-07\n",
      "----------\n",
      "train MSELoss: 6.645930481884855e-08\n",
      "test MSELoss: 7.16985724125152e-08\n",
      "\n",
      "Epoch 2200/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 6.643620253422668e-08\n",
      "test MSELoss: 7.1695114911563e-08\n",
      "\n",
      "Epoch 2252/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 6.643414166050809e-08\n",
      "test MSELoss: 7.169206952539753e-08\n",
      "\n",
      "Early stopping: 2252th training complete in 1h 10m 27s\n",
      "----------\n",
      "Best train MSELoss: 6.678912001234494e-08\n",
      "Best test MSELoss: 7.172124725229878e-08\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "since = time.time()\n",
    "\n",
    "for epoch in range(last_epoch+1,num_epochs+1):   \n",
    "\n",
    "    if epoch%num_epochs_print == 0:\n",
    "        print()\n",
    "        print('Epoch {}/{}, Learning rate {}'.format(\n",
    "            epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "        print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and test phase\n",
    "    for phase in ['train', 'test']:\n",
    "        if phase == 'train':\n",
    "            encoder_v.train()  # Set model to training mode\n",
    "            decoder_v.train()  # Set model to training mode\n",
    "        else:\n",
    "            encoder_v.eval()   # Set model to evaluation mode\n",
    "            decoder_v.eval()   # Set model to evaluation mode\n",
    "            \n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Iterate over data\n",
    "        for data, in data_loaders_v[phase]:\n",
    "            inputs = data.to(device)\n",
    "            targets = data.to(device)\n",
    "\n",
    "            if phase == 'train':\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = decoder_v(encoder_v(inputs))\n",
    "                loss = loss_func(outputs, targets)\n",
    "\n",
    "                # backward\n",
    "                loss.backward()\n",
    "\n",
    "                # optimize\n",
    "                optimizer.step()  \n",
    "\n",
    "                # add running loss\n",
    "                running_loss += loss.item()*inputs.shape[0]\n",
    "            else:\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    outputs = decoder_v(encoder_v(inputs))\n",
    "                    running_loss += loss_func(outputs,targets).item()*inputs.shape[0]\n",
    "\n",
    "        # compute epoch loss\n",
    "        epoch_loss = running_loss / dataset_v_shapes[phase][0]\n",
    "        loss_hist[phase].append(epoch_loss)\n",
    "            \n",
    "        # update learning rate\n",
    "        if phase == 'train':\n",
    "            scheduler.step(epoch_loss)\n",
    "\n",
    "        if epoch%num_epochs_print == 0:\n",
    "            print('{} MSELoss: {}'.format(\n",
    "                phase, epoch_loss))\n",
    "\n",
    "    # deep copy the model\n",
    "    if round(loss_hist['test'][-1],10) < round(best_loss,10):\n",
    "        best_loss = loss_hist['test'][-1]\n",
    "        early_stop_counter = 1\n",
    "        best_encoder_v_wts = copy.deepcopy(encoder_v.state_dict())\n",
    "        best_decoder_v_wts = copy.deepcopy(decoder_v.state_dict())\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= early_stop_patience:  \n",
    "            break\n",
    "    \n",
    "    # save checkpoint every num_epoch_print\n",
    "    if epoch%num_epochs_print== 0:\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'encoder_v_state_dict': encoder_v.state_dict(),\n",
    "                    'decoder_v_state_dict': decoder_v.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss_hist': loss_hist,\n",
    "                    'best_loss': best_loss,\n",
    "                    'early_stop_counter': early_stop_counter,\n",
    "                    'best_encoder_v_wts': best_encoder_v_wts,\n",
    "                    'best_decoder_v_wts': best_decoder_v_wts,\n",
    "                    }, PATH_v)        \n",
    "\n",
    "print()\n",
    "print('Epoch {}/{}, Learning rate {}'\\\n",
    "      .format(epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "print('-' * 10)\n",
    "print('train MSELoss: {}'.format(loss_hist['train'][-1]))\n",
    "print('test MSELoss: {}'.format(loss_hist['test'][-1]))\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "\n",
    "# load best model weights\n",
    "encoder_v.load_state_dict(best_encoder_v_wts)\n",
    "decoder_v.load_state_dict(best_decoder_v_wts)\n",
    "\n",
    "# compute best train MSELoss\n",
    "encoder_v.to('cpu').eval()\n",
    "decoder_v.to('cpu').eval()\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    train_inputs = torch.tensor(data_v[train_ind])\n",
    "    train_targets = torch.tensor(data_v[train_ind])\n",
    "    train_outputs = decoder_v(encoder_v(train_inputs))\n",
    "    train_loss = loss_func(train_outputs,train_targets).item()\n",
    "\n",
    "# print out training time and best results\n",
    "print()\n",
    "if epoch < num_epochs:\n",
    "    print('Early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "else:\n",
    "    print('No early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "print('-' * 10)\n",
    "print('Best train MSELoss: {}'.format(train_loss))\n",
    "print('Best test MSELoss: {}'.format(best_loss))\n",
    "\n",
    "# # save models\n",
    "# print()\n",
    "# print(\"Saving after {}th training to\".format(epoch),file_name_AE_v)\n",
    "# torch.save((encoder_v,decoder_v),file_name_AE_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "checkpoint removed\n"
     ]
    }
   ],
   "source": [
    "# delete checkpoint\n",
    "try:\n",
    "    os.remove(PATH_v)\n",
    "    print()\n",
    "    print(\"checkpoint removed\")\n",
    "except:\n",
    "    print(\"no checkpoint exists\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and test loss\n",
    "plt.figure()\n",
    "plt.semilogy(loss_hist['train'])\n",
    "plt.semilogy(loss_hist['test'])\n",
    "plt.legend(['train','test'])\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load models\n",
    "# try:\n",
    "#     encoder_u,decoder_u = torch.load(file_name_AE_u,map_location='cpu')\n",
    "#     encoder_v,decoder_v = torch.load(file_name_AE_v,map_location='cpu')\n",
    "#     print(\"\\n--------model restored--------\\n\")\n",
    "# except:\n",
    "#     print(\"\\n--------model not restored--------\\n\")\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights and bias\n",
    "en_wu1_s=encoder_u.full[0].weight.detach().numpy().astype('float32')\n",
    "en_bu1=encoder_u.full[0].bias.detach().numpy().astype('float32')\n",
    "en_wu2=encoder_u.full[2].weight.detach().numpy().astype('float32')\n",
    "\n",
    "en_wv1_s=encoder_v.full[0].weight.detach().numpy().astype('float32')\n",
    "en_bv1=encoder_v.full[0].bias.detach().numpy().astype('float32')\n",
    "en_wv2=encoder_v.full[2].weight.detach().numpy().astype('float32')\n",
    "\n",
    "de_wu1=decoder_u.full[0].weight.detach().numpy().astype('float32')\n",
    "de_bu1=decoder_u.full[0].bias.detach().numpy().astype('float32')\n",
    "de_wu2_s=decoder_u.full[2].weight.detach().numpy().astype('float32')\n",
    "\n",
    "de_wv1=decoder_v.full[0].weight.detach().numpy().astype('float32')\n",
    "de_bv1=decoder_v.full[0].bias.detach().numpy().astype('float32')\n",
    "de_wv2_s=decoder_v.full[2].weight.detach().numpy().astype('float32')\n",
    "\n",
    "de_wu2_s_sp=sp.csr_matrix(de_wu2_s,dtype='float32')\n",
    "de_wv2_s_sp=sp.csr_matrix(de_wv2_s,dtype='float32')\n",
    "\n",
    "# rescale weights\n",
    "en_wu1=en_wu1_s*u_scale_reciprocal\n",
    "en_wv1=en_wv1_s*v_scale_reciprocal\n",
    "\n",
    "de_wu1T=de_wu1.T\n",
    "de_wv1T=de_wv1.T\n",
    "\n",
    "de_wu2T=u_scale*de_wu2_s.T\n",
    "de_wv2T=v_scale*de_wv2_s.T\n",
    "\n",
    "de_wu2=de_wu2T.T\n",
    "de_wv2=de_wv2T.T\n",
    "\n",
    "de_wu2_sp=sp.csr_matrix(de_wu2,dtype='float32')\n",
    "de_wv2_sp=sp.csr_matrix(de_wv2,dtype='float32')\n",
    "\n",
    "de_wu2T_sp=de_wu2_sp.T\n",
    "de_wv2T_sp=de_wv2_sp.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy version of AE\n",
    "def sigmoid_np(input):\n",
    "    return (1.0/(1.0+np.exp(-input))).astype('float32')\n",
    "\n",
    "def encoder_u_np_forward(x):\n",
    "    z1 = en_wu1.dot(x) + en_bu1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = en_wu2.dot(a1)   \n",
    "    return y\n",
    "\n",
    "def decoder_u_np_forward(x):\n",
    "    z1 = de_wu1.dot(x) + de_bu1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = de_wu2.dot(a1)  \n",
    "    return y\n",
    "\n",
    "def decoder_u_sp_forward(x):\n",
    "    z1 = de_wu1.dot(x) + de_bu1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = sp.csr_matrix.dot(de_wu2_sp,a1)\n",
    "    return y\n",
    "\n",
    "def encoder_v_np_forward(x):\n",
    "    z1 = en_wv1.dot(x) + en_bv1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = en_wv2.dot(a1)   \n",
    "    return y\n",
    "\n",
    "def decoder_v_np_forward(x):\n",
    "    z1 = de_wv1.dot(x) + de_bv1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = de_wv2.dot(a1)   \n",
    "    return y\n",
    "\n",
    "def decoder_v_sp_forward(x):\n",
    "    z1 = de_wv1.dot(x) + de_bv1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = sp.csr_matrix.dot(de_wv2_sp,a1)\n",
    "    return y\n",
    "\n",
    "def decoder_u_np_forward_backwardT(x):\n",
    "    z1 = de_wu1.dot(x) + de_bu1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = de_wu2.dot(a1)\n",
    "\n",
    "    dout = de_wu1T\n",
    "    dout = (a1*(1-a1))*dout\n",
    "    dydxT = dout.dot(de_wu2T)   \n",
    "    return y,dydxT\n",
    "\n",
    "def decoder_u_sp_forward_backwardT(x):\n",
    "    z1 = de_wu1.dot(x) + de_bu1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = sparse.csr_matrix.dot(de_wu2_sp,a1)\n",
    "\n",
    "    dout = de_wu1T\n",
    "    dout = (a1*(1-a1))*dout\n",
    "    dydxT = sp.csr_matrix.dot(dout,de_wu2T_sp)\n",
    "    return y,dydxT\n",
    "\n",
    "def decoder_v_np_forward_backwardT(x):\n",
    "    z1 = de_wv1.dot(x) + de_bv1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = de_wv2.dot(a1)\n",
    "\n",
    "    dout = de_wv1T\n",
    "    dout = (a1*(1-a1))*dout\n",
    "    dydxT = dout.dot(de_wv2T)   \n",
    "    return y,dydxT\n",
    "\n",
    "def decoder_v_sp_forward_backwardT(x):\n",
    "    z1 = de_wv1.dot(x) + de_bv1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = sp.csr_matrix.dot(de_wv2_sp,a1)\n",
    "\n",
    "    dout = de_wv1T\n",
    "    dout = (a1*(1-a1))*dout\n",
    "    dydxT = sp.csr_matrix.dot(dout,de_wv2T_sp)\n",
    "    return y,dydxT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE u: 1.72900273e-08\n",
      "MSELoss of AE v: 2.14844608e-08\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss\n",
    "comp_orig_data_u=np.zeros((ndata,f))\n",
    "comp_orig_data_v=np.zeros((ndata,f))\n",
    "\n",
    "rest_orig_data_u=np.zeros(orig_data_u.shape)\n",
    "rest_orig_data_v=np.zeros(orig_data_u.shape)\n",
    "\n",
    "for k in range(ndata):\n",
    "    comp_orig_data_u[k]=encoder_u_np_forward(orig_data_u[k]-u_ref)\n",
    "    comp_orig_data_v[k]=encoder_v_np_forward(orig_data_v[k]-v_ref)\n",
    "    \n",
    "    rest_orig_data_u[k]=decoder_u_sp_forward(comp_orig_data_u[k]) + u_ref\n",
    "    rest_orig_data_v[k]=decoder_v_sp_forward(comp_orig_data_v[k]) + v_ref\n",
    "    \n",
    "print(\"MSELoss of AE u: {:.8e}\".format(np.linalg.norm(orig_data_u-rest_orig_data_u)**2/np.prod(orig_data_u.shape)))\n",
    "print(\"MSELoss of AE v: {:.8e}\".format(np.linalg.norm(orig_data_v-rest_orig_data_v)**2/np.prod(orig_data_v.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale AE\n",
    "en_weight_u_s=encoder_u.full[0].weight.data\n",
    "en_weight_u=en_weight_u_s*torch.tensor(u_scale_reciprocal)\n",
    "encoder_u.full[0].weight=nn.Parameter(en_weight_u)\n",
    "\n",
    "de_weight_u_s=decoder_u.full[2].weight.data\n",
    "de_weight_u=(torch.tensor(u_scale)*de_weight_u_s.T).T\n",
    "de_weight_u_mask=decoder_u.full[2].weight_mask.data\n",
    "prune.remove(decoder_u.full[2],'weight');\n",
    "decoder_u.full[2].weight=nn.Parameter(de_weight_u)\n",
    "prune.custom_from_mask(decoder_u.full[2], name='weight', mask=de_weight_u_mask);\n",
    "\n",
    "en_weight_v_s=encoder_v.full[0].weight.data\n",
    "en_weight_v=en_weight_v_s*torch.tensor(v_scale_reciprocal)\n",
    "encoder_v.full[0].weight=nn.Parameter(en_weight_v)\n",
    "\n",
    "de_weight_v_s=decoder_v.full[2].weight.data\n",
    "de_weight_v=(torch.tensor(v_scale)*de_weight_v_s.T).T\n",
    "de_weight_v_mask=decoder_v.full[2].weight_mask.data\n",
    "prune.remove(decoder_v.full[2],'weight');\n",
    "decoder_v.full[2].weight=nn.Parameter(de_weight_v)\n",
    "prune.custom_from_mask(decoder_v.full[2], name='weight', mask=de_weight_v_mask);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE u: 1.72896186e-08\n",
      "MSELoss of AE v: 2.14838618e-08\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss\n",
    "input_u=torch.tensor(orig_data_u-u_ref)\n",
    "target_u=decoder_u(encoder_u(input_u))\n",
    "\n",
    "input_v=torch.tensor(orig_data_v-v_ref)\n",
    "target_v=decoder_v(encoder_v(input_v))\n",
    "\n",
    "print(\"MSELoss of AE u: {:.8e}\".format(torch.nn.functional.mse_loss(input_u,target_u).detach().item()))\n",
    "print(\"MSELoss of AE v: {:.8e}\".format(torch.nn.functional.mse_loss(input_v,target_v).detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE u (predictive case): 3.07030739e-08\n",
      "MSELoss of AE v (predictive case): 3.52457974e-08\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (predictive case)\n",
    "if Re==10000:\n",
    "    FOM_solution=pickle.load(open('./data/FOM_high_Re.p','rb'))\n",
    "elif Re==100:\n",
    "    FOM_solution=pickle.load(open('./data/FOM_loq_Re.p','rb'))\n",
    "else:\n",
    "    raise NameError('{} is given for Re, but it must be either 100 or 10000'.format(Re))\n",
    "    \n",
    "u_full=FOM_solution['u'].astype('float32')\n",
    "v_full=FOM_solution['v'].astype('float32')\n",
    "\n",
    "orig_data_u_FOM = u_full[:,free_raveled_indicies]\n",
    "orig_data_v_FOM = v_full[:,free_raveled_indicies]\n",
    "\n",
    "input_u_FOM=torch.tensor(orig_data_u_FOM-u_ref)\n",
    "target_u_FOM=decoder_u(encoder_u(input_u_FOM))\n",
    "\n",
    "input_v_FOM=torch.tensor(orig_data_v_FOM-v_ref)\n",
    "target_v_FOM=decoder_v(encoder_v(input_v_FOM))\n",
    "\n",
    "print(\"MSELoss of AE u (predictive case): {:.8e}\"\\\n",
    "      .format(torch.nn.functional.mse_loss(input_u_FOM,target_u_FOM).detach().item()))\n",
    "print(\"MSELoss of AE v (predictive case): {:.8e}\"\\\n",
    "      .format(torch.nn.functional.mse_loss(input_v_FOM,target_v_FOM).detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # generate mesh grid\n",
    "# [xv,yv]=np.meshgrid(np.linspace(0,1,nx),np.linspace(0,1,ny),indexing='xy')\n",
    "# x=xv.flatten()\n",
    "# y=yv.flatten()\n",
    "\n",
    "# x_free=x[free_raveled_indicies]\n",
    "# y_free=y[free_raveled_indicies]\n",
    "\n",
    "# k=-1\n",
    "\n",
    "# # plot origianl data\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_u[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_u[k].reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Original $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_v[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_v[k].reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Original $v$')\n",
    "# plt.show()\n",
    "\n",
    "# # plot compressed data\n",
    "# plt.figure()\n",
    "# plt.plot(comp_orig_data_u[k])\n",
    "# plt.title('Compressed $u$')\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(comp_orig_data_v[k])\n",
    "# plt.title('Compressed $v$')\n",
    "# plt.show()\n",
    "\n",
    "# # plot restored data\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_orig_data_u[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_orig_data_u[k].reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Restored $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_orig_data_v[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_orig_data_v[k].reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Restored $v$')\n",
    "# plt.show()\n",
    "\n",
    "# # plot relative error\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), (orig_data_u[k]-rest_orig_data_u[k]).reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), (orig_data_u[k]-rest_orig_data_u[k]).reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Difference $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), (orig_data_v[k]-rest_orig_data_v[k]).reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), (orig_data_v[k]-rest_orig_data_v[k]).reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Difference $v$')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights and references   \n",
    "AE={'en_wu1':en_wu1,'en_bu1':en_bu1,'en_wu2':en_wu2,\n",
    "    'de_wu1':de_wu1,'de_bu1':de_bu1,'de_wu2':de_wu2,\n",
    "    'de_wu1T':de_wu1T,'de_wu2T':de_wu2T,'de_wu2_sp':de_wu2_sp,'de_wu2T_sp':de_wu2T_sp,'u_ref':u_ref,\n",
    "    'en_wv1':en_wv1,'en_bv1':en_bv1,'en_wv2':en_wv2,\n",
    "    'de_wv1':de_wv1,'de_bv1':de_bv1,'de_wv2':de_wv2,\n",
    "    'de_wv1T':de_wv1T,'de_wv2T':de_wv2T,'de_wv2_sp':de_wv2_sp,'de_wv2T_sp':de_wv2T_sp,'v_ref':v_ref}\n",
    "\n",
    "pickle.dump(AE,open(file_name_AE,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
