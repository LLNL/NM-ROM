{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.prune as prune\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "from scipy import sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import sys,time\n",
    "import os\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "redDim=25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set print option\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "# Choose device that is not being used\n",
    "gpu_ids = \"1\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=gpu_ids\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given parameters\n",
    "nx = 60\n",
    "ny = 60\n",
    "m = (ny-2)*(nx-2) # 3364\n",
    "nt = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose either Re=10000 or Re=100\n",
    "Re = 10000 \n",
    "    \n",
    "# Choose data normalize option (option 1: -1<=X<=1 option 2: 0<=X<=1)\n",
    "option = 2\n",
    "\n",
    "# Choose activation function (sigmoid, swish)\n",
    "activation = 'sigmoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set batch_size, number of epochs, paitience for early stop\n",
    "batch_size = 480\n",
    "num_epochs = 10000\n",
    "num_epochs_print = num_epochs//100\n",
    "early_stop_patience = num_epochs//50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_mask(m,b,db):\n",
    "    \n",
    "#     M2 = b + db*(m-1)\n",
    "#     mask = np.zeros((m,M2),dtype='int8')\n",
    "    \n",
    "#     block = np.ones(b,dtype='int8')\n",
    "#     ind = np.arange(b)\n",
    "#     for row in range(m):\n",
    "#         col = ind + row*db\n",
    "#         mask[row,col] = block      \n",
    "\n",
    "# #     for row in range(nx-2,m):\n",
    "# #         col = ind + (row-1)*db\n",
    "# #         mask[row-(nx-2),col] = block    \n",
    "# #     for row in range(0,m-(nx-2)):\n",
    "# #         col = ind + (row+1)*db\n",
    "# #         mask[row+(nx-2),col] = block\n",
    "                   \n",
    "#     print(\n",
    "#         \"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "#             m, M2, (1.0-np.count_nonzero(mask)/mask.size)*100\n",
    "#         )\n",
    "#     )\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.spy(mask)\n",
    "#     plt.show()\n",
    "\n",
    "#     return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_2d(m,b,db):\n",
    "    \n",
    "    # local\n",
    "    Mb=sp.diags([np.ones(nx-2),np.ones(nx-2),np.ones(nx-2)],[0,-1,1],(nx-2,nx-2))\n",
    "    M=sp.kron(sp.eye(ny-2),Mb,format=\"csr\")\n",
    "\n",
    "    Ib=sp.eye(nx-2)\n",
    "    N=sp.kron(sp.diags([np.ones(ny-2),np.ones(ny-2),np.ones(ny-2)],[0,-1,1],(ny-2,ny-2)),Ib,format=\"csr\")\n",
    "\n",
    "    local=(M+N).astype('int8')\n",
    "    I,J,V=sp.find(local)\n",
    "    local[I,J]=1\n",
    "    \n",
    "#     col_ind=np.array([],dtype='int')\n",
    "#     row_ind=np.array([],dtype='int')\n",
    "\n",
    "#     for lin_ind in range(m):\n",
    "#         j,i=np.unravel_index(lin_ind,(ny-2,nx-2))\n",
    "\n",
    "#         E=np.ravel_multi_index((j,np.max((i-1,0))),(ny-2,nx-2))\n",
    "#         W=np.ravel_multi_index((j,np.min((i+1,nx-2-1))),(ny-2,nx-2))\n",
    "#         S=np.ravel_multi_index((np.max((j-1,0)),i),(ny-2,nx-2))\n",
    "#         N=np.ravel_multi_index((np.min((j+1,ny-2-1)),i),(ny-2,nx-2))\n",
    "\n",
    "#         col=np.unique([lin_ind,E,W,S,N])\n",
    "#         row=lin_ind*np.ones(col.size,dtype='int')\n",
    "\n",
    "#         col_ind=np.append(col_ind,col)\n",
    "#         row_ind=np.append(row_ind,row)\n",
    "\n",
    "#     data=np.ones(row_ind.size,dtype='int')\n",
    "#     local2=sp.csr_matrix((data,(row_ind,col_ind)),shape=(m,m))\n",
    "\n",
    "    # basis\n",
    "    M2 = int(b + db*(m-1))\n",
    "    basis = np.zeros((m,M2),dtype='int8')\n",
    "\n",
    "    block = np.ones(b,dtype='int8')\n",
    "    ind = np.arange(b)\n",
    "    for row in range(m):\n",
    "        col = ind + row*db\n",
    "        basis[row,col] = block\n",
    "    \n",
    "    # mask\n",
    "    col_ind=np.array([],dtype='int8')\n",
    "    row_ind=np.array([],dtype='int8')\n",
    "    for i in range(m):\n",
    "        col=basis[sp.find(local[i])[1]].sum(axis=0).nonzero()[0]\n",
    "        row=i*np.ones(col.size)\n",
    "\n",
    "        col_ind=np.append(col_ind,col)\n",
    "        row_ind=np.append(row_ind,row)\n",
    "\n",
    "    data=np.ones(row_ind.size,dtype='int8')\n",
    "    mask=sp.csr_matrix((data,(row_ind,col_ind)),shape=(m,M2)).toarray()\n",
    "    \n",
    "    print(\n",
    "        \"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "            m, M2, (1.0-np.count_nonzero(mask)/np.prod(mask.shape))*100\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.spy(mask)\n",
    "    plt.show()\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if activation=='sigmoid':\n",
    "    class Encoder(nn.Module):\n",
    "        def __init__(self,m,M1,f):\n",
    "            super(Encoder,self).__init__()\n",
    "            self.full = nn.Sequential(\n",
    "                nn.Linear(m,M1),\n",
    "                nn.Sigmoid(),\n",
    "                nn.Linear(M1,f,bias=False)\n",
    "            )\n",
    "\n",
    "        def forward(self, y):     \n",
    "            y = y.view(-1,m)\n",
    "            T = self.full(y)\n",
    "            T = T.squeeze()\n",
    "\n",
    "            return T\n",
    "\n",
    "    class Decoder(nn.Module):\n",
    "        def __init__(self,f,M2,m):\n",
    "            super(Decoder,self).__init__()\n",
    "            self.full = nn.Sequential(\n",
    "                nn.Linear(f,M2),\n",
    "                nn.Sigmoid(),\n",
    "                nn.Linear(M2,m,bias=False)\n",
    "            )\n",
    "\n",
    "        def forward(self,T):\n",
    "            T = T.view(-1,f)\n",
    "            y = self.full(T)\n",
    "            y = y.squeeze()\n",
    "\n",
    "            return y\n",
    "        \n",
    "elif activation=='swish':\n",
    "    def silu(input):\n",
    "        return input * torch.sigmoid(input)\n",
    "\n",
    "    class SiLU(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "        def forward(self, input):\n",
    "            return silu(input)\n",
    "        \n",
    "    class Encoder(nn.Module):\n",
    "        def __init__(self,m,M1,f):\n",
    "            super(Encoder,self).__init__()\n",
    "            self.full = nn.Sequential(\n",
    "                nn.Linear(m,M1),\n",
    "                SiLU(),\n",
    "                nn.Linear(M1,f,bias=False)\n",
    "            )\n",
    "\n",
    "        def forward(self, y):     \n",
    "            y = y.view(-1,m)\n",
    "            T = self.full(y)\n",
    "            T = T.squeeze()\n",
    "\n",
    "            return T\n",
    "\n",
    "    class Decoder(nn.Module):\n",
    "        def __init__(self,f,M2,m):\n",
    "            super(Decoder,self).__init__()\n",
    "            self.full = nn.Sequential(\n",
    "                nn.Linear(f,M2),\n",
    "                SiLU(),\n",
    "                nn.Linear(M2,m,bias=False)\n",
    "            )\n",
    "\n",
    "        def forward(self,T):\n",
    "            T = T.view(-1,f)\n",
    "            y = self.full(T)\n",
    "            y = y.squeeze()\n",
    "\n",
    "            return y\n",
    "else:\n",
    "    raise NameError('{} is given for option, but it must be either sigmoid or swish'.format(activation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "option 2: 0<=X<=1\n",
      "data shape\n",
      "(6004, 3364)\n",
      "(6004, 3364)\n",
      "maximum abs difference\n",
      "1.1920929e-07\n",
      "1.1920929e-07\n"
     ]
    }
   ],
   "source": [
    "# load snapshot\n",
    "if Re==10000:\n",
    "    file_name_snapshot=\"./data/snapshot_full_high_Re.p\"\n",
    "elif Re==100:\n",
    "    file_name_snapshot=\"./data/snapshot_full_low_Re.p\"\n",
    "else:\n",
    "    raise NameError('{} is given for Re, but it must be either 100 or 10000'.format(Re)) \n",
    "\n",
    "snapshot = pickle.load(open(file_name_snapshot,'rb'))\n",
    "snapshot_u = snapshot['u'].astype('float32')\n",
    "snapshot_v = snapshot['v'].astype('float32')\n",
    "\n",
    "# number of data points\n",
    "ndata = snapshot_u.shape[0]\n",
    "\n",
    "# remove BC\n",
    "multi_index_i,multi_index_j=np.meshgrid(np.arange(nx),np.arange(ny),indexing='xy')\n",
    "full_multi_index=(multi_index_j.flatten(),multi_index_i.flatten())\n",
    "free_multi_index=(multi_index_j[1:-1,1:-1].flatten(),multi_index_i[1:-1,1:-1].flatten())\n",
    "\n",
    "dims=(ny,nx)\n",
    "full_raveled_indicies=np.ravel_multi_index(full_multi_index,dims)\n",
    "free_raveled_indicies=np.ravel_multi_index(free_multi_index,dims)\n",
    "\n",
    "orig_data_u = snapshot_u[:,free_raveled_indicies]\n",
    "orig_data_v = snapshot_v[:,free_raveled_indicies]\n",
    "\n",
    "# normalize data\n",
    "if option==1: # option 1: -1<=X<=1\n",
    "    print(\"option {}: -1<=X<=1\".format(option))\n",
    "#     u_ref = np.mean(orig_data_u,axis=0)\n",
    "#     v_ref = np.mean(orig_data_v,axis=0)   \n",
    "\n",
    "#     u_scale = np.max(orig_data_u,axis=0)-np.min(orig_data_u,axis=0)\n",
    "#     v_scale = np.max(orig_data_v,axis=0)-np.min(orig_data_v,axis=0)   \n",
    "    u_ref = (np.max(orig_data_u,axis=0)+np.min(orig_data_u,axis=0))/2.0\n",
    "    v_ref = (np.max(orig_data_v,axis=0)+np.min(orig_data_v,axis=0))/2.0\n",
    "    \n",
    "    u_scale = (np.max(orig_data_u,axis=0)-np.min(orig_data_u,axis=0))/2.0\n",
    "    v_scale = (np.max(orig_data_v,axis=0)-np.min(orig_data_v,axis=0))/2.0\n",
    "    \n",
    "    u_scale = np.where(u_scale > np.finfo('float32').resolution, u_scale, 1)\n",
    "    v_scale = np.where(v_scale > np.finfo('float32').resolution, v_scale, 1)\n",
    "    \n",
    "    u_scale_reciprocal = np.reciprocal(u_scale)\n",
    "    v_scale_reciprocal = np.reciprocal(v_scale)\n",
    "    \n",
    "    data_u = u_scale_reciprocal*(orig_data_u-u_ref)\n",
    "    data_v = v_scale_reciprocal*(orig_data_v-v_ref)\n",
    "    \n",
    "elif option==2: # option 2: 0<=X<=1\n",
    "    print(\"option {}: 0<=X<=1\".format(option))\n",
    "    u_ref = np.min(orig_data_u,axis=0)\n",
    "    v_ref = np.min(orig_data_v,axis=0)\n",
    "    \n",
    "    u_scale = np.max(orig_data_u,axis=0)-np.min(orig_data_u,axis=0)\n",
    "    v_scale = np.max(orig_data_v,axis=0)-np.min(orig_data_v,axis=0)\n",
    "    \n",
    "    u_scale = np.where(u_scale > np.finfo('float32').resolution, u_scale, 1)\n",
    "    v_scale = np.where(v_scale > np.finfo('float32').resolution, v_scale, 1)\n",
    "    \n",
    "    u_scale_reciprocal = np.reciprocal(u_scale)\n",
    "    v_scale_reciprocal = np.reciprocal(v_scale)\n",
    "    \n",
    "    data_u = u_scale_reciprocal*(orig_data_u-u_ref)\n",
    "    data_v = v_scale_reciprocal*(orig_data_v-v_ref)\n",
    "else:\n",
    "    raise NameError('{} is given for option, but it must be either 1 or 2'.format(option))\n",
    "\n",
    "# check shapes of snapshot\n",
    "print('data shape')\n",
    "print(data_u.shape)\n",
    "print(data_v.shape)\n",
    "\n",
    "# restore data\n",
    "rest_data_u = u_ref + u_scale*data_u\n",
    "rest_data_v = v_ref + v_scale*data_v\n",
    "\n",
    "# check precision\n",
    "print('maximum abs difference')\n",
    "print(np.max(np.abs(orig_data_u-rest_data_u)))\n",
    "print(np.max(np.abs(orig_data_v-rest_data_v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # generate mesh grid\n",
    "# [xv,yv]=np.meshgrid(np.linspace(0,1,nx),np.linspace(0,1,ny),indexing='xy')\n",
    "# x=xv.flatten()\n",
    "# y=yv.flatten()\n",
    "\n",
    "# x_free=x[free_raveled_indicies]\n",
    "# y_free=y[free_raveled_indicies]\n",
    "\n",
    "# k=0\n",
    "\n",
    "# # plot original data\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_u[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_u[k].reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Original $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_v[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_v[k].reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Original $v$')\n",
    "# plt.show()\n",
    "\n",
    "# # plot preprocessed data\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), data_u[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), data_u[k].reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Preprocessed $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), data_v[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), data_v[k].reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Preprocessed $v$')\n",
    "# plt.show()\n",
    "\n",
    "# # plot restored data\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_data_u[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_data_u[k].reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Restored $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_data_v[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_data_v[k].reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Restored $v$')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5404, 3364]) torch.Size([600, 3364])\n",
      "torch.Size([5404, 3364]) torch.Size([600, 3364])\n"
     ]
    }
   ],
   "source": [
    "# define testset and trainset indices\n",
    "nset = round(ndata/(nt+1))\n",
    "test_ind = np.array([],dtype='int')\n",
    "for foo in range(nset):\n",
    "    rand_ind = np.random.permutation(np.arange(foo*(nt+1)+1,(foo+1)*(nt+1)))[:int(0.1*(nt+1))]\n",
    "    test_ind = np.append(test_ind,rand_ind)\n",
    "train_ind = np.setdiff1d(np.arange(ndata),test_ind)\n",
    "\n",
    "# set trainset and testset\n",
    "trainset_u = data_u[train_ind]\n",
    "trainset_v = data_v[train_ind]\n",
    "testset_u = data_u[test_ind] \n",
    "testset_v = data_v[test_ind] \n",
    "\n",
    "# set dataset\n",
    "dataset_u = {'train':data_utils.TensorDataset(torch.tensor(trainset_u,dtype=torch.float32)),\n",
    "           'test':data_utils.TensorDataset(torch.tensor(testset_u,dtype=torch.float32))}\n",
    "dataset_v = {'train':data_utils.TensorDataset(torch.tensor(trainset_v,dtype=torch.float32)),\n",
    "           'test':data_utils.TensorDataset(torch.tensor(testset_v,dtype=torch.float32))}\n",
    "\n",
    "print(dataset_u['train'].tensors[0].shape, dataset_u['test'].tensors[0].shape)\n",
    "print(dataset_v['train'].tensors[0].shape, dataset_v['test'].tensors[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5404, 3364) (600, 3364)\n",
      "(5404, 3364) (600, 3364)\n"
     ]
    }
   ],
   "source": [
    "# compute dataset shapes\n",
    "dataset_u_shapes = {'train':trainset_u.shape,\n",
    "                    'test':testset_u.shape}\n",
    "dataset_v_shapes = {'train':trainset_v.shape,\n",
    "                    'test':testset_v.shape}\n",
    "\n",
    "print(dataset_u_shapes['train'],dataset_u_shapes['test'])\n",
    "print(dataset_v_shapes['train'],dataset_v_shapes['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data loaders\n",
    "train_loader_u = DataLoader(dataset=dataset_u['train'], \n",
    "                          batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "train_loader_v = DataLoader(dataset=dataset_v['train'], \n",
    "                          batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader_u = DataLoader(dataset=dataset_u['test'], \n",
    "                         batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader_v = DataLoader(dataset=dataset_v['test'], \n",
    "                         batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "data_loaders_u = {'train':train_loader_u, 'test':test_loader_u}\n",
    "data_loaders_v = {'train':train_loader_v, 'test':test_loader_v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in 3364 by 33730 mask: 99.06%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAABECAYAAABte+WAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAALRklEQVR4nO3db4xcVRnH8e/PAgUF+VtI0xaBUomlKaXd1CKCIih/fAEYwJYgGCUYBYQXvmiDIqK80AhGQBEUIoLKn6DCCxErikhigC0U2korRQtWKi0iUJUghccX5yw7TGdm73Z3Zu6d+X2Szdw9e6dznt7MOTPnOfccRQRmZtYf3tbtCpiZWee40Tcz6yNu9M3M+ogbfTOzPuJG38ysj7jRNzPrI6Vt9CUdJ2mNpLWSFne7PvUkrZO0QtJySYO5bA9JSyU9mR93rzl/SY5ljaRja8rn5X9nraQrJanN9b5B0kZJK2vKxq3ekiZKujWXPyhpvw7GcYmkv+drslzSCWWOQ9I0Sb+T9ISkVZIuyOWVuh4t4qjM9ZC0o6SHJD2WY/hKLq/UtSgkIkr3A0wAngIOAHYAHgNmdrtedXVcB+xVV/YNYHE+Xgx8PR/PzDFMBPbPsU3If3sIOAwQcDdwfJvrfSQwF1jZjnoDnwO+l48XArd2MI5LgC80OLeUcQCTgbn5eBfgz7mulboeLeKozPXIr7dzPt4eeBBYULVrUSjWbrxogQtwGHBPze9LgCXdrlddHdexdaO/BpicjycDaxrVH7gnxzgZWF1Tvgi4tgN134+3NpbjVu+hc/LxdsDzgDoUR7NGptRx1Lz+ncCHq3o9GsRRyesBvB14BHhv1a9Fo5+yDu9MAf5W8/v6XFYmAfxa0jJJ5+SyfSJiA0B+3DuXN4tnSj6uL++08az3m8+JiC3AS8Cebav51s6T9Hge/hn6Kl76OPJX/UNJnzArez3q4oAKXQ9JEyQtBzYCSyOi0teimbI2+o3Gtcu2XsThETEXOB44V9KRLc5tFk/Z49yWenczpmuA6cAcYANw+Qh1KkUcknYG7gAujIiXW53apE5ljaNS1yMiXo+IOcBUYL6kWS1OL2UMRZS10V8PTKv5fSrwbJfq0lBEPJsfNwI/B+YDz0maDJAfN+bTm8WzPh/Xl3faeNb7zedI2g7YFXihbTWvERHP5TfuG8D3SdfkLXWqq2/X45C0Pamh/HFE/CwXV+56NIqjitcj1/tF4D7gOCp4LUZS1kb/YWCGpP0l7UBKetzV5Tq9SdI7JO0ydAx8BFhJquNZ+bSzSGOb5PKFOXu/PzADeCh/XdwsaUHO8J9Z85xOGs961/5bpwC/jTyI2W5Db87sZNI1GapT6eLIr3k98EREXFHzp0pdj2ZxVOl6SJokabd8vBNwDLCail2LQjqdRBhFMuUE0iyAp4CLul2furodQMrcPwasGqofaXzuXuDJ/LhHzXMuyrGsoWaGDjBAejM8BVxN+5NsPyV91X6N9Mnj0+NZb2BH4HZgLWkWwwEdjOMmYAXwOOkNNrnMcQDvJ329fxxYnn9OqNr1aBFHZa4HMBt4NNd1JXDxeL+nO/XeGOlnqDJmZtYHyjq8Y2ZmbeBG38ysj7jRNzPrI270zcz6SMcbfZV8ITUzs17W0UZf0gTgO6S7WGcCiyTNHOE557T6exX0QgzgOMqkF2KA3oijajF0+pP+fGBtRPwlIv4H3AKcOMJzKvUf2kQvxACOo0x6IQbojTgqFUOnG/0qLKRmZtazOnpzlqRTgWMj4uz8+yeA+RFxft1555B7z4kTJ86bNavVukewbNky5s2bV6i82bnttGnTJiZNmtTR12wHx1EevRAD9EYcZY1h2bJlz0fEVhXbbiz/qKR1wGbgdWBLRAxI2gO4lbTW+TrgtIj4V37Kh4DTJR0BfJ4mC4xFxHXAdQADAwMxODg4lmrW1pf6Ti5vatOw3Hcrm1lVSXq6Ufl4DO8cFRFzImIg/74YuDciZpDWqlicKzATeB/wD+Bs4Lt0eCG1Ro14zXoZb2rVOdRrVm5mVkbtGNM/EbgxH98InFRTfgtwHmlFvsnAHyNiVRvqMCbNOodarb4hNOLOwczKYKyN/qh3j4qIX0bEu0mrJP5mjK/fNc2Gftw5mFmZjWlMn7R71LOS9gaWSlrd4tzCu8bUJnL33XffMVaxu0bTORQdampVbmbWyoif9PPelhslrawp20PSUuD3+fE1hnePek3SX/Ndt4sY3mnmDeCb+U7cK2mxS1REXBcRAxExUMaseDu045uDvzWYWb0iwzs/JG0bVmsxcD8wl5Ss/RJp96iXSZ/ef5CfczXDidoPkmb6HEzasGA2aSMBG4XRfnOoL3PnYNbfRhzeiYj7lXa4r3UiaRuwB/K/cSBwKWmXmWtJUzM/mc9dmrdN257UgfwJ2Al4NCJeH2sA1ljRZLSHlMz6y7YmcveJiAcj4pCIOBj4b0RcRkrWromIo/OUzV8A78zl6yPisoiYDnycNNxjXeRktFn/Ge8pm82StYWTuJASuZIGJQ1u2rRp3Cpn28adg1nvKJTIBQZJQzhDtkjaIGl5TvD+J5evB87Iydo1wCGkZO16YLqkFZLWkjYUbpjEhf5M5PYCdw5m5Vc0kXtWXdka4JGImAPcDPwkl68EPgAcSrrr9hBgMM/XnwR8G5gBzCN1BNaHxtI5OBltNjZF5ul/FjgamChpPfBlUgL3Y5KeBJ4BTs3nziLN6lkObAEeBwbyGj3PAxcCS4BHSFM2zZoqkowGr6lkNhojftKPiEWk+ferImJqRFwPvEKajfMK8DTD4/NTgJsiYnpEHERq/Kfkn7URMSsncr+Gl1S2cVJkTSUPKZkl25rIvQaYDswBNgCX53Incq2UnG8wS4okcqeR1sk5UNIqSRdExHPArsA9wOnAaZJ2J43TT5O0JCdsFwLTcvlUSfMkrQBuB/ZTk3eME7nWLe4crNcV+aS/hTQcsxZYAJwr6UjyEsrAlcBT+fe7SEnfRcBHgX8C55OWYtgM/Ii0ps6jwKtsfaevWSW4c7CqKtLoX0FaVuEg4AnS9MyLgQtId+UelR9PysskP00ar78L+Ayps5gPfJE07fNmUidxOcPLLpv1JM9UsrIpsgzDoqHjvBzD/aRpmc9ExMyavw0tofwkKZl7cy4/hdQJrAP+EBHH5PIjcDLXDPBMJeucwolcSTsDdwAXRsTLrU5tUDaqZK4TuWaNeaaSjVWhRK6k+0jbHE4hJWahjXflOpFrtu2cb7BWiiZy/00a159BSuTOxHflmlWaO4f+VOSO3OmkmTgrSGvi7wOcjO/KNesL3v2ttxS5I/eBiFBEzCbNtnkJuArflWtmNTxTqRrGksht2125TuSa9a4iyWhoPVOpnjuH4ookcneU9DAp6TqFNEYPaV/cX5HG9o8k3bgFTuSa2Tgouvtbq/J67hyKfdJ/lTT3/gbSzJ3jJC0Avgrcm3fIeonhT/JO5JpZRzgZPXpFErmHk5ZVWEHaTGUGcBhwBvCspNNJwzvb5/OdyDWzUnEyelihRC6pc3iDNIZ/VUR8K/0p3hMRsyPiWNKm6OBErplVVDu+OZTtW0OhRG5EvJ7n408F5kua1eJ0J3LNrKeN9ptDfVk3O4dRracfES8C95FWx3xO0mSA/Lgxn7ae4bt2IXUUQ4ncqQ3KG72OE7lmVnllnKlUZPbOJEm75eOdgGOA1Qwvo0x+vDMf3wUslDRR0v6kHMBDOZG7WdKCvI7+mTXPMTPrW+2YqdSMRkpCSJoN3AhMIHUSt0XEpZL2BG4D9iXfkRsRL+TnXAR8ipTIvTAi7s7lA6SN1ncC7gbOjxEqIGkzaVpole1FSmJXneMoj16IAXojjrLG8K6I2GqoZMRGv9skDUbEQLfrMRa9EAM4jjLphRigN+KoWgzbukeumZlVkBt9M7M+UoVG/7puV2Ac9EIM4DjKpBdigN6Io1IxlH5M38zMxk8VPumbmdk4caNvZtZH3OibmfURN/pmZn3Ejb6ZWR/5P71+ZTg7BJElAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder parameters:2.28079200e+07(0.08497GB) Decoder parameters:1.94070000e+06(0.426GB)\n",
      "Data size:2.01974560e+07(0.07524GB)\n"
     ]
    }
   ],
   "source": [
    "# set the number of nodes in each layer\n",
    "a = 2\n",
    "b = int(100)\n",
    "db = int(10)\n",
    "\n",
    "M1 = int(a*m) # encoder hidden layer\n",
    "M2 = b + (m-1)*db # decoder hidden layer\n",
    "\n",
    "f = redDim # latent dimension\n",
    "\n",
    "# sparsity and shape of mask\n",
    "mask_2d=create_mask_2d(m,b,db)\n",
    "\n",
    "# number of parameters and memory\n",
    "en_para=m*M1+M1+M1*f\n",
    "de_para=f*M2+M2+np.count_nonzero(mask_2d)\n",
    "print('Encoder parameters:{:.8e}({:.4}GB)'.format(en_para,en_para*4/2**30),\\\n",
    "      'Decoder parameters:{:.8e}({:.4}GB)'.format(de_para,(f*M2+M2+M2*m)*4/2**30))\n",
    "\n",
    "# data size\n",
    "data_size=np.prod(orig_data_u.shape)\n",
    "print('Data size:{:.8e}({:.4}GB)'.format(data_size,data_size*4/2**30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file names\n",
    "if Re==10000:\n",
    "    file_name_AE_u=\"./model/AE_u_high_Re_v3_red-dim_{}pkl\".format(redDim)\n",
    "    file_name_AE_v=\"./model/AE_v_high_Re_v3_red-dim_{}.pkl\".format(redDim)\n",
    "    file_name_AE=\"./model/AE_high_Re_v3_red-dim_{}.p\".format(redDim)\n",
    "    \n",
    "    PATH_u = './checkpoint_u_high_Re_v3_red-dim_{}.tar'.format(redDim)\n",
    "    PATH_v = './checkpoint_v_high_Re_v3_red-dim_{}.tar'.format(redDim)\n",
    "elif Re==100:\n",
    "    file_name_AE_u=\"./model/AE_u_low_Re_v3_red-dim_{}.pkl\".format(redDim)\n",
    "    file_name_AE_v=\"./model/AE_v_low_Re_v3_red-dim_{}.pkl\".format(redDim)\n",
    "    file_name_AE=\"./model/AE_low_Re_v_3_red-dim_{}.p\".format(redDim)\n",
    "    \n",
    "    PATH_u = './checkpoint_u_low_Re_v3_red-dim_{}.tar'.format(redDim)\n",
    "    PATH_v = './checkpoint_v_low_Re_v3_red-dim_{}.tar'.format(redDim)\n",
    "else:\n",
    "    raise NameError('{} is given for Re, but it must be either 100 or 10000'.format(Re))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------checkpoint not restored--------\n",
      "\n",
      "\n",
      "Start first training... m=3364, f=25, a=2, b=100, db=10\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "try:\n",
    "    checkpoint = torch.load(PATH_u, map_location=device)\n",
    "    \n",
    "    encoder_u = Encoder(m,M1,f).to(device)\n",
    "    decoder_u = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    prune.custom_from_mask(decoder_u.full[2], name='weight', mask=torch.tensor(mask_2d).to(device))    \n",
    "       \n",
    "    optimizer = torch.optim.Adam(list(encoder_u.parameters()) + list(decoder_u.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    encoder_u.load_state_dict(checkpoint['encoder_u_state_dict'])\n",
    "    decoder_u.load_state_dict(checkpoint['decoder_u_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    last_epoch = checkpoint['epoch']\n",
    "    loss_hist = checkpoint['loss_hist']\n",
    "    best_loss = checkpoint['best_loss']\n",
    "    early_stop_counter = checkpoint['early_stop_counter']\n",
    "    best_encoder_u_wts = checkpoint['best_encoder_u_wts']\n",
    "    best_decoder_u_wts = checkpoint['best_decoder_u_wts']\n",
    "    \n",
    "    print(\"\\n--------checkpoint restored--------\\n\")\n",
    "\n",
    "    # resume training\n",
    "    print(\"\")\n",
    "    print('Re-start {}th training... m={}, f={},a={}, b={}, db={}'.format(\n",
    "        last_epoch+1, m, f, a, b, db))\n",
    "except:\n",
    "    encoder_u = Encoder(m,M1,f).to(device)\n",
    "    decoder_u = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    prune.custom_from_mask(decoder_u.full[2], name='weight', mask=torch.tensor(mask_2d).to(device))\n",
    "\n",
    "    optimizer = torch.optim.Adam(list(encoder_u.parameters()) + list(decoder_u.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    last_epoch = 0\n",
    "    loss_hist = {'train':[],'test':[]}\n",
    "    best_loss = float(\"inf\")\n",
    "    early_stop_counter = 1\n",
    "    best_encoder_u_wts = copy.deepcopy(encoder_u.state_dict())\n",
    "    best_decoder_u_wts = copy.deepcopy(decoder_u.state_dict())\n",
    "    \n",
    "    print(\"\\n--------checkpoint not restored--------\\n\")\n",
    "\n",
    "    # start training\n",
    "    print(\"\")\n",
    "    print('Start first training... m={}, f={}, a={}, b={}, db={}'\\\n",
    "          .format(m, f, a, b, db))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 2.4580939046344435e-06\n",
      "test MSELoss: 2.4523210868210297e-06\n",
      "\n",
      "Epoch 200/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 1.6283812028517938e-06\n",
      "test MSELoss: 1.626231096452102e-06\n",
      "\n",
      "Epoch 300/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 9.890457429552436e-07\n",
      "test MSELoss: 9.939822348314919e-07\n",
      "\n",
      "Epoch 400/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 5.91401830356911e-07\n",
      "test MSELoss: 6.06192520535842e-07\n",
      "\n",
      "Epoch 500/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 3.335910771514774e-07\n",
      "test MSELoss: 3.3818348583736223e-07\n",
      "\n",
      "Epoch 600/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 3.1326635383745285e-07\n",
      "test MSELoss: 3.183528178851702e-07\n",
      "\n",
      "Epoch 700/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.8622892391211944e-07\n",
      "test MSELoss: 2.903311724367086e-07\n",
      "\n",
      "Epoch 800/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.5443875565263463e-07\n",
      "test MSELoss: 2.592043813365308e-07\n",
      "\n",
      "Epoch 900/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.2145152439142053e-07\n",
      "test MSELoss: 2.2613474754962225e-07\n",
      "\n",
      "Epoch 1000/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.916939862448487e-07\n",
      "test MSELoss: 1.9558377459816256e-07\n",
      "\n",
      "Epoch 1100/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.6675281864271133e-07\n",
      "test MSELoss: 1.7063506732029055e-07\n",
      "\n",
      "Epoch 1200/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.476234492095377e-07\n",
      "test MSELoss: 1.5191396585123584e-07\n",
      "\n",
      "Epoch 1300/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.3179192934935993e-07\n",
      "test MSELoss: 1.3554624729295027e-07\n",
      "\n",
      "Epoch 1400/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.1846587073369187e-07\n",
      "test MSELoss: 1.2217858511576196e-07\n",
      "\n",
      "Epoch 1500/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.085722772047553e-07\n",
      "test MSELoss: 1.105677043256037e-07\n",
      "\n",
      "Epoch 1600/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 9.93444561393784e-08\n",
      "test MSELoss: 1.0164207253637869e-07\n",
      "\n",
      "Epoch 1700/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 9.243209453498019e-08\n",
      "test MSELoss: 9.45180573808102e-08\n",
      "\n",
      "Epoch 1800/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 8.31650337286131e-08\n",
      "test MSELoss: 8.495561019117303e-08\n",
      "\n",
      "Epoch 1900/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 8.251850917352652e-08\n",
      "test MSELoss: 8.415564280994659e-08\n",
      "\n",
      "Epoch 2000/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 8.184544130841118e-08\n",
      "test MSELoss: 8.342248349890725e-08\n",
      "\n",
      "Epoch 2100/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 8.097739983814278e-08\n",
      "test MSELoss: 8.250333678461175e-08\n",
      "\n",
      "Epoch 2200/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 8.011263611045539e-08\n",
      "test MSELoss: 8.16364405409331e-08\n",
      "\n",
      "Epoch 2300/10000, Learning rate 1.0000000000000002e-07\n",
      "----------\n",
      "train MSELoss: 7.902571154546354e-08\n",
      "test MSELoss: 8.071674670873107e-08\n",
      "\n",
      "Epoch 2400/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 7.898318415847286e-08\n",
      "test MSELoss: 8.06804649755577e-08\n",
      "\n",
      "Epoch 2487/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 7.897678928962916e-08\n",
      "test MSELoss: 8.067978853887326e-08\n",
      "\n",
      "Early stopping: 2487th training complete in 1h 24m 2s\n",
      "----------\n",
      "Best train MSELoss: 7.904057497398753e-08\n",
      "Best test MSELoss: 8.074764963339476e-08\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "since = time.time()\n",
    "\n",
    "for epoch in range(last_epoch+1,num_epochs+1):   \n",
    "\n",
    "    if epoch%num_epochs_print == 0:\n",
    "        print()\n",
    "        print('Epoch {}/{}, Learning rate {}'.format(\n",
    "            epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "        print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and test phase\n",
    "    for phase in ['train', 'test']:\n",
    "        if phase == 'train':\n",
    "            encoder_u.train()  # Set model to training mode\n",
    "            decoder_u.train()  # Set model to training mode\n",
    "        else:\n",
    "            encoder_u.eval()   # Set model to evaluation mode\n",
    "            decoder_u.eval()   # Set model to evaluation mode\n",
    "            \n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Iterate over data\n",
    "        for data, in data_loaders_u[phase]:\n",
    "            inputs = data.to(device)\n",
    "            targets = data.to(device)\n",
    "\n",
    "            if phase == 'train':\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = decoder_u(encoder_u(inputs))\n",
    "                loss = loss_func(outputs, targets)\n",
    "\n",
    "                # backward\n",
    "                loss.backward()\n",
    "\n",
    "                # optimize\n",
    "                optimizer.step()  \n",
    "\n",
    "                # add running loss\n",
    "                running_loss += loss.item()*inputs.shape[0]\n",
    "            else:\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    outputs = decoder_u(encoder_u(inputs))\n",
    "                    running_loss += loss_func(outputs,targets).item()*inputs.shape[0]\n",
    "\n",
    "        # compute epoch loss\n",
    "        epoch_loss = running_loss / dataset_u_shapes[phase][0]\n",
    "        loss_hist[phase].append(epoch_loss)\n",
    "            \n",
    "        # update learning rate\n",
    "        if phase == 'train':\n",
    "            scheduler.step(epoch_loss)\n",
    "\n",
    "        if epoch%num_epochs_print == 0:\n",
    "            print('{} MSELoss: {}'.format(\n",
    "                phase, epoch_loss))\n",
    "\n",
    "    # deep copy the model\n",
    "    if round(loss_hist['test'][-1],10) < round(best_loss,10):\n",
    "        best_loss = loss_hist['test'][-1]\n",
    "        early_stop_counter = 1\n",
    "        best_encoder_u_wts = copy.deepcopy(encoder_u.state_dict())\n",
    "        best_decoder_u_wts = copy.deepcopy(decoder_u.state_dict())\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= early_stop_patience:  \n",
    "            break\n",
    "    \n",
    "    # save checkpoint every num_epoch_print\n",
    "    if epoch%num_epochs_print== 0:\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'encoder_u_state_dict': encoder_u.state_dict(),\n",
    "                    'decoder_u_state_dict': decoder_u.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss_hist': loss_hist,\n",
    "                    'best_loss': best_loss,\n",
    "                    'early_stop_counter': early_stop_counter,\n",
    "                    'best_encoder_u_wts': best_encoder_u_wts,\n",
    "                    'best_decoder_u_wts': best_decoder_u_wts,\n",
    "                    }, PATH_u)        \n",
    "\n",
    "print()\n",
    "print('Epoch {}/{}, Learning rate {}'\\\n",
    "      .format(epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "print('-' * 10)\n",
    "print('train MSELoss: {}'.format(loss_hist['train'][-1]))\n",
    "print('test MSELoss: {}'.format(loss_hist['test'][-1]))\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "\n",
    "# load best model weights\n",
    "encoder_u.load_state_dict(best_encoder_u_wts)\n",
    "decoder_u.load_state_dict(best_decoder_u_wts)\n",
    "\n",
    "# compute best train MSELoss\n",
    "encoder_u.to('cpu').eval()\n",
    "decoder_u.to('cpu').eval()\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    train_inputs = torch.tensor(data_u[train_ind])\n",
    "    train_targets = torch.tensor(data_u[train_ind])\n",
    "    train_outputs = decoder_u(encoder_u(train_inputs))\n",
    "    train_loss = loss_func(train_outputs,train_targets).item()\n",
    "\n",
    "# print out training time and best results\n",
    "print()\n",
    "if epoch < num_epochs:\n",
    "    print('Early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "else:\n",
    "    print('No early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "print('-' * 10)\n",
    "print('Best train MSELoss: {}'.format(train_loss))\n",
    "print('Best test MSELoss: {}'.format(best_loss))\n",
    "\n",
    "# # save models\n",
    "# print()\n",
    "# print(\"Saving after {}th training to\".format(epoch),file_name_AE_u)\n",
    "# torch.save((encoder_u,decoder_u),file_name_AE_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "checkpoint removed\n"
     ]
    }
   ],
   "source": [
    "# delete checkpoint\n",
    "try:\n",
    "    os.remove(PATH_u)\n",
    "    print()\n",
    "    print(\"checkpoint removed\")\n",
    "except:\n",
    "    print(\"no checkpoint exists\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhc1X3/8ff3zmizLK+ywXiJDXbMYghg2QmBJKYJYANmSVIKgZQ2BNM2NPRpyS8QskCzQNOWJ6UhIZA6hEKghCQFJ6YQEraEzTYYMBjjJRjLm4QX2ZK1zdzv748ZybIsWcuMNFczn9fz6NHMmTt3vkdjf3R07p1zzd0REZH8F+S6ABERGRwKfBGRAqHAFxEpEAp8EZECocAXESkQ8VwXcCiVlZU+derUXJchIjKkrFix4j13H9e5PZKBb2YLgYXTp09n+fLluS5HRGRIMbONXbVHckrH3Ze4+6KRI0fmuhQRkbwRycAXEZHsi2Tgm9lCM7uzrq4u16WIiOSNSM7hu/sSYElVVdWVua5FRIaW1tZWqquraWpqynUpA660tJRJkyZRVFTUq+0jGfgiIv1VXV1NRUUFU6dOxcxyXc6AcXd27NhBdXU106ZN69VzNKUjInmlqamJsWPH5nXYA5gZY8eO7dNfMpEMfJ2lIyKZyPewb9PXfkYy8DP1f6u28eNnN+S6DBGRSMnLwH9i9XZ+8sd3cl2GiBSo3bt384Mf/KDPzzv77LPZvXv3AFSUkpeBHxgkQ13YRURyo7vATyaTh3ze0qVLGTVq1ECVFc2zdDourdAfscAIdSUvEcmR6667jvXr13PiiSdSVFTE8OHDmTBhAitXruTNN9/kggsuYNOmTTQ1NXHNNdewaNEiAKZOncry5cupr69nwYIFnHbaaTz33HNMnDiRhx9+mLKysozqimTgZ3oevpmhAb6I3LTkDd7csier+zz2iBF8Y+Fxh9zmlltuYdWqVaxcuZKnnnqKc845h1WrVrWfPrl48WLGjBlDY2Mjc+bM4VOf+hRjx449YB9r167l/vvv56677uKiiy7iF7/4BZdddllGtUcy8DMVGBrhi0hkzJ0794Bz5W+77TZ+9atfAbBp0ybWrl17UOBPmzaNE088EYDZs2fzzjvvZFxHXgZ+zDSlIyL0OBIfLOXl5e23n3rqKZ544gmef/55hg0bxrx587o8l76kpKT9diwWo7GxMeM68vKgrZnpoK2I5ExFRQV79+7t8rG6ujpGjx7NsGHDeOutt3jhhRcGra78HOEHhgb4IpIrY8eO5dRTT2XWrFmUlZVx2GGHtT82f/587rjjDk444QRmzpzJhz70oUGrK5KBn+lZOjotU0Ry7Wc/+1mX7SUlJTz66KNdPtY2T19ZWcmqVava26+99tqs1BTJKZ1Ml1YIdFqmiMhBIhn4mQp00FZE5CB5Gfgn1fySrwZ357oMEZFIieQcfqaOqH+T4wJd/FxEpKO8HOG7BcQIcU3riIi0y8vAx2LECLW8gohIB4Ma+GZ2gZndZWYPm9mZA/U6bjECQp2aKSI50d/lkQG+973vsW/fvixXlNLrwDezxWZWY2arOrXPN7M1ZrbOzK471D7c/X/d/Urgr4C/6FfFvRHEiJPUmToikhNRDfy+HLS9G/g+cE9bg5nFgNuBM4BqYJmZPQLEgJs7Pf9z7l6Tvv3V9PMGRGqE7wp8EcmJjssjn3HGGYwfP54HH3yQ5uZmLrzwQm666SYaGhq46KKLqK6uJplM8rWvfY3t27ezZcsWTj/9dCorK3nyySezWlevA9/dnzGzqZ2a5wLr3H0DgJk9AJzv7jcD53beh6UuwHgL8Ki7v9zV65jZImARwJQpU3pb3oECzeGLCPDodbDt9ezu8/DjYcEth9yk4/LIjz/+OA899BAvvfQS7s55553HM888Q21tLUcccQS/+c1vgNQaOyNHjuTWW2/lySefpLKyMrt1k/kc/kRgU4f71em27vw98Ang02b2N11t4O53unuVu1eNGzeuf1Wlz9LRCF9Ecu3xxx/n8ccf56STTuLkk0/mrbfeYu3atRx//PE88cQTfPnLX+bZZ5+lvysL9EWm5+F3dcn0blPW3W8DbutxpxmupeMWJ0aSUEN8kcLWw0h8MLg7119/PVddddVBj61YsYKlS5dy/fXXc+aZZ/L1r399QGvJdIRfDUzucH8SsCXDfWa8lg5BjLhpSkdEcqPj8shnnXUWixcvpr6+HoDNmzdTU1PDli1bGDZsGJdddhnXXnstL7/88kHPzbZMR/jLgBlmNg3YDFwMfCbTojId4WOp32M9XTBYRGQgdFweecGCBXzmM5/hlFNOAWD48OHce++9rFu3ji996UsEQUBRURE//OEPAVi0aBELFixgwoQJWT9oa739NKqZ3Q/MAyqB7cA33P2/zOxs4HukzsxZ7O7fzlZxVVVVvnx535dIWHnfDZy49vvUXFPN+NEV2SpHRIaA1atXc8wxx+S6jEHTVX/NbIW7V3Xeti9n6VzSTftSYGlfizyUjEf4QapbybA1e0WJiAxxkVxaIdM5/NTHA8CTYTbLEhEZ0iIZ+Ga20MzurKur69fzPUgFfphMZLMsERkiCmXhxL72M5KBn/FZOm0j/FCBL1JoSktL2bFjR96HvruzY8cOSktLe/2cvFwP39pH+DpLR6TQTJo0ierqampra3NdyoArLS1l0qRJvd4+koGf8QevNKUjUrCKioqYNm1arsuIpLyc0mkb4aMpHRGRdpEM/Ey1BX4y1JSOiEibSAZ+pmfptJ2H75rSERFpF8nAz8ZaOgCug7YiIu0iGfiZMp2WKSJykPwM/Fhb4GuELyLSJi8Dv+2DVzotU0Rkv0gGfqYHbS2W/niBRvgiIu0iGfjZOg8/VOCLiLSLZOBnytpPy9TyyCIibfIy8GPx9AevdFqmiEi7vAz8oO0CKDpoKyLSLi8DPxZPB35CI3wRkTaRDPxMz9KJxYsAcF3iUESkXSQDP9OzdGJaHllE5CCRDPxMtU/p6KCtiEi7PA381JSORvgiIvvlZ+DHtDyyiEhneRn48fSUjq5pKyKyX14GftscfqjlkUVE2g1a4JvZMWZ2h5k9ZGZ/O5CvFW87LVNTOiIi7XoV+Ga22MxqzGxVp/b5ZrbGzNaZ2XWH2oe7r3b3vwEuAqr6X3LP4kUlqRtaS0dEpF1vR/h3A/M7NljqslK3AwuAY4FLzOxYMzvezH7d6Wt8+jnnAX8Afpe1HnQhVlyWqjHZPJAvIyIypMR7s5G7P2NmUzs1zwXWufsGADN7ADjf3W8Gzu1mP48Aj5jZb4Cf9bfoHsWKU9+TTQP2EiIiQ02vAr8bE4FNHe5XAx/sbmMzmwd8EigBlh5iu0XAIoApU6b0r7J4akrHki39e76ISB7KJPCtizbvbmN3fwp4qqeduvudZrYVWFhcXDy7X5WlR/iBpnRERNplcpZONTC5w/1JwJbMyknJdC0dzGimSCN8EZEOMgn8ZcAMM5tmZsXAxcAj2Sgq09UyAVooIlDgi4i06+1pmfcDzwMzzazazK5w9wRwNfAYsBp40N3fyEZRGY/wgVYr0lk6IiId9PYsnUu6aV/KIQ7A9peZLQQWTp8+vd/7SFCsKR0RkQ4iubRCNkb4iaBYI3wRkQ4iGfjZmMNPBkUEoUb4IiJtIhn42RjhJ4MSnZYpItJBJAM/G5JBMXGN8EVE2kUy8LMypRMro9i1tIKISJtIBn5WDtrGh1EaNmaxKhGRoS2SgZ8NYVE5pWiELyLSJn8DPz6MYTTRkghzXYqISCREMvCzMYdPcTnlNNPYquvaiohARAM/G3P4FJdTYq3sa9K0jogIRDTws8FKhgPQ1LA3x5WIiERD3gZ+vKQcUOCLiLSJZOBnYw4/VlYBQHPjnmyVJSIypEUy8LMxhx8vTQV+6776bJUlIjKkRTLws6E4PcJvbdIIX0QE8jnwh6UCP9HYkONKRESiIW8Dv7Q8FfjJZh20FRGBfA78YSMACJs1whcRgYgGfjbO0mmbw/dmHbQVEYGIBn62PmkLQItG+CIiENHAz4p4CSEGLftyXYmISCTkb+Cb0UQJltCa+CIikM+BD7RYqQJfRCQtrwO/OSglllTgi4hAngd+IiglrsAXEQEGOfDNrNzMVpjZuYPxeolYKfGk1sMXEYFeBr6ZLTazGjNb1al9vpmtMbN1ZnZdL3b1ZeDB/hTaH4lYGUWhAl9EBCDey+3uBr4P3NPWYGYx4HbgDKAaWGZmjwAx4OZOz/8ccALwJlCaWcm9F8bKKA61eJqICPQy8N39GTOb2ql5LrDO3TcAmNkDwPnufjNw0JSNmZ0OlAPHAo1mttTdB/QK42FRGaXeiLtjZgP5UiIikdfbEX5XJgKbOtyvBj7Y3cbufgOAmf0V8F53YW9mi4BFAFOmTMmgPEgWVzDK9tGcCCktimW0LxGRoS6TwO9qyOw9Pcnd7+7h8TvNbCuwsLi4eHY/awMgLB7JCPbR0JxQ4ItIwcvkLJ1qYHKH+5OALZmVk5KVtXQALx1BmbWwr1GnZoqIZBL4y4AZZjbNzIqBi4FHslFUNlbLBAjKRgHQXL87G2WJiAxpvT0t837geWCmmVWb2RXungCuBh4DVgMPuvsb2SgqWyP8oDT1/Ob6ndkoS0RkSOvtWTqXdNO+FFia1YpIjfCBhdOnT89oP7Hy1Ai/tWE3rP41VBwOk6r2b7DxOZjwgf1LKYuI5LFILq2QrRF+UTrw63e/B/9zKfz44/sf3LsNfrIAfnVVRq8hIjJURDLws6ViVCUAP3vm9fa2n/zxT5z8zd/uvzDKtte7eqqISN6JZOBn66Dt2DGpwJ81dn/bTUveZGdDC7R9EMt7PJNURCQvRDLwszWlY8NSSX+Sv3nQY6G3fYxAgS8ihSGSgZ+tET7FwwA4pf6Jgx5KuEb4IlJYIhn42RrhH0rYlvMKfBEpEJEM/IEUpAf2if2Jn7NaREQGU8EFfiyd+Ek0pSMihSWSgZ+1Ofyu9w1Asm2tzoFdoVlEJDIiGfgDOYdf5o0caVtItg/sNcIXkcIQycDPpur5iw+4f3vwb/y+5FoSyWSqQVM6IlIg8j7wS4ePPuD+abHU+m6xmrZz8xX4IlIYIhn42ZzDLy/r5hK6DTUAJJKawxeRwhDJwM/mHH5p4sBfGqvD1DVbkkEJAHsamzN+DRGRoSCSgZ9NNnLygffT38MwecB9EZF8l/eBz+GzDrhr6Tl7bw98zeGLSGHI/8DvZGZQDUAyqcAXkcJScIHf5uk12wEFvogUjkgG/kB+0rbNqs2pC5trDl9ECkUkAz/bn7RdMueeg9pipE7H1AhfRApFJAM/285ZcB4PJz98QFuQDnoFvogUioII/CAw4rHYAW0V7AM0pSMihaMgAh/gdJYdcP+6ogcACNAnbUWkMBRM4A+jqct2jfBFpFAUTOB3T3P4IlIYCibwdx4xr8t2HbQVkUIxaIFvZvPM7Fkzu8PM5g3W67apnfEXXbYHCnwRKRC9CnwzW2xmNWa2qlP7fDNbY2brzOy6HnbjQD1QClT3r9z+Kzv+/C7bNcIXkUIR7+V2dwPfB9o/wWRmMeB24AxSAb7MzB4BYsDNnZ7/OeBZd3/azA4DbgUuzaz0vplSWd5luw7aikih6FXgu/szZja1U/NcYJ27bwAwsweA8939ZuDcQ+xuF1DS3YNmtghYBDBlypTelJeRwDTCF5HCkMkc/kRgU4f71em2LpnZJ83sR8B/k/proUvufqe7V7l71bhx4zIoT0REOurtlE5XupoN6Xa47O6/BH7Zqx2bLQQWTp8+vZ+ldWPKh+Hd57K7TxGRISKTEX410PFyUpOALZmVM8BmfTLXFYiI5Ewmgb8MmGFm08ysGLgYeCQbRWV7tcx2cz6f3f2JiAwhvT0t837geWCmmVWb2RXungCuBh4DVgMPuvsb2ShqwNbDN52TIyKFq7dn6VzSTftSYGlWK0rtdwmwpKqq6sps71tEpFAVzNIK7c65leV+dK6rEBEZdJEM/AG9xOGcK4if1OUfLCIieS2SgT9gB23TKivKBmS/IiJRFsnAH2iTxgzPdQkiIoMukoE/oFM6AEGs521ERPJMJAN/oKd0KO56ITURkXwWycAfcDPPgTFHAbDGjsxxMSIigyOSgT/wUzoBfPFl3i6fTRPFA/MaIiIRE8nAH/ApnXamC6CISMGIZOAPGgswwlxXISIyKAo68N0CAtcIX0QKQyQDf8Dn8NOSRcMZ4XsIQ4W+iOS/SAb+YM3hN489hslWQ/XmQb+muojIoItk4A+Wyg+cTcIDWhefzXOP3kdrIpnrkkREBkxBB/7kWR/m3TN/zDBr5sMv/h1F3xrDyw9/n2SiNdel9cwdnvlX2L2p521FRCjwwAc48tRPcfhXXmfT+y8H4ORXbmDrd07g1d/cSRjl4N+xHn7/LfifS3NdiYgMEQUf+AAWL2HyZ24j/Nouln3oP2mmmA8s+xI13zmON5begSejGPzpA80tDbktQ0SGDAV+B0EsYM78v2TqDS/z/Jzb2OPDOO6lL7PlOx/grcfvwsMozfGnLtdYt685x3WIyFARycAfrNMyuxOLxTjlnMuZdsNynj35ezSGcY5+7lq2f/s43nrmoZzUdJD09Xl3NbTkuBARGSoiGfiDt7TCoRXF43zkvL9m8ldW8Ifj/pnGZMDRv7+C127+OG+/viyntbUFvpaGEJHeimTgR01JURGn/fk1HP6ll3jpqC/yvua3mPbQWay69TxqN2/IUVUKfBHpGwV+H5SVD2fuZ79J8MXlvDZ+IbP2PE3xnaex47snUf/uysEtxlJvXWAKfBHpHQV+P1SMmcDsL/yUTRc/QW3p+xi7bwPDF3+Mt175Y65LExHplgI/A5OPnsP0659nw0f+nV2M4OiHz+a1//hz9m55exBePTWyD7Tap4j0kgI/C478+OeJfXE5L409nxN2PU7FnXN4/Vf/iocDF8aeXuXTBuwVRCTfDFrgm1lgZt82s/80s8sH63UHy4gxhzH37+/h3U/8iCZKOP7Vb2H/PJr3Vj87IK8Xpn+Z6KCtiPRWrwLfzBabWY2ZrerUPt/M1pjZOjO7rofdnA9MBFqBvF2ecsppFxP/6hZemPFPAIx5YCHv3HkJvmdLVl9HgS8ifdXbEf7dwPyODWYWA24HFgDHApeY2bFmdryZ/brT13hgJvC8u/8j8LfZ60L0xONxPnTp19n82T+woXgGU7csxW49hh1P3p6113BPBX6gwBeRXupV4Lv7M8DOTs1zgXXuvsHdW4AHgPPd/XV3P7fTVw2pUf2u9HO7XaPAzBaZ2XIzW15bW9v3HkXIxKOO58jrXmTtuDMBGPv0V1hzx2UkWpoy3vf+4wMKfBHpnUzm8CcCHdfmrU63deeXwFlm9p/AM91t5O53unuVu1eNGzcug/KiIYgFzPjCz6n93DK2FL2PmduWEP/OYWx79F9SSxz3k7dP6YiI9E4mgd9V1nSbYO6+z92vcPe/d/dDzm3kei2dgTBuyvs54obXeOOkrwNw+IvfgZtG0bz1zX7tL2w/S0cjfBHpnUwCvxqY3OH+JCArRyajspbOQDju/H/ivb9ZxaaiqQCU/OgU6n56Cb6v84xZT9rOw3d+vnwTD63I2+PgIpIlmQT+MmCGmU0zs2LgYuCRbBSVjyP8jioPn8zkG17lxQ98B4CRf1qKfXcaftPoXl/BKkwv1Ww4X3roNa79+asDVq+I5IfenpZ5P/A8MNPMqs3sCndPAFcDjwGrgQfd/Y1sFJXPI/yOPnjhF6i96nVaKALAPITvzYLmvT1e2MTD/SP8ecErzLR3B7xeERnazDM4cDhQzGwhsHD69OlXrl27NtflDIoVj9/H7Of+7sDGM78No6fCMece2L7xORq2rKb8sX9kj5cxwhpT7Tfm519EItI3ZrbC3asOao9i4Lepqqry5cuX57qMQdOwr5Hy7x5+ULt/+ifYzAWweQVMPQ1u3P+Xz14vo0KBLyIddBf48VwU05MOI/xclzKoyoeVwY11vPSbnzB32T+0t9tDf93tc7R4moj0ViQXTyuUOfzuzD3nr/Fv7ObpYWf0uG0ZusShiPROJANfwMz42P97iNcuf+uQ23W8AEqUp+dEJPciGfj5flpmX5wwbQL+jd08cd5LhH7oz9X+7MlXBqkqERmKIhn4hT6l05mZ8YmTZxLctJv/XfgKDyU/2uV2m569b5ArE5GhJJKBL927YPaRfPqbS7j/jBf5XfzA4D9mfHGOqhKRoSCSga8pnZ5dcurR/NkNj3DfUf/G88WnAFBZ3O0ipCIi0Qx8Ten0jplx6Wev5JSv/B+NXkxR03u5LklEIiyS5+FL3+0KRjG39hckbnyYhtgIGmMVJOLlJIorCMvG4uXjiY84nLLhIygdM5HhFaMJRk2CkZMhrqkgkUKgwM8T28+5h5ee/yU07aakZRcliXqKm/dRXr+DSjZQaXWU2cHn7IcYDUEFjfERBLFi6kfNxEZOpGTkeEYcMZNhh8+AstEwrFK/GESGOC2tkOdakyG79rWwu6GFnTt3sGdXLc17ammpq8H2VBPft52ipp2UtuzkiEQ1ZTRxmO2ixBIH7KfFSthdMoF4vJgiWmmafSWjJ84kPnICjD8WTJdiEYmKIbWWTiEunhYFrcmQ2r3NbK9r5L3abezduo5kzRridRsp27eZ0a3bmM1bxO3g5Rx2FE+iZeT7mFD7RxqnnUnpGTdg44/VXwUiOTCkAr+NRvjREobOe/XNbN7VwOaNa2na9jbF21cydu9qgua9nMxblFjrAc/ZVXQ4jcMnkxh3HEfU/oHYh67CZn0KysfmqBci+U+BLwMqGTqbdu5j+87d7NzwMo1bVuM71jOyYQOV4Xscb38i1mEZiN3Fh5EoO4wRrTWEc66kdNyRMO2jUF6Zw16I5AcFvuRMzd4m1m/dwa41zzF6/cOUNWyipqWYM+2lbp9Tf9hcyt7/MWJBDE64CMYeNYgViwxtCnyJlDB0ttQ18tq6d9n27lrGvvsYVXWPMZGanp98zEI445swZtrAFyoyBCnwZUiob07w+qbdrH57DVPX/zd/tuP+brdtKBpD08ij8BlnMrpuNRw+i9jU02DUZBhxxCBWLRItQyrwdZaOdBSGztY9TaxYs5HYml8ze9PdJBKtbE6O4oNB98tHJ4vKCZIt2F/cC1NPTTWWVAxS1SK5M6QCv41G+HIojS1J1mzbw/rVr+Crf82FuxbTYOWMoL7H5/qR87ANT8FVz8KEEwa8VpHBpMCXglG7t5kX1tfS+u4yRr15H8e3vsq4ZC+ODQCJKR8hfvqXYfIHAYd4ycAWKzIAFPhS8Gr3NvPm1j28t/4VfOMLfHLrrQTm7PZyRllDt89rKRlDcfNOEhWTiF/4Axg5KfVAcTlUHHzReZFcU+CLdKOpNcnmXft4u3o79RtXUr7xd4ys38CpiRf6tqP3z4czvw2j35e6bwEEsewXLNIDBb5IP+xsaGHNlh08+cpaJu74A8VNO7mk7q4+7SNZMQkzCFrqYd718IGLUweP9ctABogCXyTLavY28e62Hfx+1bsMr32Fj+/+OSX1mxlre6iwxr7v8PIlEMRh97sw61PQug9KdU0I6bucB76ZfQS4lNSSzMe6+4d7eo4CX4aq5kSSFRt3sXPHDrZvXM2oLU8zq+FF4k072eTjmRd7tU/7S1RMIn7YMXDchTBqCkw9Dba/AbEiGDcTkgmIabVzScko8M1sMXAuUOPuszq0zwf+A4gBP3b3W3qxrwuAw9z9Rz1tq8CXfOTu7N7Xyp92NPDyhloqd7/Cm1v3Mib5HifseZopzW8zyfp39bKw6gqCsdNh0pzUGUbF5dBSD4efoCWsC0imgf9RoB64py3wzSwGvA2cAVQDy4BLSIX/zZ128Tl3r0k/70Hg8+6+p6fXVeBLoUokQzbuaODlP9VSX7eTip2vEd+6ggvq7gXgt+EczgiW9X2/wycQSzZhY47CY0XYsefDnM9DXTXUroGZ87PdFcmBjKd0zGwq8OsOgX8KcKO7n5W+fz2Au3cO+477mAJ8zd2vPMQ2i4BFAFOmTJm9cePGXtUnUmiaWpO8s6OBDbUNrNxYy5Rtv6UpjPHx2nsZ31rNtnAURwVb+7zfZKyUhqmfYFjrLrxpD0VHz4epH4F4aWr6qKUhtXSF/mKIrIEI/E8D89398+n7nwU+6O5XH2IfNwGPuftzvXlNjfBFMtOSCHljSx37WpJseW839e9Vw7bXsWQzZ9T8hInJ6n7v279ag+mDaZHUXeBncpSnq1/vh/zt4e7f6NWO96+l05+6RCStOB5w0pTRqTvTK4HpwLz0o9e2b+fu7GlKsHX3Pl6trqN13x52bN3AOxvfZV7ij8xrfZqRHPjhNPvWeJqsDMxwAhzDzXCM0OIkLY4BbgGhxXELcIvhFkDH221REsRTbenvqW0CPIgDhplBrAgPivEghgWpbSyIYUE8db+tPYhhFsOCAIsVY/FiLEi9bhDEMDOCWEDQto0FqftBjCAIsCAgSG+LBam/ZszSt9NfdLrfeZsuH+9wu7vHSe9n5GQoHpbVfw+ZBH41MLnD/UnAlszKSXH3JcCSqqqqbqd+RCR7zIyRZUWMLBvJ0RPaTgVtOz9j/x/tLYmQHXV7+P29t1BUvxX3EMMBx9wxDwEnHiYISOLuBITEPIF5SECIERKkbwekHgcIaCVuzcRIEqft8ZA4yfbRZTGtFFuCGCGx9OP7b/tB7YFF97Tznqw/50GOmnNWVveZSeAvA2aY2TRgM3Ax8JlsFKURvkg0FccDJowdxaXX9HhCXo/C0AndcVJXTEu03Q8h6anboTvuqceTodOSDGlyCN1JJFOPJ0InGYYkkk7SU9uF6W2SiZBksoUw0UyYdCAkTCYJw5BkGJJMJnFva3PCMEnoIZ5MkvQQkiGhhyTDJB46HoaEYZJEMkkikaA1GaZ+0dH2PX2b1C+/1Di+4/0O27Rv7+lfgulfnOlfgKdXvj/jn3FnvQp8M7uf1N+BlWZWDXzD3f/LzK4GHiN1Zs5id38jG0VphC+S/4LACNJj9yJ96HhQ9Crw3f2SbghgejkAAAQLSURBVNqXAkuzWhEa4YuIDIQg1wV0xd2XuPuikSP1sXIRkWyJZOCb2UIzu7Ouri7XpYiI5I1IBr5G+CIi2RfJwBcRkeyLZOBrSkdEJPsiGfia0hERyb5IBr6IiGRfpK94ZWa1QH+Xy6wE+reo+NBViH2Gwuy3+lwY+tvn97n7uM6NkQ78TJjZ8q5Wi8tnhdhnKMx+q8+FIdt91pSOiEiBUOCLiBSIfA78O3NdQA4UYp+hMPutPheGrPY5b+fwRUTkQPk8whcRkQ4U+CIiBSIvA9/M5pvZGjNbZ2bX5bqebDKzd8zsdTNbaWbL021jzOy3ZrY2/X10h+2vT/8c1phZdq+XNkDMbLGZ1ZjZqg5tfe6jmc1O/6zWmdltZtbVdZgjoZs+32hmm9Pv9UozO7vDY/nQ58lm9qSZrTazN8zsmnR73r7Xh+jz4LzX7p5XX6SuvrUeOBIoBl4Fjs11XVns3ztAZae27wLXpW9fB/xL+vax6f6XANPSP5dYrvvQiz5+FDgZWJVJH4GXgFNIXSX7UWBBrvvWxz7fCFzbxbb50ucJwMnp2xXA2+m+5e17fYg+D8p7nY8j/LnAOnff4O4twAPA+TmuaaCdD/w0ffunwAUd2h9w92Z3/xOwjtTPJ9Lc/RlgZ6fmPvXRzCYAI9z9eU/977inw3Mip5s+dydf+rzV3V9O394LrAYmksfv9SH63J2s9jkfA38isKnD/WoO/QMdahx43MxWmNmidNth7r4VUv+ggPHp9nz6WfS1jxPTtzu3DzVXm9lr6SmftqmNvOuzmU0FTgJepEDe6059hkF4r/Mx8Luax8qnc09PdfeTgQXAF8zso4fYNt9/FtB9H/Oh7z8EjgJOBLYC/55uz6s+m9lw4BfAP7j7nkNt2kXbkOx3F30elPc6HwO/Gpjc4f4kYEuOask6d9+S/l4D/IrUFM329J94pL/XpDfPp59FX/tYnb7duX3IcPft7p509xC4i/3TcXnTZzMrIhV897n7L9PNef1ed9XnwXqv8zHwlwEzzGyamRUDFwOP5LimrDCzcjOraLsNnAmsItW/y9ObXQ48nL79CHCxmZWY2TRgBqkDPUNRn/qYngrYa2YfSp+98JcdnjMktIVe2oWk3mvIkz6na/wvYLW739rhobx9r7vr86C917k+aj1AR8LPJnX0ez1wQ67ryWK/jiR1xP5V4I22vgFjgd8Ba9Pfx3R4zg3pn8MaInrmQhf9vJ/Un7WtpEYyV/Snj0BV+j/OeuD7pD9ZHsWvbvr838DrwGvp//gT8qzPp5GahngNWJn+Ojuf3+tD9HlQ3mstrSAiUiDycUpHRES6oMAXESkQCnwRkQKhwBcRKRAKfBGRAqHAFxEpEAp8EZEC8f8B5X1S1pD1l2QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and test loss\n",
    "plt.figure()\n",
    "plt.semilogy(loss_hist['train'])\n",
    "plt.semilogy(loss_hist['test'])\n",
    "plt.legend(['train','test'])\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------checkpoint not restored--------\n",
      "\n",
      "\n",
      "Start first training... m=3364, f=25, a=2, b=100, db=10\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "try:\n",
    "    checkpoint = torch.load(PATH_v, map_location=device)\n",
    "    \n",
    "    encoder_v = Encoder(m,M1,f).to(device)\n",
    "    decoder_v = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    prune.custom_from_mask(decoder_v.full[2], name='weight', mask=torch.tensor(mask_2d).to(device))    \n",
    "       \n",
    "    optimizer = torch.optim.Adam(list(encoder_v.parameters()) + list(decoder_v.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    encoder_v.load_state_dict(checkpoint['encoder_v_state_dict'])\n",
    "    decoder_v.load_state_dict(checkpoint['decoder_v_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    last_epoch = checkpoint['epoch']\n",
    "    loss_hist = checkpoint['loss_hist']\n",
    "    best_loss = checkpoint['best_loss']\n",
    "    early_stop_counter = checkpoint['early_stop_counter']\n",
    "    best_encoder_v_wts = checkpoint['best_encoder_v_wts']\n",
    "    best_decoder_v_wts = checkpoint['best_decoder_v_wts']\n",
    "    \n",
    "    print(\"\\n--------checkpoint restored--------\\n\")\n",
    "    \n",
    "    # resume training\n",
    "    print(\"\")\n",
    "    print('Re-start {}th training... m={}, f={}, a={}, b={}, db={}'.format(\n",
    "        last_epoch+1, m, f, a, b, db))\n",
    "except:\n",
    "    encoder_v = Encoder(m,M1,f).to(device)\n",
    "    decoder_v = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    prune.custom_from_mask(decoder_v.full[2], name='weight', mask=torch.tensor(mask_2d).to(device))\n",
    "\n",
    "    optimizer = torch.optim.Adam(list(encoder_v.parameters()) + list(decoder_v.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    last_epoch = 0\n",
    "    loss_hist = {'train':[],'test':[]}\n",
    "    best_loss = float(\"inf\")\n",
    "    early_stop_counter = 1\n",
    "    best_encoder_v_wts = copy.deepcopy(encoder_v.state_dict())\n",
    "    best_decoder_v_wts = copy.deepcopy(decoder_v.state_dict())\n",
    "    \n",
    "    print(\"\\n--------checkpoint not restored--------\\n\")\n",
    "\n",
    "    # start training\n",
    "    print(\"\")\n",
    "    print('Start first training... m={}, f={}, a={}, b={}, db={}'.format(\n",
    "        m, f, a, b, db))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 3.358902268734045e-06\n",
      "test MSELoss: 3.3254027130169563e-06\n",
      "\n",
      "Epoch 200/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 2.070881324339027e-06\n",
      "test MSELoss: 2.0533965653157792e-06\n",
      "\n",
      "Epoch 300/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 1.1634411116874059e-06\n",
      "test MSELoss: 1.1609079137997469e-06\n",
      "\n",
      "Epoch 400/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 6.482635511997395e-07\n",
      "test MSELoss: 6.48438924599759e-07\n",
      "\n",
      "Epoch 500/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 4.41277269213314e-07\n",
      "test MSELoss: 4.4238224745640763e-07\n",
      "\n",
      "Epoch 600/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 4.063415684443106e-07\n",
      "test MSELoss: 4.0792417053125975e-07\n",
      "\n",
      "Epoch 700/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 3.6019666817070117e-07\n",
      "test MSELoss: 3.6066006714463583e-07\n",
      "\n",
      "Epoch 800/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 3.107736391510905e-07\n",
      "test MSELoss: 3.0830120749669733e-07\n",
      "\n",
      "Epoch 900/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.6198105327419063e-07\n",
      "test MSELoss: 2.6516383400121413e-07\n",
      "\n",
      "Epoch 1000/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.2316804631659536e-07\n",
      "test MSELoss: 2.2481402766061366e-07\n",
      "\n",
      "Epoch 1100/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.9254364681078499e-07\n",
      "test MSELoss: 1.9294960509341764e-07\n",
      "\n",
      "Epoch 1200/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.677238299887178e-07\n",
      "test MSELoss: 1.693078928610703e-07\n",
      "\n",
      "Epoch 1300/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.4924940468441143e-07\n",
      "test MSELoss: 1.5128345580706083e-07\n",
      "\n",
      "Epoch 1400/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.330137218785043e-07\n",
      "test MSELoss: 1.34988701461225e-07\n",
      "\n",
      "Epoch 1500/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.2214416911213492e-07\n",
      "test MSELoss: 1.2530345259165187e-07\n",
      "\n",
      "Epoch 1600/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.1053049699454758e-07\n",
      "test MSELoss: 1.116319737093363e-07\n",
      "\n",
      "Epoch 1700/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.0176443260795607e-07\n",
      "test MSELoss: 1.0356915112197384e-07\n",
      "\n",
      "Epoch 1800/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 9.499783371789995e-08\n",
      "test MSELoss: 9.650051140397408e-08\n",
      "\n",
      "Epoch 1900/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 9.409862675980807e-08\n",
      "test MSELoss: 9.553654933824873e-08\n",
      "\n",
      "Epoch 2000/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 9.310286031526303e-08\n",
      "test MSELoss: 9.466585879636113e-08\n",
      "\n",
      "Epoch 2100/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 9.221437410065155e-08\n",
      "test MSELoss: 9.369312721219103e-08\n",
      "\n",
      "Epoch 2200/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 9.10856935792897e-08\n",
      "test MSELoss: 9.270335254996098e-08\n",
      "\n",
      "Epoch 2300/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 9.010341364084194e-08\n",
      "test MSELoss: 9.152628450692646e-08\n",
      "\n",
      "Epoch 2400/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 8.916664025149473e-08\n",
      "test MSELoss: 9.054684539933077e-08\n",
      "\n",
      "Epoch 2500/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 8.812333076663333e-08\n",
      "test MSELoss: 8.958713948459263e-08\n",
      "\n",
      "Epoch 2600/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 8.718775497576674e-08\n",
      "test MSELoss: 8.855482036551621e-08\n",
      "\n",
      "Epoch 2700/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 8.631017927371775e-08\n",
      "test MSELoss: 8.77981321423249e-08\n",
      "\n",
      "Epoch 2800/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 8.532345339942255e-08\n",
      "test MSELoss: 8.676067579926894e-08\n",
      "\n",
      "Epoch 2900/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 8.453570664007874e-08\n",
      "test MSELoss: 8.595871321404047e-08\n",
      "\n",
      "Epoch 3000/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 8.360014879948867e-08\n",
      "test MSELoss: 8.501834543039877e-08\n",
      "\n",
      "Epoch 3100/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 8.274253395744626e-08\n",
      "test MSELoss: 8.431557887433883e-08\n",
      "\n",
      "Epoch 3200/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 8.202034093999277e-08\n",
      "test MSELoss: 8.344894553147242e-08\n",
      "\n",
      "Epoch 3300/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 8.117308838813575e-08\n",
      "test MSELoss: 8.2547683177836e-08\n",
      "\n",
      "Epoch 3400/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 8.029825772673192e-08\n",
      "test MSELoss: 8.170831193865524e-08\n",
      "\n",
      "Epoch 3500/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 7.949406869291961e-08\n",
      "test MSELoss: 8.095585997125454e-08\n",
      "\n",
      "Epoch 3600/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 7.88041494732134e-08\n",
      "test MSELoss: 8.019880226584064e-08\n",
      "\n",
      "Epoch 3700/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 7.809661005591242e-08\n",
      "test MSELoss: 7.935018118132575e-08\n",
      "\n",
      "Epoch 3800/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 7.724534436289134e-08\n",
      "test MSELoss: 7.869369227364586e-08\n",
      "\n",
      "Epoch 3900/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 7.663996233595874e-08\n",
      "test MSELoss: 7.800548473824165e-08\n",
      "\n",
      "Epoch 4000/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 7.586736609385673e-08\n",
      "test MSELoss: 7.726384865236469e-08\n",
      "\n",
      "Epoch 4100/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 7.512531934478292e-08\n",
      "test MSELoss: 7.659397454062855e-08\n",
      "\n",
      "Epoch 4200/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 7.445240390186614e-08\n",
      "test MSELoss: 7.590500104015518e-08\n",
      "\n",
      "Epoch 4300/10000, Learning rate 1.0000000000000002e-07\n",
      "----------\n",
      "train MSELoss: 7.362077644247829e-08\n",
      "test MSELoss: 7.50737740418117e-08\n",
      "\n",
      "Epoch 4400/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 7.358642732348544e-08\n",
      "test MSELoss: 7.504624619514288e-08\n",
      "\n",
      "Epoch 4487/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 7.358169235294822e-08\n",
      "test MSELoss: 7.504222310217301e-08\n",
      "\n",
      "Early stopping: 4487th training complete in 2h 25m 27s\n",
      "----------\n",
      "Best train MSELoss: 7.361013842910324e-08\n",
      "Best test MSELoss: 7.50477923361359e-08\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "since = time.time()\n",
    "\n",
    "for epoch in range(last_epoch+1,num_epochs+1):   \n",
    "\n",
    "    if epoch%num_epochs_print == 0:\n",
    "        print()\n",
    "        print('Epoch {}/{}, Learning rate {}'.format(\n",
    "            epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "        print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and test phase\n",
    "    for phase in ['train', 'test']:\n",
    "        if phase == 'train':\n",
    "            encoder_v.train()  # Set model to training mode\n",
    "            decoder_v.train()  # Set model to training mode\n",
    "        else:\n",
    "            encoder_v.eval()   # Set model to evaluation mode\n",
    "            decoder_v.eval()   # Set model to evaluation mode\n",
    "            \n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Iterate over data\n",
    "        for data, in data_loaders_v[phase]:\n",
    "            inputs = data.to(device)\n",
    "            targets = data.to(device)\n",
    "\n",
    "            if phase == 'train':\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = decoder_v(encoder_v(inputs))\n",
    "                loss = loss_func(outputs, targets)\n",
    "\n",
    "                # backward\n",
    "                loss.backward()\n",
    "\n",
    "                # optimize\n",
    "                optimizer.step()  \n",
    "\n",
    "                # add running loss\n",
    "                running_loss += loss.item()*inputs.shape[0]\n",
    "            else:\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    outputs = decoder_v(encoder_v(inputs))\n",
    "                    running_loss += loss_func(outputs,targets).item()*inputs.shape[0]\n",
    "\n",
    "        # compute epoch loss\n",
    "        epoch_loss = running_loss / dataset_v_shapes[phase][0]\n",
    "        loss_hist[phase].append(epoch_loss)\n",
    "            \n",
    "        # update learning rate\n",
    "        if phase == 'train':\n",
    "            scheduler.step(epoch_loss)\n",
    "\n",
    "        if epoch%num_epochs_print == 0:\n",
    "            print('{} MSELoss: {}'.format(\n",
    "                phase, epoch_loss))\n",
    "\n",
    "    # deep copy the model\n",
    "    if round(loss_hist['test'][-1],10) < round(best_loss,10):\n",
    "        best_loss = loss_hist['test'][-1]\n",
    "        early_stop_counter = 1\n",
    "        best_encoder_v_wts = copy.deepcopy(encoder_v.state_dict())\n",
    "        best_decoder_v_wts = copy.deepcopy(decoder_v.state_dict())\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= early_stop_patience:  \n",
    "            break\n",
    "    \n",
    "    # save checkpoint every num_epoch_print\n",
    "    if epoch%num_epochs_print== 0:\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'encoder_v_state_dict': encoder_v.state_dict(),\n",
    "                    'decoder_v_state_dict': decoder_v.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss_hist': loss_hist,\n",
    "                    'best_loss': best_loss,\n",
    "                    'early_stop_counter': early_stop_counter,\n",
    "                    'best_encoder_v_wts': best_encoder_v_wts,\n",
    "                    'best_decoder_v_wts': best_decoder_v_wts,\n",
    "                    }, PATH_v)        \n",
    "\n",
    "print()\n",
    "print('Epoch {}/{}, Learning rate {}'\\\n",
    "      .format(epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "print('-' * 10)\n",
    "print('train MSELoss: {}'.format(loss_hist['train'][-1]))\n",
    "print('test MSELoss: {}'.format(loss_hist['test'][-1]))\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "\n",
    "# load best model weights\n",
    "encoder_v.load_state_dict(best_encoder_v_wts)\n",
    "decoder_v.load_state_dict(best_decoder_v_wts)\n",
    "\n",
    "# compute best train MSELoss\n",
    "encoder_v.to('cpu').eval()\n",
    "decoder_v.to('cpu').eval()\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    train_inputs = torch.tensor(data_v[train_ind])\n",
    "    train_targets = torch.tensor(data_v[train_ind])\n",
    "    train_outputs = decoder_v(encoder_v(train_inputs))\n",
    "    train_loss = loss_func(train_outputs,train_targets).item()\n",
    "\n",
    "# print out training time and best results\n",
    "print()\n",
    "if epoch < num_epochs:\n",
    "    print('Early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "else:\n",
    "    print('No early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "print('-' * 10)\n",
    "print('Best train MSELoss: {}'.format(train_loss))\n",
    "print('Best test MSELoss: {}'.format(best_loss))\n",
    "\n",
    "# # save models\n",
    "# print()\n",
    "# print(\"Saving after {}th training to\".format(epoch),file_name_AE_v)\n",
    "# torch.save((encoder_v,decoder_v),file_name_AE_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "checkpoint removed\n"
     ]
    }
   ],
   "source": [
    "# delete checkpoint\n",
    "try:\n",
    "    os.remove(PATH_v)\n",
    "    print()\n",
    "    print(\"checkpoint removed\")\n",
    "except:\n",
    "    print(\"no checkpoint exists\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and test loss\n",
    "plt.figure()\n",
    "plt.semilogy(loss_hist['train'])\n",
    "plt.semilogy(loss_hist['test'])\n",
    "plt.legend(['train','test'])\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load models\n",
    "# try:\n",
    "#     encoder_u,decoder_u = torch.load(file_name_AE_u,map_location='cpu')\n",
    "#     encoder_v,decoder_v = torch.load(file_name_AE_v,map_location='cpu')\n",
    "#     print(\"\\n--------model restored--------\\n\")\n",
    "# except:\n",
    "#     print(\"\\n--------model not restored--------\\n\")\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights and bias\n",
    "en_wu1_s=encoder_u.full[0].weight.detach().numpy().astype('float32')\n",
    "en_bu1=encoder_u.full[0].bias.detach().numpy().astype('float32')\n",
    "en_wu2=encoder_u.full[2].weight.detach().numpy().astype('float32')\n",
    "\n",
    "en_wv1_s=encoder_v.full[0].weight.detach().numpy().astype('float32')\n",
    "en_bv1=encoder_v.full[0].bias.detach().numpy().astype('float32')\n",
    "en_wv2=encoder_v.full[2].weight.detach().numpy().astype('float32')\n",
    "\n",
    "de_wu1=decoder_u.full[0].weight.detach().numpy().astype('float32')\n",
    "de_bu1=decoder_u.full[0].bias.detach().numpy().astype('float32')\n",
    "de_wu2_s=decoder_u.full[2].weight.detach().numpy().astype('float32')\n",
    "\n",
    "de_wv1=decoder_v.full[0].weight.detach().numpy().astype('float32')\n",
    "de_bv1=decoder_v.full[0].bias.detach().numpy().astype('float32')\n",
    "de_wv2_s=decoder_v.full[2].weight.detach().numpy().astype('float32')\n",
    "\n",
    "de_wu2_s_sp=sp.csr_matrix(de_wu2_s,dtype='float32')\n",
    "de_wv2_s_sp=sp.csr_matrix(de_wv2_s,dtype='float32')\n",
    "\n",
    "# rescale weights\n",
    "en_wu1=en_wu1_s*u_scale_reciprocal\n",
    "en_wv1=en_wv1_s*v_scale_reciprocal\n",
    "\n",
    "de_wu1T=de_wu1.T\n",
    "de_wv1T=de_wv1.T\n",
    "\n",
    "de_wu2T=u_scale*de_wu2_s.T\n",
    "de_wv2T=v_scale*de_wv2_s.T\n",
    "\n",
    "de_wu2=de_wu2T.T\n",
    "de_wv2=de_wv2T.T\n",
    "\n",
    "de_wu2_sp=sp.csr_matrix(de_wu2,dtype='float32')\n",
    "de_wv2_sp=sp.csr_matrix(de_wv2,dtype='float32')\n",
    "\n",
    "de_wu2T_sp=de_wu2_sp.T\n",
    "de_wv2T_sp=de_wv2_sp.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy version of AE\n",
    "def sigmoid_np(input):\n",
    "    return (1.0/(1.0+np.exp(-input))).astype('float32')\n",
    "\n",
    "def encoder_u_np_forward(x):\n",
    "    z1 = en_wu1.dot(x) + en_bu1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = en_wu2.dot(a1)   \n",
    "    return y\n",
    "\n",
    "def decoder_u_np_forward(x):\n",
    "    z1 = de_wu1.dot(x) + de_bu1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = de_wu2.dot(a1)  \n",
    "    return y\n",
    "\n",
    "def decoder_u_sp_forward(x):\n",
    "    z1 = de_wu1.dot(x) + de_bu1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = sp.csr_matrix.dot(de_wu2_sp,a1)\n",
    "    return y\n",
    "\n",
    "def encoder_v_np_forward(x):\n",
    "    z1 = en_wv1.dot(x) + en_bv1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = en_wv2.dot(a1)   \n",
    "    return y\n",
    "\n",
    "def decoder_v_np_forward(x):\n",
    "    z1 = de_wv1.dot(x) + de_bv1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = de_wv2.dot(a1)   \n",
    "    return y\n",
    "\n",
    "def decoder_v_sp_forward(x):\n",
    "    z1 = de_wv1.dot(x) + de_bv1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = sp.csr_matrix.dot(de_wv2_sp,a1)\n",
    "    return y\n",
    "\n",
    "def decoder_u_np_forward_backwardT(x):\n",
    "    z1 = de_wu1.dot(x) + de_bu1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = de_wu2.dot(a1)\n",
    "\n",
    "    dout = de_wu1T\n",
    "    dout = (a1*(1-a1))*dout\n",
    "    dydxT = dout.dot(de_wu2T)   \n",
    "    return y,dydxT\n",
    "\n",
    "def decoder_u_sp_forward_backwardT(x):\n",
    "    z1 = de_wu1.dot(x) + de_bu1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = sp.csr_matrix.dot(de_wu2_sp,a1)\n",
    "\n",
    "    dout = de_wu1T\n",
    "    dout = (a1*(1-a1))*dout\n",
    "    dydxT = sp.csr_matrix.dot(dout,de_wu2T_sp)\n",
    "    return y,dydxT\n",
    "\n",
    "def decoder_v_np_forward_backwardT(x):\n",
    "    z1 = de_wv1.dot(x) + de_bv1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = de_wv2.dot(a1)\n",
    "\n",
    "    dout = de_wv1T\n",
    "    dout = (a1*(1-a1))*dout\n",
    "    dydxT = dout.dot(de_wv2T)   \n",
    "    return y,dydxT\n",
    "\n",
    "def decoder_v_sp_forward_backwardT(x):\n",
    "    z1 = de_wv1.dot(x) + de_bv1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = sp.csr_matrix.dot(de_wv2_sp,a1)\n",
    "\n",
    "    dout = de_wv1T\n",
    "    dout = (a1*(1-a1))*dout\n",
    "    dydxT = sp.csr_matrix.dot(dout,de_wv2T_sp)\n",
    "    return y,dydxT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE u: 2.64197747e-08\n",
      "MSELoss of AE v: 2.43246392e-08\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss\n",
    "comp_orig_data_u=np.zeros((ndata,f))\n",
    "comp_orig_data_v=np.zeros((ndata,f))\n",
    "\n",
    "rest_orig_data_u=np.zeros(orig_data_u.shape)\n",
    "rest_orig_data_v=np.zeros(orig_data_u.shape)\n",
    "\n",
    "for k in range(ndata):\n",
    "    comp_orig_data_u[k]=encoder_u_np_forward(orig_data_u[k]-u_ref)\n",
    "    comp_orig_data_v[k]=encoder_v_np_forward(orig_data_v[k]-v_ref)\n",
    "    \n",
    "    rest_orig_data_u[k]=decoder_u_sp_forward(comp_orig_data_u[k]) + u_ref\n",
    "    rest_orig_data_v[k]=decoder_v_sp_forward(comp_orig_data_v[k]) + v_ref\n",
    "    \n",
    "print(\"MSELoss of AE u: {:.8e}\".format(np.linalg.norm(orig_data_u-rest_orig_data_u)**2/np.prod(orig_data_u.shape)))\n",
    "print(\"MSELoss of AE v: {:.8e}\".format(np.linalg.norm(orig_data_v-rest_orig_data_v)**2/np.prod(orig_data_v.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale AE\n",
    "en_weight_u_s=encoder_u.full[0].weight.data\n",
    "en_weight_u=en_weight_u_s*torch.tensor(u_scale_reciprocal)\n",
    "encoder_u.full[0].weight=nn.Parameter(en_weight_u)\n",
    "\n",
    "de_weight_u_s=decoder_u.full[2].weight.data\n",
    "de_weight_u=(torch.tensor(u_scale)*de_weight_u_s.T).T\n",
    "de_weight_u_mask=decoder_u.full[2].weight_mask.data\n",
    "prune.remove(decoder_u.full[2],'weight');\n",
    "decoder_u.full[2].weight=nn.Parameter(de_weight_u)\n",
    "prune.custom_from_mask(decoder_u.full[2], name='weight', mask=de_weight_u_mask);\n",
    "\n",
    "en_weight_v_s=encoder_v.full[0].weight.data\n",
    "en_weight_v=en_weight_v_s*torch.tensor(v_scale_reciprocal)\n",
    "encoder_v.full[0].weight=nn.Parameter(en_weight_v)\n",
    "\n",
    "de_weight_v_s=decoder_v.full[2].weight.data\n",
    "de_weight_v=(torch.tensor(v_scale)*de_weight_v_s.T).T\n",
    "de_weight_v_mask=decoder_v.full[2].weight_mask.data\n",
    "prune.remove(decoder_v.full[2],'weight');\n",
    "decoder_v.full[2].weight=nn.Parameter(de_weight_v)\n",
    "prune.custom_from_mask(decoder_v.full[2], name='weight', mask=de_weight_v_mask);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE u: 2.64191122e-08\n",
      "MSELoss of AE v: 2.43239988e-08\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss\n",
    "input_u=torch.tensor(orig_data_u-u_ref)\n",
    "target_u=decoder_u(encoder_u(input_u))\n",
    "\n",
    "input_v=torch.tensor(orig_data_v-v_ref)\n",
    "target_v=decoder_v(encoder_v(input_v))\n",
    "\n",
    "print(\"MSELoss of AE u: {:.8e}\".format(torch.nn.functional.mse_loss(input_u,target_u).detach().item()))\n",
    "print(\"MSELoss of AE v: {:.8e}\".format(torch.nn.functional.mse_loss(input_v,target_v).detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE u (predictive case): 4.07231582e-08\n",
      "MSELoss of AE v (predictive case): 3.85410210e-08\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (predictive case)\n",
    "if Re==10000:\n",
    "    FOM_solution=pickle.load(open('./data/FOM_high_Re.p','rb'))\n",
    "elif Re==100:\n",
    "    FOM_solution=pickle.load(open('./data/FOM_loq_Re.p','rb'))\n",
    "else:\n",
    "    raise NameError('{} is given for Re, but it must be either 100 or 10000'.format(Re))\n",
    "    \n",
    "u_full=FOM_solution['u'].astype('float32')\n",
    "v_full=FOM_solution['v'].astype('float32')\n",
    "\n",
    "orig_data_u_FOM = u_full[:,free_raveled_indicies]\n",
    "orig_data_v_FOM = v_full[:,free_raveled_indicies]\n",
    "\n",
    "input_u_FOM=torch.tensor(orig_data_u_FOM-u_ref)\n",
    "target_u_FOM=decoder_u(encoder_u(input_u_FOM))\n",
    "\n",
    "input_v_FOM=torch.tensor(orig_data_v_FOM-v_ref)\n",
    "target_v_FOM=decoder_v(encoder_v(input_v_FOM))\n",
    "\n",
    "print(\"MSELoss of AE u (predictive case): {:.8e}\"\\\n",
    "      .format(torch.nn.functional.mse_loss(input_u_FOM,target_u_FOM).detach().item()))\n",
    "print(\"MSELoss of AE v (predictive case): {:.8e}\"\\\n",
    "      .format(torch.nn.functional.mse_loss(input_v_FOM,target_v_FOM).detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # generate mesh grid\n",
    "# [xv,yv]=np.meshgrid(np.linspace(0,1,nx),np.linspace(0,1,ny),indexing='xy')\n",
    "# x=xv.flatten()\n",
    "# y=yv.flatten()\n",
    "\n",
    "# x_free=x[free_raveled_indicies]\n",
    "# y_free=y[free_raveled_indicies]\n",
    "\n",
    "# k=-1\n",
    "\n",
    "# # plot origianl data\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_u[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_u[k].reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Original $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_v[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_v[k].reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Original $v$')\n",
    "# plt.show()\n",
    "\n",
    "# # plot compressed data\n",
    "# plt.figure()\n",
    "# plt.plot(comp_orig_data_u[k])\n",
    "# plt.title('Compressed $u$')\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(comp_orig_data_v[k])\n",
    "# plt.title('Compressed $v$')\n",
    "# plt.show()\n",
    "\n",
    "# # plot restored data\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_orig_data_u[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_orig_data_u[k].reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Restored $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_orig_data_v[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_orig_data_v[k].reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Restored $v$')\n",
    "# plt.show()\n",
    "\n",
    "# # plot relative error\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), (orig_data_u[k]-rest_orig_data_u[k]).reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), (orig_data_u[k]-rest_orig_data_u[k]).reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Difference $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), (orig_data_v[k]-rest_orig_data_v[k]).reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), (orig_data_v[k]-rest_orig_data_v[k]).reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Difference $v$')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights and references   \n",
    "AE={'en_wu1':en_wu1,'en_bu1':en_bu1,'en_wu2':en_wu2,\n",
    "    'de_wu1':de_wu1,'de_bu1':de_bu1,'de_wu2':de_wu2,\n",
    "    'de_wu1T':de_wu1T,'de_wu2T':de_wu2T,'de_wu2_sp':de_wu2_sp,'de_wu2T_sp':de_wu2T_sp,'u_ref':u_ref,\n",
    "    'en_wv1':en_wv1,'en_bv1':en_bv1,'en_wv2':en_wv2,\n",
    "    'de_wv1':de_wv1,'de_bv1':de_bv1,'de_wv2':de_wv2,\n",
    "    'de_wv1T':de_wv1T,'de_wv2T':de_wv2T,'de_wv2_sp':de_wv2_sp,'de_wv2T_sp':de_wv2T_sp,'v_ref':v_ref}\n",
    "\n",
    "pickle.dump(AE,open(file_name_AE,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
