{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.prune as prune\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "from scipy import sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import sys,time\n",
    "import os\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "redDim=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set print option\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "# Choose device that is not being used\n",
    "gpu_ids = \"2\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=gpu_ids\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given parameters\n",
    "nx = 60\n",
    "ny = 60\n",
    "m = (ny-2)*(nx-2) # 3364\n",
    "nt = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose either Re=10000 or Re=100\n",
    "Re = 10000 \n",
    "    \n",
    "# Choose data normalize option (option 1: -1<=X<=1 option 2: 0<=X<=1)\n",
    "option = 2\n",
    "\n",
    "# Choose activation function (sigmoid, swish)\n",
    "activation = 'sigmoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set batch_size, number of epochs, paitience for early stop\n",
    "batch_size = 480\n",
    "num_epochs = 10000\n",
    "num_epochs_print = num_epochs//100\n",
    "early_stop_patience = num_epochs//50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_mask(m,b,db):\n",
    "    \n",
    "#     M2 = b + db*(m-1)\n",
    "#     mask = np.zeros((m,M2),dtype='int8')\n",
    "    \n",
    "#     block = np.ones(b,dtype='int8')\n",
    "#     ind = np.arange(b)\n",
    "#     for row in range(m):\n",
    "#         col = ind + row*db\n",
    "#         mask[row,col] = block      \n",
    "\n",
    "# #     for row in range(nx-2,m):\n",
    "# #         col = ind + (row-1)*db\n",
    "# #         mask[row-(nx-2),col] = block    \n",
    "# #     for row in range(0,m-(nx-2)):\n",
    "# #         col = ind + (row+1)*db\n",
    "# #         mask[row+(nx-2),col] = block\n",
    "                   \n",
    "#     print(\n",
    "#         \"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "#             m, M2, (1.0-np.count_nonzero(mask)/mask.size)*100\n",
    "#         )\n",
    "#     )\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.spy(mask)\n",
    "#     plt.show()\n",
    "\n",
    "#     return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_2d(m,b,db):\n",
    "    \n",
    "    # local\n",
    "    Mb=sp.diags([np.ones(nx-2),np.ones(nx-2),np.ones(nx-2)],[0,-1,1],(nx-2,nx-2))\n",
    "    M=sp.kron(sp.eye(ny-2),Mb,format=\"csr\")\n",
    "\n",
    "    Ib=sp.eye(nx-2)\n",
    "    N=sp.kron(sp.diags([np.ones(ny-2),np.ones(ny-2),np.ones(ny-2)],[0,-1,1],(ny-2,ny-2)),Ib,format=\"csr\")\n",
    "\n",
    "    local=(M+N).astype('int8')\n",
    "    I,J,V=sp.find(local)\n",
    "    local[I,J]=1\n",
    "    \n",
    "#     col_ind=np.array([],dtype='int')\n",
    "#     row_ind=np.array([],dtype='int')\n",
    "\n",
    "#     for lin_ind in range(m):\n",
    "#         j,i=np.unravel_index(lin_ind,(ny-2,nx-2))\n",
    "\n",
    "#         E=np.ravel_multi_index((j,np.max((i-1,0))),(ny-2,nx-2))\n",
    "#         W=np.ravel_multi_index((j,np.min((i+1,nx-2-1))),(ny-2,nx-2))\n",
    "#         S=np.ravel_multi_index((np.max((j-1,0)),i),(ny-2,nx-2))\n",
    "#         N=np.ravel_multi_index((np.min((j+1,ny-2-1)),i),(ny-2,nx-2))\n",
    "\n",
    "#         col=np.unique([lin_ind,E,W,S,N])\n",
    "#         row=lin_ind*np.ones(col.size,dtype='int')\n",
    "\n",
    "#         col_ind=np.append(col_ind,col)\n",
    "#         row_ind=np.append(row_ind,row)\n",
    "\n",
    "#     data=np.ones(row_ind.size,dtype='int')\n",
    "#     local2=sp.csr_matrix((data,(row_ind,col_ind)),shape=(m,m))\n",
    "\n",
    "    # basis\n",
    "    M2 = int(b + db*(m-1))\n",
    "    basis = np.zeros((m,M2),dtype='int8')\n",
    "\n",
    "    block = np.ones(b,dtype='int8')\n",
    "    ind = np.arange(b)\n",
    "    for row in range(m):\n",
    "        col = ind + row*db\n",
    "        basis[row,col] = block\n",
    "    \n",
    "    # mask\n",
    "    col_ind=np.array([],dtype='int8')\n",
    "    row_ind=np.array([],dtype='int8')\n",
    "    for i in range(m):\n",
    "        col=basis[sp.find(local[i])[1]].sum(axis=0).nonzero()[0]\n",
    "        row=i*np.ones(col.size)\n",
    "\n",
    "        col_ind=np.append(col_ind,col)\n",
    "        row_ind=np.append(row_ind,row)\n",
    "\n",
    "    data=np.ones(row_ind.size,dtype='int8')\n",
    "    mask=sp.csr_matrix((data,(row_ind,col_ind)),shape=(m,M2)).toarray()\n",
    "    \n",
    "    print(\n",
    "        \"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "            m, M2, (1.0-np.count_nonzero(mask)/np.prod(mask.shape))*100\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.spy(mask)\n",
    "    plt.show()\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if activation=='sigmoid':\n",
    "    class Encoder(nn.Module):\n",
    "        def __init__(self,m,M1,f):\n",
    "            super(Encoder,self).__init__()\n",
    "            self.full = nn.Sequential(\n",
    "                nn.Linear(m,M1),\n",
    "                nn.Sigmoid(),\n",
    "                nn.Linear(M1,f,bias=False)\n",
    "            )\n",
    "\n",
    "        def forward(self, y):     \n",
    "            y = y.view(-1,m)\n",
    "            T = self.full(y)\n",
    "            T = T.squeeze()\n",
    "\n",
    "            return T\n",
    "\n",
    "    class Decoder(nn.Module):\n",
    "        def __init__(self,f,M2,m):\n",
    "            super(Decoder,self).__init__()\n",
    "            self.full = nn.Sequential(\n",
    "                nn.Linear(f,M2),\n",
    "                nn.Sigmoid(),\n",
    "                nn.Linear(M2,m,bias=False)\n",
    "            )\n",
    "\n",
    "        def forward(self,T):\n",
    "            T = T.view(-1,f)\n",
    "            y = self.full(T)\n",
    "            y = y.squeeze()\n",
    "\n",
    "            return y\n",
    "        \n",
    "elif activation=='swish':\n",
    "    def silu(input):\n",
    "        return input * torch.sigmoid(input)\n",
    "\n",
    "    class SiLU(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "        def forward(self, input):\n",
    "            return silu(input)\n",
    "        \n",
    "    class Encoder(nn.Module):\n",
    "        def __init__(self,m,M1,f):\n",
    "            super(Encoder,self).__init__()\n",
    "            self.full = nn.Sequential(\n",
    "                nn.Linear(m,M1),\n",
    "                SiLU(),\n",
    "                nn.Linear(M1,f,bias=False)\n",
    "            )\n",
    "\n",
    "        def forward(self, y):     \n",
    "            y = y.view(-1,m)\n",
    "            T = self.full(y)\n",
    "            T = T.squeeze()\n",
    "\n",
    "            return T\n",
    "\n",
    "    class Decoder(nn.Module):\n",
    "        def __init__(self,f,M2,m):\n",
    "            super(Decoder,self).__init__()\n",
    "            self.full = nn.Sequential(\n",
    "                nn.Linear(f,M2),\n",
    "                SiLU(),\n",
    "                nn.Linear(M2,m,bias=False)\n",
    "            )\n",
    "\n",
    "        def forward(self,T):\n",
    "            T = T.view(-1,f)\n",
    "            y = self.full(T)\n",
    "            y = y.squeeze()\n",
    "\n",
    "            return y\n",
    "else:\n",
    "    raise NameError('{} is given for option, but it must be either sigmoid or swish'.format(activation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "option 2: 0<=X<=1\n",
      "data shape\n",
      "(6004, 3364)\n",
      "(6004, 3364)\n",
      "maximum abs difference\n",
      "1.1920929e-07\n",
      "1.1920929e-07\n"
     ]
    }
   ],
   "source": [
    "# load snapshot\n",
    "if Re==10000:\n",
    "    file_name_snapshot=\"./data/snapshot_full_high_Re.p\"\n",
    "elif Re==100:\n",
    "    file_name_snapshot=\"./data/snapshot_full_low_Re.p\"\n",
    "else:\n",
    "    raise NameError('{} is given for Re, but it must be either 100 or 10000'.format(Re)) \n",
    "\n",
    "snapshot = pickle.load(open(file_name_snapshot,'rb'))\n",
    "snapshot_u = snapshot['u'].astype('float32')\n",
    "snapshot_v = snapshot['v'].astype('float32')\n",
    "\n",
    "# number of data points\n",
    "ndata = snapshot_u.shape[0]\n",
    "\n",
    "# remove BC\n",
    "multi_index_i,multi_index_j=np.meshgrid(np.arange(nx),np.arange(ny),indexing='xy')\n",
    "full_multi_index=(multi_index_j.flatten(),multi_index_i.flatten())\n",
    "free_multi_index=(multi_index_j[1:-1,1:-1].flatten(),multi_index_i[1:-1,1:-1].flatten())\n",
    "\n",
    "dims=(ny,nx)\n",
    "full_raveled_indicies=np.ravel_multi_index(full_multi_index,dims)\n",
    "free_raveled_indicies=np.ravel_multi_index(free_multi_index,dims)\n",
    "\n",
    "orig_data_u = snapshot_u[:,free_raveled_indicies]\n",
    "orig_data_v = snapshot_v[:,free_raveled_indicies]\n",
    "\n",
    "# normalize data\n",
    "if option==1: # option 1: -1<=X<=1\n",
    "    print(\"option {}: -1<=X<=1\".format(option))\n",
    "#     u_ref = np.mean(orig_data_u,axis=0)\n",
    "#     v_ref = np.mean(orig_data_v,axis=0)   \n",
    "\n",
    "#     u_scale = np.max(orig_data_u,axis=0)-np.min(orig_data_u,axis=0)\n",
    "#     v_scale = np.max(orig_data_v,axis=0)-np.min(orig_data_v,axis=0)   \n",
    "    u_ref = (np.max(orig_data_u,axis=0)+np.min(orig_data_u,axis=0))/2.0\n",
    "    v_ref = (np.max(orig_data_v,axis=0)+np.min(orig_data_v,axis=0))/2.0\n",
    "    \n",
    "    u_scale = (np.max(orig_data_u,axis=0)-np.min(orig_data_u,axis=0))/2.0\n",
    "    v_scale = (np.max(orig_data_v,axis=0)-np.min(orig_data_v,axis=0))/2.0\n",
    "    \n",
    "    u_scale = np.where(u_scale > np.finfo('float32').resolution, u_scale, 1)\n",
    "    v_scale = np.where(v_scale > np.finfo('float32').resolution, v_scale, 1)\n",
    "    \n",
    "    u_scale_reciprocal = np.reciprocal(u_scale)\n",
    "    v_scale_reciprocal = np.reciprocal(v_scale)\n",
    "    \n",
    "    data_u = u_scale_reciprocal*(orig_data_u-u_ref)\n",
    "    data_v = v_scale_reciprocal*(orig_data_v-v_ref)\n",
    "    \n",
    "elif option==2: # option 2: 0<=X<=1\n",
    "    print(\"option {}: 0<=X<=1\".format(option))\n",
    "    u_ref = np.min(orig_data_u,axis=0)\n",
    "    v_ref = np.min(orig_data_v,axis=0)\n",
    "    \n",
    "    u_scale = np.max(orig_data_u,axis=0)-np.min(orig_data_u,axis=0)\n",
    "    v_scale = np.max(orig_data_v,axis=0)-np.min(orig_data_v,axis=0)\n",
    "    \n",
    "    u_scale = np.where(u_scale > np.finfo('float32').resolution, u_scale, 1)\n",
    "    v_scale = np.where(v_scale > np.finfo('float32').resolution, v_scale, 1)\n",
    "    \n",
    "    u_scale_reciprocal = np.reciprocal(u_scale)\n",
    "    v_scale_reciprocal = np.reciprocal(v_scale)\n",
    "    \n",
    "    data_u = u_scale_reciprocal*(orig_data_u-u_ref)\n",
    "    data_v = v_scale_reciprocal*(orig_data_v-v_ref)\n",
    "else:\n",
    "    raise NameError('{} is given for option, but it must be either 1 or 2'.format(option))\n",
    "\n",
    "# check shapes of snapshot\n",
    "print('data shape')\n",
    "print(data_u.shape)\n",
    "print(data_v.shape)\n",
    "\n",
    "# restore data\n",
    "rest_data_u = u_ref + u_scale*data_u\n",
    "rest_data_v = v_ref + v_scale*data_v\n",
    "\n",
    "# check precision\n",
    "print('maximum abs difference')\n",
    "print(np.max(np.abs(orig_data_u-rest_data_u)))\n",
    "print(np.max(np.abs(orig_data_v-rest_data_v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # generate mesh grid\n",
    "# [xv,yv]=np.meshgrid(np.linspace(0,1,nx),np.linspace(0,1,ny),indexing='xy')\n",
    "# x=xv.flatten()\n",
    "# y=yv.flatten()\n",
    "\n",
    "# x_free=x[free_raveled_indicies]\n",
    "# y_free=y[free_raveled_indicies]\n",
    "\n",
    "# k=0\n",
    "\n",
    "# # plot original data\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_u[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_u[k].reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Original $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_v[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_v[k].reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Original $v$')\n",
    "# plt.show()\n",
    "\n",
    "# # plot preprocessed data\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), data_u[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), data_u[k].reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Preprocessed $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), data_v[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), data_v[k].reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Preprocessed $v$')\n",
    "# plt.show()\n",
    "\n",
    "# # plot restored data\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_data_u[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_data_u[k].reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Restored $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_data_v[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_data_v[k].reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Restored $v$')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5404, 3364]) torch.Size([600, 3364])\n",
      "torch.Size([5404, 3364]) torch.Size([600, 3364])\n"
     ]
    }
   ],
   "source": [
    "# define testset and trainset indices\n",
    "nset = round(ndata/(nt+1))\n",
    "test_ind = np.array([],dtype='int')\n",
    "for foo in range(nset):\n",
    "    rand_ind = np.random.permutation(np.arange(foo*(nt+1)+1,(foo+1)*(nt+1)))[:int(0.1*(nt+1))]\n",
    "    test_ind = np.append(test_ind,rand_ind)\n",
    "train_ind = np.setdiff1d(np.arange(ndata),test_ind)\n",
    "\n",
    "# set trainset and testset\n",
    "trainset_u = data_u[train_ind]\n",
    "trainset_v = data_v[train_ind]\n",
    "testset_u = data_u[test_ind] \n",
    "testset_v = data_v[test_ind] \n",
    "\n",
    "# set dataset\n",
    "dataset_u = {'train':data_utils.TensorDataset(torch.tensor(trainset_u,dtype=torch.float32)),\n",
    "           'test':data_utils.TensorDataset(torch.tensor(testset_u,dtype=torch.float32))}\n",
    "dataset_v = {'train':data_utils.TensorDataset(torch.tensor(trainset_v,dtype=torch.float32)),\n",
    "           'test':data_utils.TensorDataset(torch.tensor(testset_v,dtype=torch.float32))}\n",
    "\n",
    "print(dataset_u['train'].tensors[0].shape, dataset_u['test'].tensors[0].shape)\n",
    "print(dataset_v['train'].tensors[0].shape, dataset_v['test'].tensors[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5404, 3364) (600, 3364)\n",
      "(5404, 3364) (600, 3364)\n"
     ]
    }
   ],
   "source": [
    "# compute dataset shapes\n",
    "dataset_u_shapes = {'train':trainset_u.shape,\n",
    "                    'test':testset_u.shape}\n",
    "dataset_v_shapes = {'train':trainset_v.shape,\n",
    "                    'test':testset_v.shape}\n",
    "\n",
    "print(dataset_u_shapes['train'],dataset_u_shapes['test'])\n",
    "print(dataset_v_shapes['train'],dataset_v_shapes['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data loaders\n",
    "train_loader_u = DataLoader(dataset=dataset_u['train'], \n",
    "                          batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "train_loader_v = DataLoader(dataset=dataset_v['train'], \n",
    "                          batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader_u = DataLoader(dataset=dataset_u['test'], \n",
    "                         batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader_v = DataLoader(dataset=dataset_v['test'], \n",
    "                         batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "data_loaders_u = {'train':train_loader_u, 'test':test_loader_u}\n",
    "data_loaders_v = {'train':train_loader_v, 'test':test_loader_v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in 3364 by 33730 mask: 99.06%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAABECAYAAABte+WAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAALRklEQVR4nO3db4xcVRnH8e/PAgUF+VtI0xaBUomlKaXd1CKCIih/fAEYwJYgGCUYBYQXvmiDIqK80AhGQBEUIoLKn6DCCxErikhigC0U2korRQtWKi0iUJUghccX5yw7TGdm73Z3Zu6d+X2Szdw9e6dznt7MOTPnOfccRQRmZtYf3tbtCpiZWee40Tcz6yNu9M3M+ogbfTOzPuJG38ysj7jRNzPrI6Vt9CUdJ2mNpLWSFne7PvUkrZO0QtJySYO5bA9JSyU9mR93rzl/SY5ljaRja8rn5X9nraQrJanN9b5B0kZJK2vKxq3ekiZKujWXPyhpvw7GcYmkv+drslzSCWWOQ9I0Sb+T9ISkVZIuyOWVuh4t4qjM9ZC0o6SHJD2WY/hKLq/UtSgkIkr3A0wAngIOAHYAHgNmdrtedXVcB+xVV/YNYHE+Xgx8PR/PzDFMBPbPsU3If3sIOAwQcDdwfJvrfSQwF1jZjnoDnwO+l48XArd2MI5LgC80OLeUcQCTgbn5eBfgz7mulboeLeKozPXIr7dzPt4eeBBYULVrUSjWbrxogQtwGHBPze9LgCXdrlddHdexdaO/BpicjycDaxrVH7gnxzgZWF1Tvgi4tgN134+3NpbjVu+hc/LxdsDzgDoUR7NGptRx1Lz+ncCHq3o9GsRRyesBvB14BHhv1a9Fo5+yDu9MAf5W8/v6XFYmAfxa0jJJ5+SyfSJiA0B+3DuXN4tnSj6uL++08az3m8+JiC3AS8Cebav51s6T9Hge/hn6Kl76OPJX/UNJnzArez3q4oAKXQ9JEyQtBzYCSyOi0teimbI2+o3Gtcu2XsThETEXOB44V9KRLc5tFk/Z49yWenczpmuA6cAcYANw+Qh1KkUcknYG7gAujIiXW53apE5ljaNS1yMiXo+IOcBUYL6kWS1OL2UMRZS10V8PTKv5fSrwbJfq0lBEPJsfNwI/B+YDz0maDJAfN+bTm8WzPh/Xl3faeNb7zedI2g7YFXihbTWvERHP5TfuG8D3SdfkLXWqq2/X45C0Pamh/HFE/CwXV+56NIqjitcj1/tF4D7gOCp4LUZS1kb/YWCGpP0l7UBKetzV5Tq9SdI7JO0ydAx8BFhJquNZ+bSzSGOb5PKFOXu/PzADeCh/XdwsaUHO8J9Z85xOGs961/5bpwC/jTyI2W5Db87sZNI1GapT6eLIr3k98EREXFHzp0pdj2ZxVOl6SJokabd8vBNwDLCail2LQjqdRBhFMuUE0iyAp4CLul2furodQMrcPwasGqofaXzuXuDJ/LhHzXMuyrGsoWaGDjBAejM8BVxN+5NsPyV91X6N9Mnj0+NZb2BH4HZgLWkWwwEdjOMmYAXwOOkNNrnMcQDvJ329fxxYnn9OqNr1aBFHZa4HMBt4NNd1JXDxeL+nO/XeGOlnqDJmZtYHyjq8Y2ZmbeBG38ysj7jRNzPrI270zcz6SMcbfZV8ITUzs17W0UZf0gTgO6S7WGcCiyTNHOE557T6exX0QgzgOMqkF2KA3oijajF0+pP+fGBtRPwlIv4H3AKcOMJzKvUf2kQvxACOo0x6IQbojTgqFUOnG/0qLKRmZtazOnpzlqRTgWMj4uz8+yeA+RFxft1555B7z4kTJ86bNavVukewbNky5s2bV6i82bnttGnTJiZNmtTR12wHx1EevRAD9EYcZY1h2bJlz0fEVhXbbiz/qKR1wGbgdWBLRAxI2gO4lbTW+TrgtIj4V37Kh4DTJR0BfJ4mC4xFxHXAdQADAwMxODg4lmrW1pf6Ti5vatOw3Hcrm1lVSXq6Ufl4DO8cFRFzImIg/74YuDciZpDWqlicKzATeB/wD+Bs4Lt0eCG1Ro14zXoZb2rVOdRrVm5mVkbtGNM/EbgxH98InFRTfgtwHmlFvsnAHyNiVRvqMCbNOodarb4hNOLOwczKYKyN/qh3j4qIX0bEu0mrJP5mjK/fNc2Gftw5mFmZjWlMn7R71LOS9gaWSlrd4tzCu8bUJnL33XffMVaxu0bTORQdampVbmbWyoif9PPelhslrawp20PSUuD3+fE1hnePek3SX/Ndt4sY3mnmDeCb+U7cK2mxS1REXBcRAxExUMaseDu045uDvzWYWb0iwzs/JG0bVmsxcD8wl5Ss/RJp96iXSZ/ef5CfczXDidoPkmb6HEzasGA2aSMBG4XRfnOoL3PnYNbfRhzeiYj7lXa4r3UiaRuwB/K/cSBwKWmXmWtJUzM/mc9dmrdN257UgfwJ2Al4NCJeH2sA1ljRZLSHlMz6y7YmcveJiAcj4pCIOBj4b0RcRkrWromIo/OUzV8A78zl6yPisoiYDnycNNxjXeRktFn/Ge8pm82StYWTuJASuZIGJQ1u2rRp3Cpn28adg1nvKJTIBQZJQzhDtkjaIGl5TvD+J5evB87Iydo1wCGkZO16YLqkFZLWkjYUbpjEhf5M5PYCdw5m5Vc0kXtWXdka4JGImAPcDPwkl68EPgAcSrrr9hBgMM/XnwR8G5gBzCN1BNaHxtI5OBltNjZF5ul/FjgamChpPfBlUgL3Y5KeBJ4BTs3nziLN6lkObAEeBwbyGj3PAxcCS4BHSFM2zZoqkowGr6lkNhojftKPiEWk+ferImJqRFwPvEKajfMK8DTD4/NTgJsiYnpEHERq/Kfkn7URMSsncr+Gl1S2cVJkTSUPKZkl25rIvQaYDswBNgCX53Incq2UnG8wS4okcqeR1sk5UNIqSRdExHPArsA9wOnAaZJ2J43TT5O0JCdsFwLTcvlUSfMkrQBuB/ZTk3eME7nWLe4crNcV+aS/hTQcsxZYAJwr6UjyEsrAlcBT+fe7SEnfRcBHgX8C55OWYtgM/Ii0ps6jwKtsfaevWSW4c7CqKtLoX0FaVuEg4AnS9MyLgQtId+UelR9PysskP00ar78L+Ayps5gPfJE07fNmUidxOcPLLpv1JM9UsrIpsgzDoqHjvBzD/aRpmc9ExMyavw0tofwkKZl7cy4/hdQJrAP+EBHH5PIjcDLXDPBMJeucwolcSTsDdwAXRsTLrU5tUDaqZK4TuWaNeaaSjVWhRK6k+0jbHE4hJWahjXflOpFrtu2cb7BWiiZy/00a159BSuTOxHflmlWaO4f+VOSO3OmkmTgrSGvi7wOcjO/KNesL3v2ttxS5I/eBiFBEzCbNtnkJuArflWtmNTxTqRrGksht2125TuSa9a4iyWhoPVOpnjuH4ookcneU9DAp6TqFNEYPaV/cX5HG9o8k3bgFTuSa2Tgouvtbq/J67hyKfdJ/lTT3/gbSzJ3jJC0Avgrcm3fIeonhT/JO5JpZRzgZPXpFErmHk5ZVWEHaTGUGcBhwBvCspNNJwzvb5/OdyDWzUnEyelihRC6pc3iDNIZ/VUR8K/0p3hMRsyPiWNKm6OBErplVVDu+OZTtW0OhRG5EvJ7n408F5kua1eJ0J3LNrKeN9ptDfVk3O4dRracfES8C95FWx3xO0mSA/Lgxn7ae4bt2IXUUQ4ncqQ3KG72OE7lmVnllnKlUZPbOJEm75eOdgGOA1Qwvo0x+vDMf3wUslDRR0v6kHMBDOZG7WdKCvI7+mTXPMTPrW+2YqdSMRkpCSJoN3AhMIHUSt0XEpZL2BG4D9iXfkRsRL+TnXAR8ipTIvTAi7s7lA6SN1ncC7gbOjxEqIGkzaVpole1FSmJXneMoj16IAXojjrLG8K6I2GqoZMRGv9skDUbEQLfrMRa9EAM4jjLphRigN+KoWgzbukeumZlVkBt9M7M+UoVG/7puV2Ac9EIM4DjKpBdigN6Io1IxlH5M38zMxk8VPumbmdk4caNvZtZH3OibmfURN/pmZn3Ejb6ZWR/5P71+ZTg7BJElAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder parameters:2.28415600e+07(0.08509GB) Decoder parameters:2.10935000e+06(0.4266GB)\n",
      "Data size:2.01974560e+07(0.07524GB)\n"
     ]
    }
   ],
   "source": [
    "# set the number of nodes in each layer\n",
    "a = 2\n",
    "b = int(100)\n",
    "db = int(10)\n",
    "\n",
    "M1 = int(a*m) # encoder hidden layer\n",
    "M2 = b + (m-1)*db # decoder hidden layer\n",
    "\n",
    "f = redDim # latent dimension\n",
    "\n",
    "# sparsity and shape of mask\n",
    "mask_2d=create_mask_2d(m,b,db)\n",
    "\n",
    "# number of parameters and memory\n",
    "en_para=m*M1+M1+M1*f\n",
    "de_para=f*M2+M2+np.count_nonzero(mask_2d)\n",
    "print('Encoder parameters:{:.8e}({:.4}GB)'.format(en_para,en_para*4/2**30),\\\n",
    "      'Decoder parameters:{:.8e}({:.4}GB)'.format(de_para,(f*M2+M2+M2*m)*4/2**30))\n",
    "\n",
    "# data size\n",
    "data_size=np.prod(orig_data_u.shape)\n",
    "print('Data size:{:.8e}({:.4}GB)'.format(data_size,data_size*4/2**30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file names\n",
    "if Re==10000:\n",
    "    file_name_AE_u=\"./model/AE_u_high_Re_v3_red-dim_{}pkl\".format(redDim)\n",
    "    file_name_AE_v=\"./model/AE_v_high_Re_v3_red-dim_{}.pkl\".format(redDim)\n",
    "    file_name_AE=\"./model/AE_high_Re_v3_red-dim_{}.p\".format(redDim)\n",
    "    \n",
    "    PATH_u = './checkpoint_u_high_Re_v3_red-dim_{}.tar'.format(redDim)\n",
    "    PATH_v = './checkpoint_v_high_Re_v3_red-dim_{}.tar'.format(redDim)\n",
    "elif Re==100:\n",
    "    file_name_AE_u=\"./model/AE_u_low_Re_v3_red-dim_{}.pkl\".format(redDim)\n",
    "    file_name_AE_v=\"./model/AE_v_low_Re_v3_red-dim_{}.pkl\".format(redDim)\n",
    "    file_name_AE=\"./model/AE_low_Re_v_3_red-dim_{}.p\".format(redDim)\n",
    "    \n",
    "    PATH_u = './checkpoint_u_low_Re_v3_red-dim_{}.tar'.format(redDim)\n",
    "    PATH_v = './checkpoint_v_low_Re_v3_red-dim_{}.tar'.format(redDim)\n",
    "else:\n",
    "    raise NameError('{} is given for Re, but it must be either 100 or 10000'.format(Re))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------checkpoint not restored--------\n",
      "\n",
      "\n",
      "Start first training... m=3364, f=30, a=2, b=100, db=10\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "try:\n",
    "    checkpoint = torch.load(PATH_u, map_location=device)\n",
    "    \n",
    "    encoder_u = Encoder(m,M1,f).to(device)\n",
    "    decoder_u = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    prune.custom_from_mask(decoder_u.full[2], name='weight', mask=torch.tensor(mask_2d).to(device))    \n",
    "       \n",
    "    optimizer = torch.optim.Adam(list(encoder_u.parameters()) + list(decoder_u.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    encoder_u.load_state_dict(checkpoint['encoder_u_state_dict'])\n",
    "    decoder_u.load_state_dict(checkpoint['decoder_u_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    last_epoch = checkpoint['epoch']\n",
    "    loss_hist = checkpoint['loss_hist']\n",
    "    best_loss = checkpoint['best_loss']\n",
    "    early_stop_counter = checkpoint['early_stop_counter']\n",
    "    best_encoder_u_wts = checkpoint['best_encoder_u_wts']\n",
    "    best_decoder_u_wts = checkpoint['best_decoder_u_wts']\n",
    "    \n",
    "    print(\"\\n--------checkpoint restored--------\\n\")\n",
    "\n",
    "    # resume training\n",
    "    print(\"\")\n",
    "    print('Re-start {}th training... m={}, f={},a={}, b={}, db={}'.format(\n",
    "        last_epoch+1, m, f, a, b, db))\n",
    "except:\n",
    "    encoder_u = Encoder(m,M1,f).to(device)\n",
    "    decoder_u = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    prune.custom_from_mask(decoder_u.full[2], name='weight', mask=torch.tensor(mask_2d).to(device))\n",
    "\n",
    "    optimizer = torch.optim.Adam(list(encoder_u.parameters()) + list(decoder_u.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    last_epoch = 0\n",
    "    loss_hist = {'train':[],'test':[]}\n",
    "    best_loss = float(\"inf\")\n",
    "    early_stop_counter = 1\n",
    "    best_encoder_u_wts = copy.deepcopy(encoder_u.state_dict())\n",
    "    best_decoder_u_wts = copy.deepcopy(decoder_u.state_dict())\n",
    "    \n",
    "    print(\"\\n--------checkpoint not restored--------\\n\")\n",
    "\n",
    "    # start training\n",
    "    print(\"\")\n",
    "    print('Start first training... m={}, f={}, a={}, b={}, db={}'\\\n",
    "          .format(m, f, a, b, db))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 2.723888589654092e-06\n",
      "test MSELoss: 2.7366178983356805e-06\n",
      "\n",
      "Epoch 200/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 1.7307970102605454e-06\n",
      "test MSELoss: 1.7519808807264781e-06\n",
      "\n",
      "Epoch 300/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 1.0109282168679021e-06\n",
      "test MSELoss: 1.0201940312981605e-06\n",
      "\n",
      "Epoch 400/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 5.903368498024722e-07\n",
      "test MSELoss: 5.905228476876801e-07\n",
      "\n",
      "Epoch 500/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 4.071000587932176e-07\n",
      "test MSELoss: 4.116696686651267e-07\n",
      "\n",
      "Epoch 600/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 3.736325138436827e-07\n",
      "test MSELoss: 3.7765883007523373e-07\n",
      "\n",
      "Epoch 700/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 3.3182473855441943e-07\n",
      "test MSELoss: 3.354256875809369e-07\n",
      "\n",
      "Epoch 800/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.8274796692914225e-07\n",
      "test MSELoss: 2.8641997005252053e-07\n",
      "\n",
      "Epoch 900/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.395050037200601e-07\n",
      "test MSELoss: 2.4040069490638416e-07\n",
      "\n",
      "Epoch 1000/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.0266597019984164e-07\n",
      "test MSELoss: 2.072434369893017e-07\n",
      "\n",
      "Epoch 1100/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.745282849916232e-07\n",
      "test MSELoss: 1.7721876872656138e-07\n",
      "\n",
      "Epoch 1200/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.5114028131116494e-07\n",
      "test MSELoss: 1.5453095727480104e-07\n",
      "\n",
      "Epoch 1300/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.350390959142734e-07\n",
      "test MSELoss: 1.371986542153536e-07\n",
      "\n",
      "Epoch 1400/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.2111162573293821e-07\n",
      "test MSELoss: 1.2188734501705767e-07\n",
      "\n",
      "Epoch 1500/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.078100586523141e-07\n",
      "test MSELoss: 1.105702637005379e-07\n",
      "\n",
      "Epoch 1600/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 9.914222487926637e-08\n",
      "test MSELoss: 1.0212837651124573e-07\n",
      "\n",
      "Epoch 1700/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 9.108110270008728e-08\n",
      "test MSELoss: 9.31644692059308e-08\n",
      "\n",
      "Epoch 1800/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 8.473302362674498e-08\n",
      "test MSELoss: 8.736777630247161e-08\n",
      "\n",
      "Epoch 1900/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 7.889043435392594e-08\n",
      "test MSELoss: 8.065158425552e-08\n",
      "\n",
      "Epoch 2000/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 7.35545863046434e-08\n",
      "test MSELoss: 7.543763445028162e-08\n",
      "\n",
      "Epoch 2100/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 7.29424148867188e-08\n",
      "test MSELoss: 7.477834031988096e-08\n",
      "\n",
      "Epoch 2200/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 7.233735678522731e-08\n",
      "test MSELoss: 7.42559606692339e-08\n",
      "\n",
      "Epoch 2300/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 7.233126292143066e-08\n",
      "test MSELoss: 7.424235946018598e-08\n",
      "\n",
      "Epoch 2384/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 7.23260616802329e-08\n",
      "test MSELoss: 7.423785177707032e-08\n",
      "\n",
      "Early stopping: 2384th training complete in 1h 17m 24s\n",
      "----------\n",
      "Best train MSELoss: 7.233517607119211e-08\n",
      "Best test MSELoss: 7.424953594181715e-08\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "since = time.time()\n",
    "\n",
    "for epoch in range(last_epoch+1,num_epochs+1):   \n",
    "\n",
    "    if epoch%num_epochs_print == 0:\n",
    "        print()\n",
    "        print('Epoch {}/{}, Learning rate {}'.format(\n",
    "            epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "        print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and test phase\n",
    "    for phase in ['train', 'test']:\n",
    "        if phase == 'train':\n",
    "            encoder_u.train()  # Set model to training mode\n",
    "            decoder_u.train()  # Set model to training mode\n",
    "        else:\n",
    "            encoder_u.eval()   # Set model to evaluation mode\n",
    "            decoder_u.eval()   # Set model to evaluation mode\n",
    "            \n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Iterate over data\n",
    "        for data, in data_loaders_u[phase]:\n",
    "            inputs = data.to(device)\n",
    "            targets = data.to(device)\n",
    "\n",
    "            if phase == 'train':\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = decoder_u(encoder_u(inputs))\n",
    "                loss = loss_func(outputs, targets)\n",
    "\n",
    "                # backward\n",
    "                loss.backward()\n",
    "\n",
    "                # optimize\n",
    "                optimizer.step()  \n",
    "\n",
    "                # add running loss\n",
    "                running_loss += loss.item()*inputs.shape[0]\n",
    "            else:\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    outputs = decoder_u(encoder_u(inputs))\n",
    "                    running_loss += loss_func(outputs,targets).item()*inputs.shape[0]\n",
    "\n",
    "        # compute epoch loss\n",
    "        epoch_loss = running_loss / dataset_u_shapes[phase][0]\n",
    "        loss_hist[phase].append(epoch_loss)\n",
    "            \n",
    "        # update learning rate\n",
    "        if phase == 'train':\n",
    "            scheduler.step(epoch_loss)\n",
    "\n",
    "        if epoch%num_epochs_print == 0:\n",
    "            print('{} MSELoss: {}'.format(\n",
    "                phase, epoch_loss))\n",
    "\n",
    "    # deep copy the model\n",
    "    if round(loss_hist['test'][-1],10) < round(best_loss,10):\n",
    "        best_loss = loss_hist['test'][-1]\n",
    "        early_stop_counter = 1\n",
    "        best_encoder_u_wts = copy.deepcopy(encoder_u.state_dict())\n",
    "        best_decoder_u_wts = copy.deepcopy(decoder_u.state_dict())\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= early_stop_patience:  \n",
    "            break\n",
    "    \n",
    "    # save checkpoint every num_epoch_print\n",
    "    if epoch%num_epochs_print== 0:\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'encoder_u_state_dict': encoder_u.state_dict(),\n",
    "                    'decoder_u_state_dict': decoder_u.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss_hist': loss_hist,\n",
    "                    'best_loss': best_loss,\n",
    "                    'early_stop_counter': early_stop_counter,\n",
    "                    'best_encoder_u_wts': best_encoder_u_wts,\n",
    "                    'best_decoder_u_wts': best_decoder_u_wts,\n",
    "                    }, PATH_u)        \n",
    "\n",
    "print()\n",
    "print('Epoch {}/{}, Learning rate {}'\\\n",
    "      .format(epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "print('-' * 10)\n",
    "print('train MSELoss: {}'.format(loss_hist['train'][-1]))\n",
    "print('test MSELoss: {}'.format(loss_hist['test'][-1]))\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "\n",
    "# load best model weights\n",
    "encoder_u.load_state_dict(best_encoder_u_wts)\n",
    "decoder_u.load_state_dict(best_decoder_u_wts)\n",
    "\n",
    "# compute best train MSELoss\n",
    "encoder_u.to('cpu').eval()\n",
    "decoder_u.to('cpu').eval()\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    train_inputs = torch.tensor(data_u[train_ind])\n",
    "    train_targets = torch.tensor(data_u[train_ind])\n",
    "    train_outputs = decoder_u(encoder_u(train_inputs))\n",
    "    train_loss = loss_func(train_outputs,train_targets).item()\n",
    "\n",
    "# print out training time and best results\n",
    "print()\n",
    "if epoch < num_epochs:\n",
    "    print('Early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "else:\n",
    "    print('No early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "print('-' * 10)\n",
    "print('Best train MSELoss: {}'.format(train_loss))\n",
    "print('Best test MSELoss: {}'.format(best_loss))\n",
    "\n",
    "# # save models\n",
    "# print()\n",
    "# print(\"Saving after {}th training to\".format(epoch),file_name_AE_u)\n",
    "# torch.save((encoder_u,decoder_u),file_name_AE_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "checkpoint removed\n"
     ]
    }
   ],
   "source": [
    "# delete checkpoint\n",
    "try:\n",
    "    os.remove(PATH_u)\n",
    "    print()\n",
    "    print(\"checkpoint removed\")\n",
    "except:\n",
    "    print(\"no checkpoint exists\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD4CAYAAAAZ1BptAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZxU5Z3v8c+vqqt31m4aEMRuBREQF2hcosnoGBGMuEwSrxpzM5MMZHJjbmYcM2ISxzj3JjKZmbxyzTpkwjhm0WHMJhEjwStiFBcwqK2A3WzSNPTG1vtS9cwfVQ1t09UUVdVVp6u+79erX1311Dmnfk/T9tfnPE+dY845REREBuNLdwEiIuJdCgkREYlKISEiIlEpJEREJCqFhIiIRJWT7gKGUlpa6srLy9NdhojIiLJly5Ym59yEZBzLkyFhZkuAJdOnT2fz5s3pLkdEZEQxs73JOpYnTzc559Y455aNGTMm3aWIiGQ1T4aEmS0xs5VHjx5NdykiIlnNkyGhkYSIiDd4ck5CRCRePT091NbW0tnZme5Shl1+fj5Tp04lEAgM23soJEQko9TW1jJq1CjKy8sxs3SXM2ycczQ3N1NbW0tFRcWwvY8nTzdpTkJE4tXZ2UlJSUlGBwSAmVFSUjLsIyZPhoTmJEQkEZkeEH1S0U9PhkSifld1kH97YVe6yxARGfEyMiTWb6vn31/ck+4yRCRLHTlyhO9///unvd/111/PkSNHhqGi+HkyJBKdk/AZBEO6mZKIpEe0kAgGg0Put3btWsaOHTtcZcXFkyGR6JyE32eEdMc9EUmT5cuXs3PnTi666CIWLFjA1VdfzR133MHcuXMBuPnmm5k/fz5z5sxh5cqVx/crLy+nqamJPXv2MGvWLJYuXcqcOXNYuHAhHR0daelLRi6BNVNIiAg8uOZt3qk7ltRjzj5jNA8smTPkNitWrKCqqoqtW7eyYcMGPvKRj1BVVXV8qeqqVasYP348HR0dLFiwgI9+9KOUlJS87xjV1dU89thj/OhHP+LWW2/lF7/4BXfeeWdS+xKLjAwJvxk62yQiXnHJJZe877MMDz/8ML/61a8A2LdvH9XV1SeFREVFBRdddBEA8+fPZ8+ePSmrt7+MDAnNSYgIcMr/40+VoqKi4483bNjA+vXr2bRpE4WFhVx11VWDftYhLy/v+GO/35+2002enJNIlE9zEiKSRqNGjaKlpWXQ144ePcq4ceMoLCxk+/btvPzyyymu7vR4ciTR/34S8fCZEdJIQkTSpKSkhCuuuILzzz+fgoICJk6cePy1RYsW8cMf/pALLriAmTNnctlll6Wx0lPzZEg459YAayorK5fGs7/P0JyEiKTVz3/+80Hb8/LyePrppwd9rW/eobS0lKqqquPt99xzT9Lri5VON4mISFSZGRJaAisikhQZGRI5hMhxPekuQ0RkxMvIkFi08//y+8Dd6S5DRGTEy8iQcD4/fkI4nXISEUlIRoYEFg4JfaBORCQxKQ0JM7vZzH5kZr8xs4XD90Y+fIS0DFZE0iLeS4UDfPvb36a9vT3JFcUv5pAws1Vm1mBmVQPaF5nZDjOrMbPlQx3DOfdr59xS4M+B/xFXxTFwkZGEVjiJSDpkUkiczofpHgG+Czza12BmfuB7wLVALfCamT0J+IGHBuz/aedcQ+TxVyP7DQ+fQkJE0qf/pcKvvfZaysrKWL16NV1dXdxyyy08+OCDtLW1ceutt1JbW0swGOT++++nvr6euro6rr76akpLS3nuuefS3ZXYQ8I5t9HMygc0XwLUOOd2AZjZ48BNzrmHgBsGHsPCN2RdATztnHt9sPcxs2XAMoBp06bFWt6Ag4RPN2lOQiTLPb0cDr6V3GNOmguLVwy5Sf9Lha9bt44nnniCV199FeccN954Ixs3bqSxsZEzzjiDp556Cghf02nMmDF861vf4rnnnqO0tDS5dccp0TmJKcC+fs9rI23RfAH4MPAxM/urwTZwzq0EHgRez83Njasod3wkEdfuIiJJs27dOtatW8fFF1/MvHnz2L59O9XV1cydO5f169dz77338sILLxDvTdaGW6LXbrJB2qL+aXbOPQw8fKqDJnrtJiwnPHGtlBDJbqf4P/5UcM5x33338dnPfvak17Zs2cLatWu57777WLhwIX//93+fhgqHluhIohY4s9/zqUBdgsdM+B7X+PzkENSchIikRf9LhV933XWsWrWK1tZWAPbv309DQwN1dXUUFhZy5513cs899/D666+ftK8XJDqSeA2YYWYVwH7gNuCORItKdCThzIffHMFQKNFSREROW/9LhS9evJg77riDyy+/HIDi4mJ++tOfUlNTw5e+9CV8Ph+BQIAf/OAHACxbtozFixczefJkT0xcW6yfSjazx4CrgFKgHnjAOfdjM7se+DbhFU2rnHNfT7ioE/eTWFpdXX3a+7/x0/u4sOb71P91HRPHFp16BxHJGNu2bWPWrFnpLiNlBuuvmW1xzlUm4/ins7rp9ijta4G1ySim3zETGkmYzw9AKNSbzLJERLJOxl6WAyAYVEiIiCTCkyGRjIlrAIKakxDJRtlycc9U9NOTIeGcW+OcWxb3umFfuFsaSYhkn/z8fJqbmzM+KJxzNDc3k5+fP6zv48l7XPebuI5vf1+4W05zEiJZZ+rUqdTW1tLY2JjuUoZdfn4+U6dOHdb38GRIJLwENnK6yWkkIZJ1AoEAFRUV6S4jY3jydFOizMLZFwoF01yJiMjIlpEh0TcnEQoqJEREEuHJkEh0dVPf5yQ0JyEikhhPhkTiq5siH6bTSEJEJCGeDIlEnRhJKCRERBKRkSHR94lrXZZDRCQxngyJZM1JoJGEiEhCPBkSic5J9H2YTnMSIiKJ8WRIJEyrm0REkiIjQ8L8Ot0kIpIMGRkSvsjpJl3gT0QkMRkZEn5/35yEQkJEJBGeDIlEVzfl5IRDordXp5tERBLhyZBIdHWT368704mIJIMnQyJR/kAuAKHe7jRXIiIysmVoSOQB4BQSIiIJycyQyA2HRKi3K82ViIiMbBkZEjmBgvADhYSISEIyMyRywzcGdwoJEZGEZGhIhE83EdSchIhIIlIWEmY2y8x+aGZPmNnnhvO9AoHwSEIhISKSmJhCwsxWmVmDmVUNaF9kZjvMrMbMlg91DOfcNufcXwG3ApXxl3xqvsjqJs1JiIgkJtaRxCPAov4NZuYHvgcsBmYDt5vZbDOba2a/HfBVFtnnRuAPwLNJ68FgcsIhYRpJiIgkJCeWjZxzG82sfEDzJUCNc24XgJk9DtzknHsIuCHKcZ4EnjSzp4CfD7aNmS0DlgFMmzYtlvJO5sshhCkkREQSFFNIRDEF2NfveS1wabSNzewq4M+APGBttO2ccyuBlQCVlZUursrM6CEHCykkREQSkUhI2CBtUf+oO+c2ABtiOrDZEmDJ9OnT4yoMoIcAFuyJe38REUlsdVMtcGa/51OBusTKSZ4ecrCgJq5FRBKRSEi8BswwswozywVuA55MRlGJXgUWoMdydbpJRCRBsS6BfQzYBMw0s1oz+4xzrhe4C3gG2Aasds69nYyiEr2fBEDQApiWwIqIJCTW1U23R2lfyxCT0PFyzq0B1lRWVi6N9xhd/kICvW1JrEpEJPtk5GU5ALr8xeQGFRIiIonwZEgk43RTT04RBSGFhIhIIjwZEsmYuO4NjKLAtSexKhGR7OPJkEjKxHWgmCLXkcSqRESyjydDIhkjCZc3mmLa6erpTWJlIiLZxZMhkQyWP4qABWltbU13KSIiI1bGhoS/IDwKaTt2OM2ViIiMXJ4MiWTMSeREQqK9VSEhIhIvT4ZEMuYkcovGAtDZciRZZYmIZB1PhkQy5BaFA6arTSEhIhKvjA2JwlHjAOhpj/+UlYhItvNkSCRjTqJgdDgkehUSIiJx82RIJGNOoqg4HBKhzmPJKktEJOt4MiSSwVcwOvxAISEiEreMDQn8ATrJxd/Tku5KRERGrMwNCaDL8qBH128SEYlXRodEt+Xj61VIiIjEy5MhkYzVTQCdvkJKuuuSVJWISPbxZEgkY3UTQGPuVEYHdVkOEZF4eTIkkqU9UEJxSBPXIiLxyuiQcIECculOdxkiIiNWRoeEBQrIc13gXLpLEREZkTI8JPLxmyPY25PuUkRERqSMDglfbgEA7e26O52ISDwyOiRyIiHR0dGW5kpEREamlIaEmRWZ2RYzuyEV7+fvC4n29lS8nYhIxokpJMxslZk1mFnVgPZFZrbDzGrMbHkMh7oXWB1PofEI5BcB0NmukYSISDxyYtzuEeC7wKN9DWbmB74HXAvUAq+Z2ZOAH3howP6fBi4A3gHyEys5doHc8Ft16nSTiEhcYgoJ59xGMysf0HwJUOOc2wVgZo8DNznnHgJOOp1kZlcDRcBsoMPM1jrnQoNstwxYBjBt2rTYezKI3ILwSKK7UyEhIhKPWEcSg5kC7Ov3vBa4NNrGzrmvAJjZnwNNgwVEZLuVwEqAysrKhD7goJAQEUlMIiFhg7Sd8o+6c+6RUx7YbAmwZPr06XGUdUJ+JCR6u3QlWBGReCSyuqkWOLPf86mApy65mldQDECvRhIiInFJJCReA2aYWYWZ5QK3AU8mo6hkXQW24PhIQktgRUTiEesS2MeATcBMM6s1s88453qBu4BngG3Aaufc28koKln3k8iJLIG9rvprSahKRCT7xLq66fYo7WuBtUmtKHzcNcCaysrKpQkdKCdlq21FRDJSRl+Wg0DB+5+/9B14d116ahERGYE8GRLJOt2EP/fE46P7Yd1X4ecfT+yYIiJZxJMhkayJa6zfKt3ezsSOJSKShTwZEkkbSfTT2tXvnhJdLfCHb0No0M/ziYhIhCdDImkjiX42vHPgxJPfPwDrH4Dta5J2fBGRTOTJkBgOU/JO3Hjod69Xhx/06JPYIiJDyfiQqJ33JQAufvbO423tPZHTTLr3tYjIkDwZEsmck+icOO+kNnf8slMKCRGRoXgyJJI5JxHIO/kDdcdDYvAL0YqISIQnQyKZ+m5h2p/OMomIxCbjQyInd6iRhNJCRGQongyJZM5JBPIGGUn0hcQ7v074+CIimcyTIZHUOYlBTjeF+kKiZn3CxxcRyWSeDIlkKigYbCQhIiKxyPiQCOQVntR2rf/1NFQiIjLyZHxIkFt0UtMES941oUREMlnmh4QZbxVelu4qRERGJE+GRLKvAltdPD/6i7oSrIhIVJ4MiWRfBbYgd4i7tLpgUt5DRCQTeTIkku1PLp4V9bVgb0/U10REsl1WhEThvNuivtbdo5AQEYkmK0ICMzp8xYO+tLvxWIqLEREZObIjJICOKFMPvb29qS1ERGQEyZqQCOIftN2FFBIiItFkTUhE+wBdKKglsCIi0aQsJMzsKjN7wcx+aGZXpep9+9QXnTdoe0gjCRGRqGIKCTNbZWYNZlY1oH2Rme0wsxozW36KwzigFcgHauMrN349V949aLsL6nMSIiLRxDqSeARY1L/BzPzA94DFwGzgdjObbWZzzey3A77KgBecc4uBe4EHk9eF2Ey99GODtmskISIS3RAfRT7BObfRzMoHNF8C1DjndgGY2ePATc65h4AbhjjcYSAv2otmtgxYBjBt2rRYyouNDZ6HGkmIiESXyJzEFGBfv+e1kbZBmdmfmdm/Aj8BvhttO+fcSudcpXOucsKECQmUd1IB/O7ckwcwWt0kIhJdTCOJKGyQtqj383HO/RL4ZUwHNlsCLJk+fXqcpQ2uO3fsSW1a3SQiEl0iI4la4Mx+z6cCdYmVM7wunH7y6atQUJflEBGJJpGQeA2YYWYVZpYL3AY8mYyikn0V2D5nVcwc5M00JyEiEk2sS2AfAzYBM82s1sw+45zrBe4CngG2Aaudc28no6hk30/iuDFT4J6a9zW5kEJCRCSaWFc33R6lfS2wNqkVhY+7BlhTWVm5NNnHpvj9k+EuqIlrEZFosuayHNE4nW4SEYnKkyExbKebBuG0uklEJCpPhsRwTVwfd8d/ceTK+8Pvpc9JiIhElcjnJIbNcH1O4rhzF9LbEwA0cS0iMpTsHEkAPn84HxUSIiLReTIkUsHnD9+ESCEhIhJd1oaE+SJn2hQSIiJReTIkUrG6yeeL3M5UE9ciIlF5MiRSMyeh000iIqfiyZBIhdzRZQD42w6muRIREe/K2pAIjJnMUYopa/gDuKhXOBcRyWqeDImUfOLajB2jLuf8tleoXnEle17+tcJCRGQAT4ZEKuYkAM7//M/YcM7fUdx1gPLffYo935hP9e9/pIv+iYhEeDIkUqUwP4+rPvkVir70Fs/OfIBgTxczXryH5q+fy7tPPYzr7Up3iSIiaZXVIdFndFER19x+N1O+/AYbL/wnWlwh5752P/seqmTH8/8JIV0EUESyk0Kin/zcHD50yzKmfPkNXrjon/EFu5n53DLeW7GAgy/+VHMWIpJ1FBKDyA34+eDNSyld/gbPznwA6zrGpN9/nn0rLqGp6tl0lycikjKeDIlU3k9iKPn5+Vxz+90U/u0brJ/2v5nQuZvR//Vxtqz8HK1HmtJam4hIKpjz8CmUyspKt3nz5nSXcVzd3nfZ+8RXufTYOlqsiIPz72bm9V8EvyevuC4iWcrMtjjnKpNxLE+OJLzqjLPO5fK/Xc2OW9ayy1/BzC3/AP+nhJZf/o3mK0QkIykk4jDrog8wZ/nzrD//mwCMenMVPDiWzj2vpLkyEZHkUkjEKTfg58Mf+ywHP7+TNwsvAyD/kYXs/tWD0NOR5upERJJDIZGgSRNKueDvnuHtax7lGMVUvPEtjq2YTXv18+kuTUQkYQqJJJnzwZvIXV7Di1OXUtB7lMKf3Ujdo0uhpzPdpYmIxE0hkUT5+QVc8Zf/zLs3/gaAM3atpusbZ9H6K01si8jIlLKQMDOfmX3dzL5jZp9K1fumw5z5H6Tzy01sGH0jea6T4jdW0fbNWdBSn+7SREROS0whYWarzKzBzKoGtC8ysx1mVmNmy09xmJuAKUAPUBtfuSNHfm6Aq+7+CX/8xJsAFHUcgH85l/aX/z3NlYmIxC7WkcQjwKL+DWbmB74HLAZmA7eb2Wwzm2tmvx3wVQbMBDY55+4GPpe8LnjbxTPOovPLzbw75koACn/317SvmAnd7WmuTETk1GIKCefcRuDQgOZLgBrn3C7nXDfwOHCTc+4t59wNA74aCI8eDkf2jXpjaTNbZmabzWxzY2Pj6ffIg/Jzczj3b55i+0fXA1DYeRC+MZnWl36c5spERIaWyJzEFGBfv+e1kbZofglcZ2bfATZG28g5t9I5V+mcq5wwYUIC5XnPeXMX0Hv/Ydad82UAitfdzaF/vRG6WtJcmYjI4BIJCRukLeoSHudcu3PuM865LzjnvjfkgT1ygb/hkOP3sfCT97Ltk2+w3yYx/sDz8NBU9r7+TLpLExE5SSIhUQuc2e/5VKAusXKyx6xzyilZ/habz/gEAGc9eSvbVn4a13kszZWJiJyQSEi8BswwswozywVuA55MRlGpusd1uuXn5VK57Ptsuf4pAGbV/QJbcSaH19x/6s9VtA+cIhIRSb5Yl8A+BmwCZppZrZl9xjnXC9wFPANsA1Y7595ORlGZfLppMPMvuZLW5U28mPdBAMZteZjOr59F+5b/hPp3Tt6h/h34ZgWhLY+muFIRyTa6n4THbHppI5evW3LyCw8cAYtMA1X9Ep74C14v/hPm3ZOUwZuIZBDdTyKDXf6BD9GxvIFNhVe9/4UHx8KeF6HxXUJH9wNw8KiuNisiw8uTt1QzsyXAkunTp6e7lLQoyM/j8r/7DW9sfY0Lf/3hEy88cj1wItkt+mIyEZGk8ORIIlsmrk/lwosWwANHePKcfxj09QC9Ka5IRLKNJ0NC+jHjxk9+kb3/a89JL1XYwdTXIyJZxZMhkW2rm2JxVtk4+NpRnr52/fG2ltzM+kS6iHiPVjeNUG9+cxEXtG+iZswHCBaU4Msfha94AoHRZRSMnUzh+EkUjpuEFZZA/pgTK6NEJOMlc3WTJyeu5dR6L7uLFzd0M+bIAcYf2U4xnYy2wa8s20kex3LG0xoopaugDCsuIzBmErkTzmF06WRGjy3FJs0Fnz/FvRARr/PkSKLf6qal1dXV6S7H05xztHb1crith8MtrbQcOkDnkQa6jx4g2NKItTcSaG8kv6uR4u5mxoUOUcIRxgwIlG4CNOdMJJg7ivYxM3Cl51Iw6VxKz6igcOpcCBSkqYcicrqSOZLwZEj00emm5AuFHAePdVLf1ERb/S566nfQdawJ/9E95LXVkd99iApXywR7/3zQEd84juWfQdfYc8gZdxZjJp7J2HMuwTfpfPAH0tQbERmMQkKG1dH2HvYdqONo7Q5aGvZAw3YCLe8xqXMnU1w9Y63tfds35U6lZfz5+EeVMWbaXMZcfAsUa1JdJF0UEpIWzjmaWrs5ULuL9qqnGVX7PJ2dHYzpqmP6+24tEtZt+RybMI+e826idM7VBMrO1QS6SApkfEhoTmJkcc5x4EgHu955ld7dL9F5tJGZh56jIrj7fdsd8Y0nGCjm8LQPU+oOUzymlJzFX4ecvDRVLpKZMj4k+mgkMbJ19gR55716DlT/Ebf7BcYd2sr53W8yinZ8Fv696ybAoaJzaDlrIcVnL6Bs2kz848sVHCIJUEjIiNUbDLFt7wGadr5O6Zs/pL2zm+nd2ymxk2+2dHjUDApdOzkf+Sf8ZefB+LN1ukokBgoJySidPUG2795Hy85N9O7exAcaHiOP7kG33X/mDRTN/FNGlZ2Ff8rFUFSS4mpFvE8hIRkvGHJU7Wum8ZXV7N5dw8faVzPOWk7arqmggtKO8NxHz2VfIHD1vRAoAp8nrzgjkhIKCclKXb1BqmqPsHvHW5TueoLx9a8wx1Xjt5N/h/dPXkjRmPEUjy0hZ94nYcJ5OlUlWSPjQ0KrmyRWRzt62LqngaZ3X6H7nbXM7t3GhcGqqNu3FZcTmnEdxVPnYId3wwfvgbziFFYsMvwyPiT6aCQh8QiGHDtq62nc/RYVr/4DdB1jWu+eoffx5WKjz8BXNgs+/DUoOy8VpYoMC4WESByaWzrZvKuenB1rOGPvb5jV9uop9zlYfjMlY0cTuPDjMHUB5OTrtJV4nkJCJEmCIce+Q+28ves93K4NzNzxA3rJoTTUdNL1q/r0+vJom1hJbkk5+TOvwcZOg3HlUFSqABFPUEiIDLNQyPHyriZajh2hq+YF8t57npK2aird2zHt31M2l8DM6+DSz0LeqHBjy0EYXzGMVYuEKSRE0mjfoXbe3b2H9n1v0nVoH7Pfe4zZ7DytY3Qv+hdyS8ph9OTwyivdy0OSSCEh4kFdvUF2NbbxH3+oZk77q0w59Ao5Hc18qHtjzMfomLyA/LOvwMpmwxkXw/Mr4PK7YMq8YaxcMo1CQmQECYUcDS1dNLd2srOugea9b1N2+HWO7H2bT+Q8G9Mx2gqn4OvtoKD7EABu4hxobcTueBxKZkD+6OHsgowwIzIkzOyDwCcI3zJ1tnPuA6faRyEh2aCzJ8j+Ix28vLMJO7QLju3nrP2/pbLl/0e9PMlAIcvB53oB6Bo3g7yP/GN4Er14UviugrlFUFw2nN0QD0l5SJjZKuAGoME5d36/9kXA/wP8wL8551bEcKybgYnOuX891bYKCRE40t7N9oMt/HHvYfLoIbjvFcoPv8Slh9Ycv695l8shz3pjOl7X6HJyzr0GX3crrm4rvkXfAPOBPxcmng8FY4ezO5IC6QiJDwGtwKN9IWFmfuBd4FqgFngNuJ1wYDw04BCfds41RPZbDfylc+7ky34OoJAQObWWzh5qD3dQf6yTHfsP0bFvK8U9zcyqX8P47jpm2V4Aep2PHAvF9yZ3rIaaZ6HjELz1X/C5l2DCLHDB8O1rm2ogJxfGTktizyReaTndZGblwG/7hcTlwNecc9dFnt8H4JwbGBD9jzENuN85t3SIbZYBywCmTZs2f+/evTHVJyLRdfYEaWzpYv+RDvY3HKL+YC0FBzez9WA3F+Ud4C+6fgJAVaic8317TuvYHeXXULAnMrdy9VehpQ5mLITG7XDuYpgwc/DPj7Q1Q+M2KL8ywd7JQF4JiY8Bi5xzfxl5/kngUufcXUMc40HgGefcS7G8p0YSIqnjnKOxpYs9TW00t3WzvbaRX//hj3xhwh+Z1rGDUR37CBBkuq/utEclzUXTKWmrASCYOwp/qAd6O8MvfuIJKBgP486C/LHgzzmxY+cxTcrHIZkhkXPqTaLXMUjbkInjnHsgpgOfuMBfPHWJSBzMjLLR+ZSNzgdg8dzJ/M3iC4BPvW+73mCImsZWmlu7qT/cSkdHG+/V7mdf01GusDcYd2gr17sX3rfPuNadx/9i+LsHXPL9Zx87dXH3N4VPa0nKJRIStcCZ/Z5PBeoSK0dEvC7H7+O8SX3/d18a+T4n8v3jx7cLhhzt3b3saQpPrm/a2cjLb+2g61gTXxy9gYbuXPYf6+Gz/AIYevK96Tt/iu/MBeDLwXw+MB8W+cLnB58//Nznx3yR79b32IfP58d8fnw+HxY5hvlywvuaD44/9vf77uv3PNb7k8R4WZZYLt9SNgvyx8T4vsMnkdNNOYQnrq8B9hOeuL7DuRivWxADnW4SyQ7OOZyDPc1tvLX/KPubjtFxrJm65sN8Yt+DnGP78eHIIYjhMBw+HD5Cg95PJBPs/MhqzllwXVz7pvx0k5k9BlwFlJpZLfCAc+7HZnYX8AzhFU2rkhUQOt0kkl3MDDM4e0IxZ08oBqYcf63+2LW8vO8IoZAj5CDk3PEv58IfVgyFQrhQLy7kCLleCIUIBXvD4RMKEgqFCIWCWChIKBSEUBDngrhgMLxCKxSM7B9+jAueeBwK4o6/ZzjQEuprjPtfP3F2Qu+TLPrEtYhIhknmSEI3AhYRkag8GRJmtsTMVh49Ovj1/EVEJDU8GRLOuTXOuWVjxqR/Zl9EJJt5MiRERMQbPBkSOt0kIuINngwJnW4SEfEGT4aEiIh4gydDQqebRES8wdMfpjOzRiDea4WXAk1JLGekUf/Vf/U/O5UCRc65Cck4mKdDIhFmtjlZnzgcidR/9V/9z87+J96jrBAAAAODSURBVLvvnjzdJCIi3qCQEBGRqDI5JFamu4A0U/+zm/qfvZLa94ydkxARkcRl8khCREQSpJAQEZGoMjIkzGyRme0wsxozW57ueoaDme0xs7fMbKuZbY60jTez35tZdeT7uH7b3xf5eewws/juiZhGZrbKzBrMrKpf22n318zmR35uNWb2sFksNxtOvyj9/5qZ7Y/8Dmw1s+v7vZZp/T/TzJ4zs21m9raZfTHSnvG/A0P0PTX//uF7y2bOF+Fbqe4EzgZygTeA2emuaxj6uQcoHdD2TWB55PFy4B8jj2dHfg55QEXk5+NPdx9Os78fAuYBVYn0F3gVuJzwHeufBhanu28J9P9rwD2DbJuJ/Z8MzIs8HgW8G+lnxv8ODNH3lPz7Z+JI4hKgxjm3yznXDTwO3JTmmlLlJuA/Io//A7i5X/vjzrku59xuoIbwz2nEcM5tBA4NaD6t/prZZGC0c26TC/8X82i/fTwtSv+jycT+H3DOvR553AJsI3wj7Iz/HRii79Ekte+ZGBJTgH39ntcy9A90pHLAOjPbYmbLIm0TnXMHIPyLBZRF2jP1Z3K6/Z0SeTywfSS7y8zejJyO6jvVktH9N7Ny4GLgFbLsd2BA3yEF//6ZGBKDnWPLxHW+Vzjn5gGLgc+b2YeG2DZbfiZ9ovU3034OPwDOAS4CDgD/EmnP2P6bWTHwC+CvnXPHhtp0kLYR/TMYpO8p+ffPxJCoBc7s93wqUJemWoaNc64u8r0B+BXh00f1kSElke8Nkc0z9Wdyuv2tjTwe2D4iOefqnXNB51wI+BEnTiFmZP/NLED4j+TPnHO/jDRnxe/AYH1P1b9/JobEa8AMM6sws1zgNuDJNNeUVGZWZGaj+h4DC4Eqwv38VGSzTwG/iTx+ErjNzPLMrAKYQXgCa6Q7rf5GTke0mNllkVUd/7PfPiNO3x/HiFsI/w5ABvY/Uu+PgW3OuW/1eynjfwei9T1l//7pnrkfptUA1xNeAbAT+Eq66xmG/p1NePXCG8DbfX0ESoBngerI9/H99vlK5OexA4+v5ojS58cID6l7CP8f0Wfi6S9QGfmPaSfwXSJXHfD6V5T+/wR4C3gz8odhcgb3/0rCp0beBLZGvq7Pht+BIfqekn9/XZZDRESiysTTTSIikiQKCRERiUohISIiUSkkREQkKoWEiIhEpZAQEZGoFBIiIhLVfwPm/EUGd+6RPgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and test loss\n",
    "plt.figure()\n",
    "plt.semilogy(loss_hist['train'])\n",
    "plt.semilogy(loss_hist['test'])\n",
    "plt.legend(['train','test'])\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------checkpoint not restored--------\n",
      "\n",
      "\n",
      "Start first training... m=3364, f=30, a=2, b=100, db=10\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "try:\n",
    "    checkpoint = torch.load(PATH_v, map_location=device)\n",
    "    \n",
    "    encoder_v = Encoder(m,M1,f).to(device)\n",
    "    decoder_v = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    prune.custom_from_mask(decoder_v.full[2], name='weight', mask=torch.tensor(mask_2d).to(device))    \n",
    "       \n",
    "    optimizer = torch.optim.Adam(list(encoder_v.parameters()) + list(decoder_v.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    encoder_v.load_state_dict(checkpoint['encoder_v_state_dict'])\n",
    "    decoder_v.load_state_dict(checkpoint['decoder_v_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    last_epoch = checkpoint['epoch']\n",
    "    loss_hist = checkpoint['loss_hist']\n",
    "    best_loss = checkpoint['best_loss']\n",
    "    early_stop_counter = checkpoint['early_stop_counter']\n",
    "    best_encoder_v_wts = checkpoint['best_encoder_v_wts']\n",
    "    best_decoder_v_wts = checkpoint['best_decoder_v_wts']\n",
    "    \n",
    "    print(\"\\n--------checkpoint restored--------\\n\")\n",
    "    \n",
    "    # resume training\n",
    "    print(\"\")\n",
    "    print('Re-start {}th training... m={}, f={}, a={}, b={}, db={}'.format(\n",
    "        last_epoch+1, m, f, a, b, db))\n",
    "except:\n",
    "    encoder_v = Encoder(m,M1,f).to(device)\n",
    "    decoder_v = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    prune.custom_from_mask(decoder_v.full[2], name='weight', mask=torch.tensor(mask_2d).to(device))\n",
    "\n",
    "    optimizer = torch.optim.Adam(list(encoder_v.parameters()) + list(decoder_v.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    last_epoch = 0\n",
    "    loss_hist = {'train':[],'test':[]}\n",
    "    best_loss = float(\"inf\")\n",
    "    early_stop_counter = 1\n",
    "    best_encoder_v_wts = copy.deepcopy(encoder_v.state_dict())\n",
    "    best_decoder_v_wts = copy.deepcopy(decoder_v.state_dict())\n",
    "    \n",
    "    print(\"\\n--------checkpoint not restored--------\\n\")\n",
    "\n",
    "    # start training\n",
    "    print(\"\")\n",
    "    print('Start first training... m={}, f={}, a={}, b={}, db={}'.format(\n",
    "        m, f, a, b, db))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 2.493340050307871e-06\n",
      "test MSELoss: 2.4978205146908296e-06\n",
      "\n",
      "Epoch 200/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 1.6659348460629504e-06\n",
      "test MSELoss: 1.6792017049738206e-06\n",
      "\n",
      "Epoch 300/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 1.0108957859934017e-06\n",
      "test MSELoss: 1.027663051900163e-06\n",
      "\n",
      "Epoch 400/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 6.04355878595803e-07\n",
      "test MSELoss: 6.193901185724826e-07\n",
      "\n",
      "Epoch 500/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 3.749569697947966e-07\n",
      "test MSELoss: 3.815787238181656e-07\n",
      "\n",
      "Epoch 600/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 3.504879896808807e-07\n",
      "test MSELoss: 3.564197299965599e-07\n",
      "\n",
      "Epoch 700/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 3.1712944676253176e-07\n",
      "test MSELoss: 3.219404106857837e-07\n",
      "\n",
      "Epoch 800/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.7831269414550786e-07\n",
      "test MSELoss: 2.836985117937729e-07\n",
      "\n",
      "Epoch 900/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.40152331735414e-07\n",
      "test MSELoss: 2.4355722416657954e-07\n",
      "\n",
      "Epoch 1000/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.0566413069724213e-07\n",
      "test MSELoss: 2.1010583282077277e-07\n",
      "\n",
      "Epoch 1100/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.7813039867289383e-07\n",
      "test MSELoss: 1.8294677488484013e-07\n",
      "\n",
      "Epoch 1200/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.5709966327710904e-07\n",
      "test MSELoss: 1.614026047036532e-07\n",
      "\n",
      "Epoch 1300/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.3992736390615738e-07\n",
      "test MSELoss: 1.43094783311426e-07\n",
      "\n",
      "Epoch 1400/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.265062736129214e-07\n",
      "test MSELoss: 1.293784919198515e-07\n",
      "\n",
      "Epoch 1500/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.1461106039648616e-07\n",
      "test MSELoss: 1.1799832435599456e-07\n",
      "\n",
      "Epoch 1600/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.0522076211659916e-07\n",
      "test MSELoss: 1.075867217537052e-07\n",
      "\n",
      "Epoch 1700/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 9.670151436868668e-08\n",
      "test MSELoss: 9.952785404720998e-08\n",
      "\n",
      "Epoch 1800/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 9.075379597489854e-08\n",
      "test MSELoss: 9.348518688057084e-08\n",
      "\n",
      "Epoch 1900/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 8.502411139055649e-08\n",
      "test MSELoss: 8.602218883879687e-08\n",
      "\n",
      "Epoch 2000/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 7.927446797632996e-08\n",
      "test MSELoss: 8.106284212772153e-08\n",
      "\n",
      "Epoch 2100/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 7.403058471598559e-08\n",
      "test MSELoss: 7.517337792251056e-08\n",
      "\n",
      "Epoch 2200/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 6.672049966057224e-08\n",
      "test MSELoss: 6.823356102358957e-08\n",
      "\n",
      "Epoch 2300/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 6.63648068740557e-08\n",
      "test MSELoss: 6.797138780711976e-08\n",
      "\n",
      "Epoch 2400/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 6.636104122896906e-08\n",
      "test MSELoss: 6.796573899237046e-08\n",
      "\n",
      "Epoch 2427/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 6.635999573712398e-08\n",
      "test MSELoss: 6.796717713086765e-08\n",
      "\n",
      "Early stopping: 2427th training complete in 1h 20m 14s\n",
      "----------\n",
      "Best train MSELoss: 6.640907201926893e-08\n",
      "Best test MSELoss: 6.797091884891416e-08\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "since = time.time()\n",
    "\n",
    "for epoch in range(last_epoch+1,num_epochs+1):   \n",
    "\n",
    "    if epoch%num_epochs_print == 0:\n",
    "        print()\n",
    "        print('Epoch {}/{}, Learning rate {}'.format(\n",
    "            epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "        print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and test phase\n",
    "    for phase in ['train', 'test']:\n",
    "        if phase == 'train':\n",
    "            encoder_v.train()  # Set model to training mode\n",
    "            decoder_v.train()  # Set model to training mode\n",
    "        else:\n",
    "            encoder_v.eval()   # Set model to evaluation mode\n",
    "            decoder_v.eval()   # Set model to evaluation mode\n",
    "            \n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Iterate over data\n",
    "        for data, in data_loaders_v[phase]:\n",
    "            inputs = data.to(device)\n",
    "            targets = data.to(device)\n",
    "\n",
    "            if phase == 'train':\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = decoder_v(encoder_v(inputs))\n",
    "                loss = loss_func(outputs, targets)\n",
    "\n",
    "                # backward\n",
    "                loss.backward()\n",
    "\n",
    "                # optimize\n",
    "                optimizer.step()  \n",
    "\n",
    "                # add running loss\n",
    "                running_loss += loss.item()*inputs.shape[0]\n",
    "            else:\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    outputs = decoder_v(encoder_v(inputs))\n",
    "                    running_loss += loss_func(outputs,targets).item()*inputs.shape[0]\n",
    "\n",
    "        # compute epoch loss\n",
    "        epoch_loss = running_loss / dataset_v_shapes[phase][0]\n",
    "        loss_hist[phase].append(epoch_loss)\n",
    "            \n",
    "        # update learning rate\n",
    "        if phase == 'train':\n",
    "            scheduler.step(epoch_loss)\n",
    "\n",
    "        if epoch%num_epochs_print == 0:\n",
    "            print('{} MSELoss: {}'.format(\n",
    "                phase, epoch_loss))\n",
    "\n",
    "    # deep copy the model\n",
    "    if round(loss_hist['test'][-1],10) < round(best_loss,10):\n",
    "        best_loss = loss_hist['test'][-1]\n",
    "        early_stop_counter = 1\n",
    "        best_encoder_v_wts = copy.deepcopy(encoder_v.state_dict())\n",
    "        best_decoder_v_wts = copy.deepcopy(decoder_v.state_dict())\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= early_stop_patience:  \n",
    "            break\n",
    "    \n",
    "    # save checkpoint every num_epoch_print\n",
    "    if epoch%num_epochs_print== 0:\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'encoder_v_state_dict': encoder_v.state_dict(),\n",
    "                    'decoder_v_state_dict': decoder_v.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss_hist': loss_hist,\n",
    "                    'best_loss': best_loss,\n",
    "                    'early_stop_counter': early_stop_counter,\n",
    "                    'best_encoder_v_wts': best_encoder_v_wts,\n",
    "                    'best_decoder_v_wts': best_decoder_v_wts,\n",
    "                    }, PATH_v)        \n",
    "\n",
    "print()\n",
    "print('Epoch {}/{}, Learning rate {}'\\\n",
    "      .format(epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "print('-' * 10)\n",
    "print('train MSELoss: {}'.format(loss_hist['train'][-1]))\n",
    "print('test MSELoss: {}'.format(loss_hist['test'][-1]))\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "\n",
    "# load best model weights\n",
    "encoder_v.load_state_dict(best_encoder_v_wts)\n",
    "decoder_v.load_state_dict(best_decoder_v_wts)\n",
    "\n",
    "# compute best train MSELoss\n",
    "encoder_v.to('cpu').eval()\n",
    "decoder_v.to('cpu').eval()\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    train_inputs = torch.tensor(data_v[train_ind])\n",
    "    train_targets = torch.tensor(data_v[train_ind])\n",
    "    train_outputs = decoder_v(encoder_v(train_inputs))\n",
    "    train_loss = loss_func(train_outputs,train_targets).item()\n",
    "\n",
    "# print out training time and best results\n",
    "print()\n",
    "if epoch < num_epochs:\n",
    "    print('Early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "else:\n",
    "    print('No early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "print('-' * 10)\n",
    "print('Best train MSELoss: {}'.format(train_loss))\n",
    "print('Best test MSELoss: {}'.format(best_loss))\n",
    "\n",
    "# # save models\n",
    "# print()\n",
    "# print(\"Saving after {}th training to\".format(epoch),file_name_AE_v)\n",
    "# torch.save((encoder_v,decoder_v),file_name_AE_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "checkpoint removed\n"
     ]
    }
   ],
   "source": [
    "# delete checkpoint\n",
    "try:\n",
    "    os.remove(PATH_v)\n",
    "    print()\n",
    "    print(\"checkpoint removed\")\n",
    "except:\n",
    "    print(\"no checkpoint exists\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and test loss\n",
    "plt.figure()\n",
    "plt.semilogy(loss_hist['train'])\n",
    "plt.semilogy(loss_hist['test'])\n",
    "plt.legend(['train','test'])\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load models\n",
    "# try:\n",
    "#     encoder_u,decoder_u = torch.load(file_name_AE_u,map_location='cpu')\n",
    "#     encoder_v,decoder_v = torch.load(file_name_AE_v,map_location='cpu')\n",
    "#     print(\"\\n--------model restored--------\\n\")\n",
    "# except:\n",
    "#     print(\"\\n--------model not restored--------\\n\")\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights and bias\n",
    "en_wu1_s=encoder_u.full[0].weight.detach().numpy().astype('float32')\n",
    "en_bu1=encoder_u.full[0].bias.detach().numpy().astype('float32')\n",
    "en_wu2=encoder_u.full[2].weight.detach().numpy().astype('float32')\n",
    "\n",
    "en_wv1_s=encoder_v.full[0].weight.detach().numpy().astype('float32')\n",
    "en_bv1=encoder_v.full[0].bias.detach().numpy().astype('float32')\n",
    "en_wv2=encoder_v.full[2].weight.detach().numpy().astype('float32')\n",
    "\n",
    "de_wu1=decoder_u.full[0].weight.detach().numpy().astype('float32')\n",
    "de_bu1=decoder_u.full[0].bias.detach().numpy().astype('float32')\n",
    "de_wu2_s=decoder_u.full[2].weight.detach().numpy().astype('float32')\n",
    "\n",
    "de_wv1=decoder_v.full[0].weight.detach().numpy().astype('float32')\n",
    "de_bv1=decoder_v.full[0].bias.detach().numpy().astype('float32')\n",
    "de_wv2_s=decoder_v.full[2].weight.detach().numpy().astype('float32')\n",
    "\n",
    "de_wu2_s_sp=sp.csr_matrix(de_wu2_s,dtype='float32')\n",
    "de_wv2_s_sp=sp.csr_matrix(de_wv2_s,dtype='float32')\n",
    "\n",
    "# rescale weights\n",
    "en_wu1=en_wu1_s*u_scale_reciprocal\n",
    "en_wv1=en_wv1_s*v_scale_reciprocal\n",
    "\n",
    "de_wu1T=de_wu1.T\n",
    "de_wv1T=de_wv1.T\n",
    "\n",
    "de_wu2T=u_scale*de_wu2_s.T\n",
    "de_wv2T=v_scale*de_wv2_s.T\n",
    "\n",
    "de_wu2=de_wu2T.T\n",
    "de_wv2=de_wv2T.T\n",
    "\n",
    "de_wu2_sp=sp.csr_matrix(de_wu2,dtype='float32')\n",
    "de_wv2_sp=sp.csr_matrix(de_wv2,dtype='float32')\n",
    "\n",
    "de_wu2T_sp=de_wu2_sp.T\n",
    "de_wv2T_sp=de_wv2_sp.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy version of AE\n",
    "def sigmoid_np(input):\n",
    "    return (1.0/(1.0+np.exp(-input))).astype('float32')\n",
    "\n",
    "def encoder_u_np_forward(x):\n",
    "    z1 = en_wu1.dot(x) + en_bu1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = en_wu2.dot(a1)   \n",
    "    return y\n",
    "\n",
    "def decoder_u_np_forward(x):\n",
    "    z1 = de_wu1.dot(x) + de_bu1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = de_wu2.dot(a1)  \n",
    "    return y\n",
    "\n",
    "def decoder_u_sp_forward(x):\n",
    "    z1 = de_wu1.dot(x) + de_bu1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = sp.csr_matrix.dot(de_wu2_sp,a1)\n",
    "    return y\n",
    "\n",
    "def encoder_v_np_forward(x):\n",
    "    z1 = en_wv1.dot(x) + en_bv1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = en_wv2.dot(a1)   \n",
    "    return y\n",
    "\n",
    "def decoder_v_np_forward(x):\n",
    "    z1 = de_wv1.dot(x) + de_bv1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = de_wv2.dot(a1)   \n",
    "    return y\n",
    "\n",
    "def decoder_v_sp_forward(x):\n",
    "    z1 = de_wv1.dot(x) + de_bv1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = sp.csr_matrix.dot(de_wv2_sp,a1)\n",
    "    return y\n",
    "\n",
    "def decoder_u_np_forward_backwardT(x):\n",
    "    z1 = de_wu1.dot(x) + de_bu1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = de_wu2.dot(a1)\n",
    "\n",
    "    dout = de_wu1T\n",
    "    dout = (a1*(1-a1))*dout\n",
    "    dydxT = dout.dot(de_wu2T)   \n",
    "    return y,dydxT\n",
    "\n",
    "def decoder_u_sp_forward_backwardT(x):\n",
    "    z1 = de_wu1.dot(x) + de_bu1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = sp.csr_matrix.dot(de_wu2_sp,a1)\n",
    "\n",
    "    dout = de_wu1T\n",
    "    dout = (a1*(1-a1))*dout\n",
    "    dydxT = sp.csr_matrix.dot(dout,de_wu2T_sp)\n",
    "    return y,dydxT\n",
    "\n",
    "def decoder_v_np_forward_backwardT(x):\n",
    "    z1 = de_wv1.dot(x) + de_bv1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = de_wv2.dot(a1)\n",
    "\n",
    "    dout = de_wv1T\n",
    "    dout = (a1*(1-a1))*dout\n",
    "    dydxT = dout.dot(de_wv2T)   \n",
    "    return y,dydxT\n",
    "\n",
    "def decoder_v_sp_forward_backwardT(x):\n",
    "    z1 = de_wv1.dot(x) + de_bv1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = sp.csr_matrix.dot(de_wv2_sp,a1)\n",
    "\n",
    "    dout = de_wv1T\n",
    "    dout = (a1*(1-a1))*dout\n",
    "    dydxT = sp.csr_matrix.dot(dout,de_wv2T_sp)\n",
    "    return y,dydxT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE u: 2.36340476e-08\n",
      "MSELoss of AE v: 2.15329289e-08\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss\n",
    "comp_orig_data_u=np.zeros((ndata,f))\n",
    "comp_orig_data_v=np.zeros((ndata,f))\n",
    "\n",
    "rest_orig_data_u=np.zeros(orig_data_u.shape)\n",
    "rest_orig_data_v=np.zeros(orig_data_u.shape)\n",
    "\n",
    "for k in range(ndata):\n",
    "    comp_orig_data_u[k]=encoder_u_np_forward(orig_data_u[k]-u_ref)\n",
    "    comp_orig_data_v[k]=encoder_v_np_forward(orig_data_v[k]-v_ref)\n",
    "    \n",
    "    rest_orig_data_u[k]=decoder_u_sp_forward(comp_orig_data_u[k]) + u_ref\n",
    "    rest_orig_data_v[k]=decoder_v_sp_forward(comp_orig_data_v[k]) + v_ref\n",
    "    \n",
    "print(\"MSELoss of AE u: {:.8e}\".format(np.linalg.norm(orig_data_u-rest_orig_data_u)**2/np.prod(orig_data_u.shape)))\n",
    "print(\"MSELoss of AE v: {:.8e}\".format(np.linalg.norm(orig_data_v-rest_orig_data_v)**2/np.prod(orig_data_v.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale AE\n",
    "en_weight_u_s=encoder_u.full[0].weight.data\n",
    "en_weight_u=en_weight_u_s*torch.tensor(u_scale_reciprocal)\n",
    "encoder_u.full[0].weight=nn.Parameter(en_weight_u)\n",
    "\n",
    "de_weight_u_s=decoder_u.full[2].weight.data\n",
    "de_weight_u=(torch.tensor(u_scale)*de_weight_u_s.T).T\n",
    "de_weight_u_mask=decoder_u.full[2].weight_mask.data\n",
    "prune.remove(decoder_u.full[2],'weight');\n",
    "decoder_u.full[2].weight=nn.Parameter(de_weight_u)\n",
    "prune.custom_from_mask(decoder_u.full[2], name='weight', mask=de_weight_u_mask);\n",
    "\n",
    "en_weight_v_s=encoder_v.full[0].weight.data\n",
    "en_weight_v=en_weight_v_s*torch.tensor(v_scale_reciprocal)\n",
    "encoder_v.full[0].weight=nn.Parameter(en_weight_v)\n",
    "\n",
    "de_weight_v_s=decoder_v.full[2].weight.data\n",
    "de_weight_v=(torch.tensor(v_scale)*de_weight_v_s.T).T\n",
    "de_weight_v_mask=decoder_v.full[2].weight_mask.data\n",
    "prune.remove(decoder_v.full[2],'weight');\n",
    "decoder_v.full[2].weight=nn.Parameter(de_weight_v)\n",
    "prune.custom_from_mask(decoder_v.full[2], name='weight', mask=de_weight_v_mask);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE u: 2.36334383e-08\n",
      "MSELoss of AE v: 2.15323226e-08\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss\n",
    "input_u=torch.tensor(orig_data_u-u_ref)\n",
    "target_u=decoder_u(encoder_u(input_u))\n",
    "\n",
    "input_v=torch.tensor(orig_data_v-v_ref)\n",
    "target_v=decoder_v(encoder_v(input_v))\n",
    "\n",
    "print(\"MSELoss of AE u: {:.8e}\".format(torch.nn.functional.mse_loss(input_u,target_u).detach().item()))\n",
    "print(\"MSELoss of AE v: {:.8e}\".format(torch.nn.functional.mse_loss(input_v,target_v).detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE u (predictive case): 3.68442592e-08\n",
      "MSELoss of AE v (predictive case): 3.68993867e-08\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (predictive case)\n",
    "if Re==10000:\n",
    "    FOM_solution=pickle.load(open('./data/FOM_high_Re.p','rb'))\n",
    "elif Re==100:\n",
    "    FOM_solution=pickle.load(open('./data/FOM_loq_Re.p','rb'))\n",
    "else:\n",
    "    raise NameError('{} is given for Re, but it must be either 100 or 10000'.format(Re))\n",
    "    \n",
    "u_full=FOM_solution['u'].astype('float32')\n",
    "v_full=FOM_solution['v'].astype('float32')\n",
    "\n",
    "orig_data_u_FOM = u_full[:,free_raveled_indicies]\n",
    "orig_data_v_FOM = v_full[:,free_raveled_indicies]\n",
    "\n",
    "input_u_FOM=torch.tensor(orig_data_u_FOM-u_ref)\n",
    "target_u_FOM=decoder_u(encoder_u(input_u_FOM))\n",
    "\n",
    "input_v_FOM=torch.tensor(orig_data_v_FOM-v_ref)\n",
    "target_v_FOM=decoder_v(encoder_v(input_v_FOM))\n",
    "\n",
    "print(\"MSELoss of AE u (predictive case): {:.8e}\"\\\n",
    "      .format(torch.nn.functional.mse_loss(input_u_FOM,target_u_FOM).detach().item()))\n",
    "print(\"MSELoss of AE v (predictive case): {:.8e}\"\\\n",
    "      .format(torch.nn.functional.mse_loss(input_v_FOM,target_v_FOM).detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # generate mesh grid\n",
    "# [xv,yv]=np.meshgrid(np.linspace(0,1,nx),np.linspace(0,1,ny),indexing='xy')\n",
    "# x=xv.flatten()\n",
    "# y=yv.flatten()\n",
    "\n",
    "# x_free=x[free_raveled_indicies]\n",
    "# y_free=y[free_raveled_indicies]\n",
    "\n",
    "# k=-1\n",
    "\n",
    "# # plot origianl data\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_u[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_u[k].reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Original $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_v[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_v[k].reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Original $v$')\n",
    "# plt.show()\n",
    "\n",
    "# # plot compressed data\n",
    "# plt.figure()\n",
    "# plt.plot(comp_orig_data_u[k])\n",
    "# plt.title('Compressed $u$')\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(comp_orig_data_v[k])\n",
    "# plt.title('Compressed $v$')\n",
    "# plt.show()\n",
    "\n",
    "# # plot restored data\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_orig_data_u[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_orig_data_u[k].reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Restored $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_orig_data_v[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_orig_data_v[k].reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Restored $v$')\n",
    "# plt.show()\n",
    "\n",
    "# # plot relative error\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), (orig_data_u[k]-rest_orig_data_u[k]).reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), (orig_data_u[k]-rest_orig_data_u[k]).reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Difference $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), (orig_data_v[k]-rest_orig_data_v[k]).reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), (orig_data_v[k]-rest_orig_data_v[k]).reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Difference $v$')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights and references   \n",
    "AE={'en_wu1':en_wu1,'en_bu1':en_bu1,'en_wu2':en_wu2,\n",
    "    'de_wu1':de_wu1,'de_bu1':de_bu1,'de_wu2':de_wu2,\n",
    "    'de_wu1T':de_wu1T,'de_wu2T':de_wu2T,'de_wu2_sp':de_wu2_sp,'de_wu2T_sp':de_wu2T_sp,'u_ref':u_ref,\n",
    "    'en_wv1':en_wv1,'en_bv1':en_bv1,'en_wv2':en_wv2,\n",
    "    'de_wv1':de_wv1,'de_bv1':de_bv1,'de_wv2':de_wv2,\n",
    "    'de_wv1T':de_wv1T,'de_wv2T':de_wv2T,'de_wv2_sp':de_wv2_sp,'de_wv2T_sp':de_wv2T_sp,'v_ref':v_ref}\n",
    "\n",
    "pickle.dump(AE,open(file_name_AE,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
