{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.prune as prune\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import torch.utils.data as data_utils\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "from scipy import sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import sys,time\n",
    "import os\n",
    "import copy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "redDim=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set print option\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "# Choose device that is not being used\n",
    "gpu_ids = \"3\"\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=gpu_ids\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given parameters\n",
    "nx = 60\n",
    "ny = 60\n",
    "m = (ny-2)*(nx-2) # 3364\n",
    "nt = 1500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose either Re=10000 or Re=100\n",
    "Re = 10000 \n",
    "    \n",
    "# Choose data normalize option (option 1: -1<=X<=1 option 2: 0<=X<=1)\n",
    "option = 2\n",
    "\n",
    "# Choose activation function (sigmoid, swish)\n",
    "activation = 'sigmoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set batch_size, number of epochs, paitience for early stop\n",
    "batch_size = 480\n",
    "num_epochs = 10000\n",
    "num_epochs_print = num_epochs//100\n",
    "early_stop_patience = num_epochs//50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_mask(m,b,db):\n",
    "    \n",
    "#     M2 = b + db*(m-1)\n",
    "#     mask = np.zeros((m,M2),dtype='int8')\n",
    "    \n",
    "#     block = np.ones(b,dtype='int8')\n",
    "#     ind = np.arange(b)\n",
    "#     for row in range(m):\n",
    "#         col = ind + row*db\n",
    "#         mask[row,col] = block      \n",
    "\n",
    "# #     for row in range(nx-2,m):\n",
    "# #         col = ind + (row-1)*db\n",
    "# #         mask[row-(nx-2),col] = block    \n",
    "# #     for row in range(0,m-(nx-2)):\n",
    "# #         col = ind + (row+1)*db\n",
    "# #         mask[row+(nx-2),col] = block\n",
    "                   \n",
    "#     print(\n",
    "#         \"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "#             m, M2, (1.0-np.count_nonzero(mask)/mask.size)*100\n",
    "#         )\n",
    "#     )\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.spy(mask)\n",
    "#     plt.show()\n",
    "\n",
    "#     return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_2d(m,b,db):\n",
    "    \n",
    "    # local\n",
    "    Mb=sp.diags([np.ones(nx-2),np.ones(nx-2),np.ones(nx-2)],[0,-1,1],(nx-2,nx-2))\n",
    "    M=sp.kron(sp.eye(ny-2),Mb,format=\"csr\")\n",
    "\n",
    "    Ib=sp.eye(nx-2)\n",
    "    N=sp.kron(sp.diags([np.ones(ny-2),np.ones(ny-2),np.ones(ny-2)],[0,-1,1],(ny-2,ny-2)),Ib,format=\"csr\")\n",
    "\n",
    "    local=(M+N).astype('int8')\n",
    "    I,J,V=sp.find(local)\n",
    "    local[I,J]=1\n",
    "    \n",
    "#     col_ind=np.array([],dtype='int')\n",
    "#     row_ind=np.array([],dtype='int')\n",
    "\n",
    "#     for lin_ind in range(m):\n",
    "#         j,i=np.unravel_index(lin_ind,(ny-2,nx-2))\n",
    "\n",
    "#         E=np.ravel_multi_index((j,np.max((i-1,0))),(ny-2,nx-2))\n",
    "#         W=np.ravel_multi_index((j,np.min((i+1,nx-2-1))),(ny-2,nx-2))\n",
    "#         S=np.ravel_multi_index((np.max((j-1,0)),i),(ny-2,nx-2))\n",
    "#         N=np.ravel_multi_index((np.min((j+1,ny-2-1)),i),(ny-2,nx-2))\n",
    "\n",
    "#         col=np.unique([lin_ind,E,W,S,N])\n",
    "#         row=lin_ind*np.ones(col.size,dtype='int')\n",
    "\n",
    "#         col_ind=np.append(col_ind,col)\n",
    "#         row_ind=np.append(row_ind,row)\n",
    "\n",
    "#     data=np.ones(row_ind.size,dtype='int')\n",
    "#     local2=sp.csr_matrix((data,(row_ind,col_ind)),shape=(m,m))\n",
    "\n",
    "    # basis\n",
    "    M2 = int(b + db*(m-1))\n",
    "    basis = np.zeros((m,M2),dtype='int8')\n",
    "\n",
    "    block = np.ones(b,dtype='int8')\n",
    "    ind = np.arange(b)\n",
    "    for row in range(m):\n",
    "        col = ind + row*db\n",
    "        basis[row,col] = block\n",
    "    \n",
    "    # mask\n",
    "    col_ind=np.array([],dtype='int8')\n",
    "    row_ind=np.array([],dtype='int8')\n",
    "    for i in range(m):\n",
    "        col=basis[sp.find(local[i])[1]].sum(axis=0).nonzero()[0]\n",
    "        row=i*np.ones(col.size)\n",
    "\n",
    "        col_ind=np.append(col_ind,col)\n",
    "        row_ind=np.append(row_ind,row)\n",
    "\n",
    "    data=np.ones(row_ind.size,dtype='int8')\n",
    "    mask=sp.csr_matrix((data,(row_ind,col_ind)),shape=(m,M2)).toarray()\n",
    "    \n",
    "    print(\n",
    "        \"Sparsity in {} by {} mask: {:.2f}%\".format(\n",
    "            m, M2, (1.0-np.count_nonzero(mask)/np.prod(mask.shape))*100\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.spy(mask)\n",
    "    plt.show()\n",
    "\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if activation=='sigmoid':\n",
    "    class Encoder(nn.Module):\n",
    "        def __init__(self,m,M1,f):\n",
    "            super(Encoder,self).__init__()\n",
    "            self.full = nn.Sequential(\n",
    "                nn.Linear(m,M1),\n",
    "                nn.Sigmoid(),\n",
    "                nn.Linear(M1,f,bias=False)\n",
    "            )\n",
    "\n",
    "        def forward(self, y):     \n",
    "            y = y.view(-1,m)\n",
    "            T = self.full(y)\n",
    "            T = T.squeeze()\n",
    "\n",
    "            return T\n",
    "\n",
    "    class Decoder(nn.Module):\n",
    "        def __init__(self,f,M2,m):\n",
    "            super(Decoder,self).__init__()\n",
    "            self.full = nn.Sequential(\n",
    "                nn.Linear(f,M2),\n",
    "                nn.Sigmoid(),\n",
    "                nn.Linear(M2,m,bias=False)\n",
    "            )\n",
    "\n",
    "        def forward(self,T):\n",
    "            T = T.view(-1,f)\n",
    "            y = self.full(T)\n",
    "            y = y.squeeze()\n",
    "\n",
    "            return y\n",
    "        \n",
    "elif activation=='swish':\n",
    "    def silu(input):\n",
    "        return input * torch.sigmoid(input)\n",
    "\n",
    "    class SiLU(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "        def forward(self, input):\n",
    "            return silu(input)\n",
    "        \n",
    "    class Encoder(nn.Module):\n",
    "        def __init__(self,m,M1,f):\n",
    "            super(Encoder,self).__init__()\n",
    "            self.full = nn.Sequential(\n",
    "                nn.Linear(m,M1),\n",
    "                SiLU(),\n",
    "                nn.Linear(M1,f,bias=False)\n",
    "            )\n",
    "\n",
    "        def forward(self, y):     \n",
    "            y = y.view(-1,m)\n",
    "            T = self.full(y)\n",
    "            T = T.squeeze()\n",
    "\n",
    "            return T\n",
    "\n",
    "    class Decoder(nn.Module):\n",
    "        def __init__(self,f,M2,m):\n",
    "            super(Decoder,self).__init__()\n",
    "            self.full = nn.Sequential(\n",
    "                nn.Linear(f,M2),\n",
    "                SiLU(),\n",
    "                nn.Linear(M2,m,bias=False)\n",
    "            )\n",
    "\n",
    "        def forward(self,T):\n",
    "            T = T.view(-1,f)\n",
    "            y = self.full(T)\n",
    "            y = y.squeeze()\n",
    "\n",
    "            return y\n",
    "else:\n",
    "    raise NameError('{} is given for option, but it must be either sigmoid or swish'.format(activation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "option 2: 0<=X<=1\n",
      "data shape\n",
      "(6004, 3364)\n",
      "(6004, 3364)\n",
      "maximum abs difference\n",
      "1.1920929e-07\n",
      "1.1920929e-07\n"
     ]
    }
   ],
   "source": [
    "# load snapshot\n",
    "if Re==10000:\n",
    "    file_name_snapshot=\"./data/snapshot_full_high_Re.p\"\n",
    "elif Re==100:\n",
    "    file_name_snapshot=\"./data/snapshot_full_low_Re.p\"\n",
    "else:\n",
    "    raise NameError('{} is given for Re, but it must be either 100 or 10000'.format(Re)) \n",
    "\n",
    "snapshot = pickle.load(open(file_name_snapshot,'rb'))\n",
    "snapshot_u = snapshot['u'].astype('float32')\n",
    "snapshot_v = snapshot['v'].astype('float32')\n",
    "\n",
    "# number of data points\n",
    "ndata = snapshot_u.shape[0]\n",
    "\n",
    "# remove BC\n",
    "multi_index_i,multi_index_j=np.meshgrid(np.arange(nx),np.arange(ny),indexing='xy')\n",
    "full_multi_index=(multi_index_j.flatten(),multi_index_i.flatten())\n",
    "free_multi_index=(multi_index_j[1:-1,1:-1].flatten(),multi_index_i[1:-1,1:-1].flatten())\n",
    "\n",
    "dims=(ny,nx)\n",
    "full_raveled_indicies=np.ravel_multi_index(full_multi_index,dims)\n",
    "free_raveled_indicies=np.ravel_multi_index(free_multi_index,dims)\n",
    "\n",
    "orig_data_u = snapshot_u[:,free_raveled_indicies]\n",
    "orig_data_v = snapshot_v[:,free_raveled_indicies]\n",
    "\n",
    "# normalize data\n",
    "if option==1: # option 1: -1<=X<=1\n",
    "    print(\"option {}: -1<=X<=1\".format(option))\n",
    "#     u_ref = np.mean(orig_data_u,axis=0)\n",
    "#     v_ref = np.mean(orig_data_v,axis=0)   \n",
    "\n",
    "#     u_scale = np.max(orig_data_u,axis=0)-np.min(orig_data_u,axis=0)\n",
    "#     v_scale = np.max(orig_data_v,axis=0)-np.min(orig_data_v,axis=0)   \n",
    "    u_ref = (np.max(orig_data_u,axis=0)+np.min(orig_data_u,axis=0))/2.0\n",
    "    v_ref = (np.max(orig_data_v,axis=0)+np.min(orig_data_v,axis=0))/2.0\n",
    "    \n",
    "    u_scale = (np.max(orig_data_u,axis=0)-np.min(orig_data_u,axis=0))/2.0\n",
    "    v_scale = (np.max(orig_data_v,axis=0)-np.min(orig_data_v,axis=0))/2.0\n",
    "    \n",
    "    u_scale = np.where(u_scale > np.finfo('float32').resolution, u_scale, 1)\n",
    "    v_scale = np.where(v_scale > np.finfo('float32').resolution, v_scale, 1)\n",
    "    \n",
    "    u_scale_reciprocal = np.reciprocal(u_scale)\n",
    "    v_scale_reciprocal = np.reciprocal(v_scale)\n",
    "    \n",
    "    data_u = u_scale_reciprocal*(orig_data_u-u_ref)\n",
    "    data_v = v_scale_reciprocal*(orig_data_v-v_ref)\n",
    "    \n",
    "elif option==2: # option 2: 0<=X<=1\n",
    "    print(\"option {}: 0<=X<=1\".format(option))\n",
    "    u_ref = np.min(orig_data_u,axis=0)\n",
    "    v_ref = np.min(orig_data_v,axis=0)\n",
    "    \n",
    "    u_scale = np.max(orig_data_u,axis=0)-np.min(orig_data_u,axis=0)\n",
    "    v_scale = np.max(orig_data_v,axis=0)-np.min(orig_data_v,axis=0)\n",
    "    \n",
    "    u_scale = np.where(u_scale > np.finfo('float32').resolution, u_scale, 1)\n",
    "    v_scale = np.where(v_scale > np.finfo('float32').resolution, v_scale, 1)\n",
    "    \n",
    "    u_scale_reciprocal = np.reciprocal(u_scale)\n",
    "    v_scale_reciprocal = np.reciprocal(v_scale)\n",
    "    \n",
    "    data_u = u_scale_reciprocal*(orig_data_u-u_ref)\n",
    "    data_v = v_scale_reciprocal*(orig_data_v-v_ref)\n",
    "else:\n",
    "    raise NameError('{} is given for option, but it must be either 1 or 2'.format(option))\n",
    "\n",
    "# check shapes of snapshot\n",
    "print('data shape')\n",
    "print(data_u.shape)\n",
    "print(data_v.shape)\n",
    "\n",
    "# restore data\n",
    "rest_data_u = u_ref + u_scale*data_u\n",
    "rest_data_v = v_ref + v_scale*data_v\n",
    "\n",
    "# check precision\n",
    "print('maximum abs difference')\n",
    "print(np.max(np.abs(orig_data_u-rest_data_u)))\n",
    "print(np.max(np.abs(orig_data_v-rest_data_v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # generate mesh grid\n",
    "# [xv,yv]=np.meshgrid(np.linspace(0,1,nx),np.linspace(0,1,ny),indexing='xy')\n",
    "# x=xv.flatten()\n",
    "# y=yv.flatten()\n",
    "\n",
    "# x_free=x[free_raveled_indicies]\n",
    "# y_free=y[free_raveled_indicies]\n",
    "\n",
    "# k=0\n",
    "\n",
    "# # plot original data\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_u[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_u[k].reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Original $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_v[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_v[k].reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Original $v$')\n",
    "# plt.show()\n",
    "\n",
    "# # plot preprocessed data\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), data_u[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), data_u[k].reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Preprocessed $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), data_v[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), data_v[k].reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Preprocessed $v$')\n",
    "# plt.show()\n",
    "\n",
    "# # plot restored data\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_data_u[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_data_u[k].reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Restored $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_data_v[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_data_v[k].reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Restored $v$')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5404, 3364]) torch.Size([600, 3364])\n",
      "torch.Size([5404, 3364]) torch.Size([600, 3364])\n"
     ]
    }
   ],
   "source": [
    "# define testset and trainset indices\n",
    "nset = round(ndata/(nt+1))\n",
    "test_ind = np.array([],dtype='int')\n",
    "for foo in range(nset):\n",
    "    rand_ind = np.random.permutation(np.arange(foo*(nt+1)+1,(foo+1)*(nt+1)))[:int(0.1*(nt+1))]\n",
    "    test_ind = np.append(test_ind,rand_ind)\n",
    "train_ind = np.setdiff1d(np.arange(ndata),test_ind)\n",
    "\n",
    "# set trainset and testset\n",
    "trainset_u = data_u[train_ind]\n",
    "trainset_v = data_v[train_ind]\n",
    "testset_u = data_u[test_ind] \n",
    "testset_v = data_v[test_ind] \n",
    "\n",
    "# set dataset\n",
    "dataset_u = {'train':data_utils.TensorDataset(torch.tensor(trainset_u,dtype=torch.float32)),\n",
    "           'test':data_utils.TensorDataset(torch.tensor(testset_u,dtype=torch.float32))}\n",
    "dataset_v = {'train':data_utils.TensorDataset(torch.tensor(trainset_v,dtype=torch.float32)),\n",
    "           'test':data_utils.TensorDataset(torch.tensor(testset_v,dtype=torch.float32))}\n",
    "\n",
    "print(dataset_u['train'].tensors[0].shape, dataset_u['test'].tensors[0].shape)\n",
    "print(dataset_v['train'].tensors[0].shape, dataset_v['test'].tensors[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5404, 3364) (600, 3364)\n",
      "(5404, 3364) (600, 3364)\n"
     ]
    }
   ],
   "source": [
    "# compute dataset shapes\n",
    "dataset_u_shapes = {'train':trainset_u.shape,\n",
    "                    'test':testset_u.shape}\n",
    "dataset_v_shapes = {'train':trainset_v.shape,\n",
    "                    'test':testset_v.shape}\n",
    "\n",
    "print(dataset_u_shapes['train'],dataset_u_shapes['test'])\n",
    "print(dataset_v_shapes['train'],dataset_v_shapes['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data loaders\n",
    "train_loader_u = DataLoader(dataset=dataset_u['train'], \n",
    "                          batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "train_loader_v = DataLoader(dataset=dataset_v['train'], \n",
    "                          batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader_u = DataLoader(dataset=dataset_u['test'], \n",
    "                         batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "test_loader_v = DataLoader(dataset=dataset_v['test'], \n",
    "                         batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "data_loaders_u = {'train':train_loader_u, 'test':test_loader_u}\n",
    "data_loaders_v = {'train':train_loader_v, 'test':test_loader_v}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity in 3364 by 33730 mask: 99.06%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAABECAYAAABte+WAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAALRklEQVR4nO3db4xcVRnH8e/PAgUF+VtI0xaBUomlKaXd1CKCIih/fAEYwJYgGCUYBYQXvmiDIqK80AhGQBEUIoLKn6DCCxErikhigC0U2korRQtWKi0iUJUghccX5yw7TGdm73Z3Zu6d+X2Szdw9e6dznt7MOTPnOfccRQRmZtYf3tbtCpiZWee40Tcz6yNu9M3M+ogbfTOzPuJG38ysj7jRNzPrI6Vt9CUdJ2mNpLWSFne7PvUkrZO0QtJySYO5bA9JSyU9mR93rzl/SY5ljaRja8rn5X9nraQrJanN9b5B0kZJK2vKxq3ekiZKujWXPyhpvw7GcYmkv+drslzSCWWOQ9I0Sb+T9ISkVZIuyOWVuh4t4qjM9ZC0o6SHJD2WY/hKLq/UtSgkIkr3A0wAngIOAHYAHgNmdrtedXVcB+xVV/YNYHE+Xgx8PR/PzDFMBPbPsU3If3sIOAwQcDdwfJvrfSQwF1jZjnoDnwO+l48XArd2MI5LgC80OLeUcQCTgbn5eBfgz7mulboeLeKozPXIr7dzPt4eeBBYULVrUSjWbrxogQtwGHBPze9LgCXdrlddHdexdaO/BpicjycDaxrVH7gnxzgZWF1Tvgi4tgN134+3NpbjVu+hc/LxdsDzgDoUR7NGptRx1Lz+ncCHq3o9GsRRyesBvB14BHhv1a9Fo5+yDu9MAf5W8/v6XFYmAfxa0jJJ5+SyfSJiA0B+3DuXN4tnSj6uL++08az3m8+JiC3AS8Cebav51s6T9Hge/hn6Kl76OPJX/UNJnzArez3q4oAKXQ9JEyQtBzYCSyOi0teimbI2+o3Gtcu2XsThETEXOB44V9KRLc5tFk/Z49yWenczpmuA6cAcYANw+Qh1KkUcknYG7gAujIiXW53apE5ljaNS1yMiXo+IOcBUYL6kWS1OL2UMRZS10V8PTKv5fSrwbJfq0lBEPJsfNwI/B+YDz0maDJAfN+bTm8WzPh/Xl3faeNb7zedI2g7YFXihbTWvERHP5TfuG8D3SdfkLXWqq2/X45C0Pamh/HFE/CwXV+56NIqjitcj1/tF4D7gOCp4LUZS1kb/YWCGpP0l7UBKetzV5Tq9SdI7JO0ydAx8BFhJquNZ+bSzSGOb5PKFOXu/PzADeCh/XdwsaUHO8J9Z85xOGs961/5bpwC/jTyI2W5Db87sZNI1GapT6eLIr3k98EREXFHzp0pdj2ZxVOl6SJokabd8vBNwDLCail2LQjqdRBhFMuUE0iyAp4CLul2furodQMrcPwasGqofaXzuXuDJ/LhHzXMuyrGsoWaGDjBAejM8BVxN+5NsPyV91X6N9Mnj0+NZb2BH4HZgLWkWwwEdjOMmYAXwOOkNNrnMcQDvJ329fxxYnn9OqNr1aBFHZa4HMBt4NNd1JXDxeL+nO/XeGOlnqDJmZtYHyjq8Y2ZmbeBG38ysj7jRNzPrI270zcz6SMcbfZV8ITUzs17W0UZf0gTgO6S7WGcCiyTNHOE557T6exX0QgzgOMqkF2KA3oijajF0+pP+fGBtRPwlIv4H3AKcOMJzKvUf2kQvxACOo0x6IQbojTgqFUOnG/0qLKRmZtazOnpzlqRTgWMj4uz8+yeA+RFxft1555B7z4kTJ86bNavVukewbNky5s2bV6i82bnttGnTJiZNmtTR12wHx1EevRAD9EYcZY1h2bJlz0fEVhXbbiz/qKR1wGbgdWBLRAxI2gO4lbTW+TrgtIj4V37Kh4DTJR0BfJ4mC4xFxHXAdQADAwMxODg4lmrW1pf6Ti5vatOw3Hcrm1lVSXq6Ufl4DO8cFRFzImIg/74YuDciZpDWqlicKzATeB/wD+Bs4Lt0eCG1Ro14zXoZb2rVOdRrVm5mVkbtGNM/EbgxH98InFRTfgtwHmlFvsnAHyNiVRvqMCbNOodarb4hNOLOwczKYKyN/qh3j4qIX0bEu0mrJP5mjK/fNc2Gftw5mFmZjWlMn7R71LOS9gaWSlrd4tzCu8bUJnL33XffMVaxu0bTORQdampVbmbWyoif9PPelhslrawp20PSUuD3+fE1hnePek3SX/Ndt4sY3mnmDeCb+U7cK2mxS1REXBcRAxExUMaseDu045uDvzWYWb0iwzs/JG0bVmsxcD8wl5Ss/RJp96iXSZ/ef5CfczXDidoPkmb6HEzasGA2aSMBG4XRfnOoL3PnYNbfRhzeiYj7lXa4r3UiaRuwB/K/cSBwKWmXmWtJUzM/mc9dmrdN257UgfwJ2Al4NCJeH2sA1ljRZLSHlMz6y7YmcveJiAcj4pCIOBj4b0RcRkrWromIo/OUzV8A78zl6yPisoiYDnycNNxjXeRktFn/Ge8pm82StYWTuJASuZIGJQ1u2rRp3Cpn28adg1nvKJTIBQZJQzhDtkjaIGl5TvD+J5evB87Iydo1wCGkZO16YLqkFZLWkjYUbpjEhf5M5PYCdw5m5Vc0kXtWXdka4JGImAPcDPwkl68EPgAcSrrr9hBgMM/XnwR8G5gBzCN1BNaHxtI5OBltNjZF5ul/FjgamChpPfBlUgL3Y5KeBJ4BTs3nziLN6lkObAEeBwbyGj3PAxcCS4BHSFM2zZoqkowGr6lkNhojftKPiEWk+ferImJqRFwPvEKajfMK8DTD4/NTgJsiYnpEHERq/Kfkn7URMSsncr+Gl1S2cVJkTSUPKZkl25rIvQaYDswBNgCX53Incq2UnG8wS4okcqeR1sk5UNIqSRdExHPArsA9wOnAaZJ2J43TT5O0JCdsFwLTcvlUSfMkrQBuB/ZTk3eME7nWLe4crNcV+aS/hTQcsxZYAJwr6UjyEsrAlcBT+fe7SEnfRcBHgX8C55OWYtgM/Ii0ps6jwKtsfaevWSW4c7CqKtLoX0FaVuEg4AnS9MyLgQtId+UelR9PysskP00ar78L+Ayps5gPfJE07fNmUidxOcPLLpv1JM9UsrIpsgzDoqHjvBzD/aRpmc9ExMyavw0tofwkKZl7cy4/hdQJrAP+EBHH5PIjcDLXDPBMJeucwolcSTsDdwAXRsTLrU5tUDaqZK4TuWaNeaaSjVWhRK6k+0jbHE4hJWahjXflOpFrtu2cb7BWiiZy/00a159BSuTOxHflmlWaO4f+VOSO3OmkmTgrSGvi7wOcjO/KNesL3v2ttxS5I/eBiFBEzCbNtnkJuArflWtmNTxTqRrGksht2125TuSa9a4iyWhoPVOpnjuH4ookcneU9DAp6TqFNEYPaV/cX5HG9o8k3bgFTuSa2Tgouvtbq/J67hyKfdJ/lTT3/gbSzJ3jJC0Avgrcm3fIeonhT/JO5JpZRzgZPXpFErmHk5ZVWEHaTGUGcBhwBvCspNNJwzvb5/OdyDWzUnEyelihRC6pc3iDNIZ/VUR8K/0p3hMRsyPiWNKm6OBErplVVDu+OZTtW0OhRG5EvJ7n408F5kua1eJ0J3LNrKeN9ptDfVk3O4dRracfES8C95FWx3xO0mSA/Lgxn7ae4bt2IXUUQ4ncqQ3KG72OE7lmVnllnKlUZPbOJEm75eOdgGOA1Qwvo0x+vDMf3wUslDRR0v6kHMBDOZG7WdKCvI7+mTXPMTPrW+2YqdSMRkpCSJoN3AhMIHUSt0XEpZL2BG4D9iXfkRsRL+TnXAR8ipTIvTAi7s7lA6SN1ncC7gbOjxEqIGkzaVpole1FSmJXneMoj16IAXojjrLG8K6I2GqoZMRGv9skDUbEQLfrMRa9EAM4jjLphRigN+KoWgzbukeumZlVkBt9M7M+UoVG/7puV2Ac9EIM4DjKpBdigN6Io1IxlH5M38zMxk8VPumbmdk4caNvZtZH3OibmfURN/pmZn3Ejb6ZWR/5P71+ZTg7BJElAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder parameters:2.29088400e+07(0.08534GB) Decoder parameters:2.44665000e+06(0.4279GB)\n",
      "Data size:2.01974560e+07(0.07524GB)\n"
     ]
    }
   ],
   "source": [
    "# set the number of nodes in each layer\n",
    "a = 2\n",
    "b = int(100)\n",
    "db = int(10)\n",
    "\n",
    "M1 = int(a*m) # encoder hidden layer\n",
    "M2 = b + (m-1)*db # decoder hidden layer\n",
    "\n",
    "f = redDim # latent dimension\n",
    "\n",
    "# sparsity and shape of mask\n",
    "mask_2d=create_mask_2d(m,b,db)\n",
    "\n",
    "# number of parameters and memory\n",
    "en_para=m*M1+M1+M1*f\n",
    "de_para=f*M2+M2+np.count_nonzero(mask_2d)\n",
    "print('Encoder parameters:{:.8e}({:.4}GB)'.format(en_para,en_para*4/2**30),\\\n",
    "      'Decoder parameters:{:.8e}({:.4}GB)'.format(de_para,(f*M2+M2+M2*m)*4/2**30))\n",
    "\n",
    "# data size\n",
    "data_size=np.prod(orig_data_u.shape)\n",
    "print('Data size:{:.8e}({:.4}GB)'.format(data_size,data_size*4/2**30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set file names\n",
    "if Re==10000:\n",
    "    file_name_AE_u=\"./model/AE_u_high_Re_v3_red-dim_{}pkl\".format(redDim)\n",
    "    file_name_AE_v=\"./model/AE_v_high_Re_v3_red-dim_{}.pkl\".format(redDim)\n",
    "    file_name_AE=\"./model/AE_high_Re_v3_red-dim_{}.p\".format(redDim)\n",
    "    \n",
    "    PATH_u = './checkpoint_u_high_Re_v3_red-dim_{}.tar'.format(redDim)\n",
    "    PATH_v = './checkpoint_v_high_Re_v3_red-dim_{}.tar'.format(redDim)\n",
    "elif Re==100:\n",
    "    file_name_AE_u=\"./model/AE_u_low_Re_v3_red-dim_{}.pkl\".format(redDim)\n",
    "    file_name_AE_v=\"./model/AE_v_low_Re_v3_red-dim_{}.pkl\".format(redDim)\n",
    "    file_name_AE=\"./model/AE_low_Re_v_3_red-dim_{}.p\".format(redDim)\n",
    "    \n",
    "    PATH_u = './checkpoint_u_low_Re_v3_red-dim_{}.tar'.format(redDim)\n",
    "    PATH_v = './checkpoint_v_low_Re_v3_red-dim_{}.tar'.format(redDim)\n",
    "else:\n",
    "    raise NameError('{} is given for Re, but it must be either 100 or 10000'.format(Re))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------checkpoint not restored--------\n",
      "\n",
      "\n",
      "Start first training... m=3364, f=40, a=2, b=100, db=10\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "try:\n",
    "    checkpoint = torch.load(PATH_u, map_location=device)\n",
    "    \n",
    "    encoder_u = Encoder(m,M1,f).to(device)\n",
    "    decoder_u = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    prune.custom_from_mask(decoder_u.full[2], name='weight', mask=torch.tensor(mask_2d).to(device))    \n",
    "       \n",
    "    optimizer = torch.optim.Adam(list(encoder_u.parameters()) + list(decoder_u.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    encoder_u.load_state_dict(checkpoint['encoder_u_state_dict'])\n",
    "    decoder_u.load_state_dict(checkpoint['decoder_u_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    last_epoch = checkpoint['epoch']\n",
    "    loss_hist = checkpoint['loss_hist']\n",
    "    best_loss = checkpoint['best_loss']\n",
    "    early_stop_counter = checkpoint['early_stop_counter']\n",
    "    best_encoder_u_wts = checkpoint['best_encoder_u_wts']\n",
    "    best_decoder_u_wts = checkpoint['best_decoder_u_wts']\n",
    "    \n",
    "    print(\"\\n--------checkpoint restored--------\\n\")\n",
    "\n",
    "    # resume training\n",
    "    print(\"\")\n",
    "    print('Re-start {}th training... m={}, f={},a={}, b={}, db={}'.format(\n",
    "        last_epoch+1, m, f, a, b, db))\n",
    "except:\n",
    "    encoder_u = Encoder(m,M1,f).to(device)\n",
    "    decoder_u = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    prune.custom_from_mask(decoder_u.full[2], name='weight', mask=torch.tensor(mask_2d).to(device))\n",
    "\n",
    "    optimizer = torch.optim.Adam(list(encoder_u.parameters()) + list(decoder_u.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    last_epoch = 0\n",
    "    loss_hist = {'train':[],'test':[]}\n",
    "    best_loss = float(\"inf\")\n",
    "    early_stop_counter = 1\n",
    "    best_encoder_u_wts = copy.deepcopy(encoder_u.state_dict())\n",
    "    best_decoder_u_wts = copy.deepcopy(decoder_u.state_dict())\n",
    "    \n",
    "    print(\"\\n--------checkpoint not restored--------\\n\")\n",
    "\n",
    "    # start training\n",
    "    print(\"\")\n",
    "    print('Start first training... m={}, f={}, a={}, b={}, db={}'\\\n",
    "          .format(m, f, a, b, db))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 3.2485333442611235e-06\n",
      "test MSELoss: 3.3810509648901644e-06\n",
      "\n",
      "Epoch 200/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 2.0444157496841258e-06\n",
      "test MSELoss: 2.137788305844879e-06\n",
      "\n",
      "Epoch 300/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 1.1858055739497816e-06\n",
      "test MSELoss: 1.2415569926815807e-06\n",
      "\n",
      "Epoch 400/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 6.913127378025796e-07\n",
      "test MSELoss: 7.354643344115175e-07\n",
      "\n",
      "Epoch 500/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 4.676644718985563e-07\n",
      "test MSELoss: 4.921507411381754e-07\n",
      "\n",
      "Epoch 600/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 4.3230672288173473e-07\n",
      "test MSELoss: 4.547259607079468e-07\n",
      "\n",
      "Epoch 700/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 3.8491661793250995e-07\n",
      "test MSELoss: 4.037352653085691e-07\n",
      "\n",
      "Epoch 800/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 3.3227135083788565e-07\n",
      "test MSELoss: 3.4998953992726454e-07\n",
      "\n",
      "Epoch 900/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.8314392217536273e-07\n",
      "test MSELoss: 2.9687685696444534e-07\n",
      "\n",
      "Epoch 1000/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.4056343423805834e-07\n",
      "test MSELoss: 2.5330331823170125e-07\n",
      "\n",
      "Epoch 1100/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.0799634398280063e-07\n",
      "test MSELoss: 2.187178552048863e-07\n",
      "\n",
      "Epoch 1200/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.825877391257105e-07\n",
      "test MSELoss: 1.9202116448013838e-07\n",
      "\n",
      "Epoch 1300/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.6133850950351313e-07\n",
      "test MSELoss: 1.71084624867035e-07\n",
      "\n",
      "Epoch 1400/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.4479116184757972e-07\n",
      "test MSELoss: 1.5203731891233473e-07\n",
      "\n",
      "Epoch 1500/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.3216684058128215e-07\n",
      "test MSELoss: 1.38942070293524e-07\n",
      "\n",
      "Epoch 1600/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.2027033942067337e-07\n",
      "test MSELoss: 1.2686410286733007e-07\n",
      "\n",
      "Epoch 1700/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.1073422096767753e-07\n",
      "test MSELoss: 1.1667299872897275e-07\n",
      "\n",
      "Epoch 1800/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.0283571566068289e-07\n",
      "test MSELoss: 1.0840231823294744e-07\n",
      "\n",
      "Epoch 1900/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 9.597340492326389e-08\n",
      "test MSELoss: 1.0132327474821067e-07\n",
      "\n",
      "Epoch 2000/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 8.939386151525817e-08\n",
      "test MSELoss: 9.460937349103915e-08\n",
      "\n",
      "Epoch 2100/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 8.405525420921637e-08\n",
      "test MSELoss: 8.802069118019062e-08\n",
      "\n",
      "Epoch 2200/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 7.959814503253782e-08\n",
      "test MSELoss: 8.487975691195971e-08\n",
      "\n",
      "Epoch 2300/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 7.452251864440015e-08\n",
      "test MSELoss: 7.933353742828331e-08\n",
      "\n",
      "Epoch 2400/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 7.059757653477607e-08\n",
      "test MSELoss: 7.41981040164319e-08\n",
      "\n",
      "Epoch 2500/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 6.685841152458837e-08\n",
      "test MSELoss: 7.072936227814353e-08\n",
      "\n",
      "Epoch 2600/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 6.68547396595722e-08\n",
      "test MSELoss: 7.072260785889739e-08\n",
      "\n",
      "Epoch 2671/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 6.68522949718105e-08\n",
      "test MSELoss: 7.071824796867076e-08\n",
      "\n",
      "Early stopping: 2671th training complete in 1h 26m 28s\n",
      "----------\n",
      "Best train MSELoss: 6.687479725542289e-08\n",
      "Best test MSELoss: 7.07461040860835e-08\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "since = time.time()\n",
    "\n",
    "for epoch in range(last_epoch+1,num_epochs+1):   \n",
    "\n",
    "    if epoch%num_epochs_print == 0:\n",
    "        print()\n",
    "        print('Epoch {}/{}, Learning rate {}'.format(\n",
    "            epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "        print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and test phase\n",
    "    for phase in ['train', 'test']:\n",
    "        if phase == 'train':\n",
    "            encoder_u.train()  # Set model to training mode\n",
    "            decoder_u.train()  # Set model to training mode\n",
    "        else:\n",
    "            encoder_u.eval()   # Set model to evaluation mode\n",
    "            decoder_u.eval()   # Set model to evaluation mode\n",
    "            \n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Iterate over data\n",
    "        for data, in data_loaders_u[phase]:\n",
    "            inputs = data.to(device)\n",
    "            targets = data.to(device)\n",
    "\n",
    "            if phase == 'train':\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = decoder_u(encoder_u(inputs))\n",
    "                loss = loss_func(outputs, targets)\n",
    "\n",
    "                # backward\n",
    "                loss.backward()\n",
    "\n",
    "                # optimize\n",
    "                optimizer.step()  \n",
    "\n",
    "                # add running loss\n",
    "                running_loss += loss.item()*inputs.shape[0]\n",
    "            else:\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    outputs = decoder_u(encoder_u(inputs))\n",
    "                    running_loss += loss_func(outputs,targets).item()*inputs.shape[0]\n",
    "\n",
    "        # compute epoch loss\n",
    "        epoch_loss = running_loss / dataset_u_shapes[phase][0]\n",
    "        loss_hist[phase].append(epoch_loss)\n",
    "            \n",
    "        # update learning rate\n",
    "        if phase == 'train':\n",
    "            scheduler.step(epoch_loss)\n",
    "\n",
    "        if epoch%num_epochs_print == 0:\n",
    "            print('{} MSELoss: {}'.format(\n",
    "                phase, epoch_loss))\n",
    "\n",
    "    # deep copy the model\n",
    "    if round(loss_hist['test'][-1],10) < round(best_loss,10):\n",
    "        best_loss = loss_hist['test'][-1]\n",
    "        early_stop_counter = 1\n",
    "        best_encoder_u_wts = copy.deepcopy(encoder_u.state_dict())\n",
    "        best_decoder_u_wts = copy.deepcopy(decoder_u.state_dict())\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= early_stop_patience:  \n",
    "            break\n",
    "    \n",
    "    # save checkpoint every num_epoch_print\n",
    "    if epoch%num_epochs_print== 0:\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'encoder_u_state_dict': encoder_u.state_dict(),\n",
    "                    'decoder_u_state_dict': decoder_u.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss_hist': loss_hist,\n",
    "                    'best_loss': best_loss,\n",
    "                    'early_stop_counter': early_stop_counter,\n",
    "                    'best_encoder_u_wts': best_encoder_u_wts,\n",
    "                    'best_decoder_u_wts': best_decoder_u_wts,\n",
    "                    }, PATH_u)        \n",
    "\n",
    "print()\n",
    "print('Epoch {}/{}, Learning rate {}'\\\n",
    "      .format(epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "print('-' * 10)\n",
    "print('train MSELoss: {}'.format(loss_hist['train'][-1]))\n",
    "print('test MSELoss: {}'.format(loss_hist['test'][-1]))\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "\n",
    "# load best model weights\n",
    "encoder_u.load_state_dict(best_encoder_u_wts)\n",
    "decoder_u.load_state_dict(best_decoder_u_wts)\n",
    "\n",
    "# compute best train MSELoss\n",
    "encoder_u.to('cpu').eval()\n",
    "decoder_u.to('cpu').eval()\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    train_inputs = torch.tensor(data_u[train_ind])\n",
    "    train_targets = torch.tensor(data_u[train_ind])\n",
    "    train_outputs = decoder_u(encoder_u(train_inputs))\n",
    "    train_loss = loss_func(train_outputs,train_targets).item()\n",
    "\n",
    "# print out training time and best results\n",
    "print()\n",
    "if epoch < num_epochs:\n",
    "    print('Early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "else:\n",
    "    print('No early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "print('-' * 10)\n",
    "print('Best train MSELoss: {}'.format(train_loss))\n",
    "print('Best test MSELoss: {}'.format(best_loss))\n",
    "\n",
    "# # save models\n",
    "# print()\n",
    "# print(\"Saving after {}th training to\".format(epoch),file_name_AE_u)\n",
    "# torch.save((encoder_u,decoder_u),file_name_AE_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "checkpoint removed\n"
     ]
    }
   ],
   "source": [
    "# delete checkpoint\n",
    "try:\n",
    "    os.remove(PATH_u)\n",
    "    print()\n",
    "    print(\"checkpoint removed\")\n",
    "except:\n",
    "    print(\"no checkpoint exists\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and test loss\n",
    "plt.figure()\n",
    "plt.semilogy(loss_hist['train'])\n",
    "plt.semilogy(loss_hist['test'])\n",
    "plt.legend(['train','test'])\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# release gpu memory\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------checkpoint not restored--------\n",
      "\n",
      "\n",
      "Start first training... m=3364, f=40, a=2, b=100, db=10\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "try:\n",
    "    checkpoint = torch.load(PATH_v, map_location=device)\n",
    "    \n",
    "    encoder_v = Encoder(m,M1,f).to(device)\n",
    "    decoder_v = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    prune.custom_from_mask(decoder_v.full[2], name='weight', mask=torch.tensor(mask_2d).to(device))    \n",
    "       \n",
    "    optimizer = torch.optim.Adam(list(encoder_v.parameters()) + list(decoder_v.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    encoder_v.load_state_dict(checkpoint['encoder_v_state_dict'])\n",
    "    decoder_v.load_state_dict(checkpoint['decoder_v_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    last_epoch = checkpoint['epoch']\n",
    "    loss_hist = checkpoint['loss_hist']\n",
    "    best_loss = checkpoint['best_loss']\n",
    "    early_stop_counter = checkpoint['early_stop_counter']\n",
    "    best_encoder_v_wts = checkpoint['best_encoder_v_wts']\n",
    "    best_decoder_v_wts = checkpoint['best_decoder_v_wts']\n",
    "    \n",
    "    print(\"\\n--------checkpoint restored--------\\n\")\n",
    "    \n",
    "    # resume training\n",
    "    print(\"\")\n",
    "    print('Re-start {}th training... m={}, f={}, a={}, b={}, db={}'.format(\n",
    "        last_epoch+1, m, f, a, b, db))\n",
    "except:\n",
    "    encoder_v = Encoder(m,M1,f).to(device)\n",
    "    decoder_v = Decoder(f,M2,m).to(device)\n",
    "    \n",
    "    # Prune\n",
    "    prune.custom_from_mask(decoder_v.full[2], name='weight', mask=torch.tensor(mask_2d).to(device))\n",
    "\n",
    "    optimizer = torch.optim.Adam(list(encoder_v.parameters()) + list(decoder_v.parameters()), lr=0.001)\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,patience=10) \n",
    "    \n",
    "    loss_func = nn.MSELoss(reduction='mean')\n",
    "    \n",
    "    last_epoch = 0\n",
    "    loss_hist = {'train':[],'test':[]}\n",
    "    best_loss = float(\"inf\")\n",
    "    early_stop_counter = 1\n",
    "    best_encoder_v_wts = copy.deepcopy(encoder_v.state_dict())\n",
    "    best_decoder_v_wts = copy.deepcopy(decoder_v.state_dict())\n",
    "    \n",
    "    print(\"\\n--------checkpoint not restored--------\\n\")\n",
    "\n",
    "    # start training\n",
    "    print(\"\")\n",
    "    print('Start first training... m={}, f={}, a={}, b={}, db={}'.format(\n",
    "        m, f, a, b, db))\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 100/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 1.722192601499101e-06\n",
      "test MSELoss: 1.8258946056448623e-06\n",
      "\n",
      "Epoch 200/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 1.2254382091197043e-06\n",
      "test MSELoss: 1.295603715334437e-06\n",
      "\n",
      "Epoch 300/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 8.003348809559236e-07\n",
      "test MSELoss: 8.387875027437986e-07\n",
      "\n",
      "Epoch 400/10000, Learning rate 0.0001\n",
      "----------\n",
      "train MSELoss: 5.067955286084895e-07\n",
      "test MSELoss: 5.352457947083167e-07\n",
      "\n",
      "Epoch 500/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 3.0391004094810183e-07\n",
      "test MSELoss: 3.2002896546146074e-07\n",
      "\n",
      "Epoch 600/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.8602153715692893e-07\n",
      "test MSELoss: 3.0051030535105384e-07\n",
      "\n",
      "Epoch 700/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.621520405501777e-07\n",
      "test MSELoss: 2.774405231775745e-07\n",
      "\n",
      "Epoch 800/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.3192828747149644e-07\n",
      "test MSELoss: 2.4695337401681173e-07\n",
      "\n",
      "Epoch 900/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 2.0113066161228308e-07\n",
      "test MSELoss: 2.1267244392220165e-07\n",
      "\n",
      "Epoch 1000/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.739555077512313e-07\n",
      "test MSELoss: 1.8458796944287314e-07\n",
      "\n",
      "Epoch 1100/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.5144409094557676e-07\n",
      "test MSELoss: 1.6012050139124767e-07\n",
      "\n",
      "Epoch 1200/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.32655144472559e-07\n",
      "test MSELoss: 1.402900409175345e-07\n",
      "\n",
      "Epoch 1300/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.1870205087369835e-07\n",
      "test MSELoss: 1.267071070287784e-07\n",
      "\n",
      "Epoch 1400/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 1.0725477385382789e-07\n",
      "test MSELoss: 1.1418002259233617e-07\n",
      "\n",
      "Epoch 1500/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 9.747560095708396e-08\n",
      "test MSELoss: 1.0305854090120192e-07\n",
      "\n",
      "Epoch 1600/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 8.902982891877393e-08\n",
      "test MSELoss: 9.447105497883967e-08\n",
      "\n",
      "Epoch 1700/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 8.287065633601345e-08\n",
      "test MSELoss: 8.805830304936535e-08\n",
      "\n",
      "Epoch 1800/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 7.654948993395669e-08\n",
      "test MSELoss: 8.071190222835867e-08\n",
      "\n",
      "Epoch 1900/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 7.177931968814646e-08\n",
      "test MSELoss: 7.557123353763018e-08\n",
      "\n",
      "Epoch 2000/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 6.688632383641203e-08\n",
      "test MSELoss: 7.106014692226381e-08\n",
      "\n",
      "Epoch 2100/10000, Learning rate 1e-05\n",
      "----------\n",
      "train MSELoss: 6.343763275684726e-08\n",
      "test MSELoss: 6.697070347172484e-08\n",
      "\n",
      "Epoch 2200/10000, Learning rate 1.0000000000000002e-06\n",
      "----------\n",
      "train MSELoss: 5.65961916693792e-08\n",
      "test MSELoss: 5.993656060354624e-08\n",
      "\n",
      "Epoch 2300/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 5.6219657720363454e-08\n",
      "test MSELoss: 5.971434120510821e-08\n",
      "\n",
      "Epoch 2400/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 5.6216518778177253e-08\n",
      "test MSELoss: 5.970910308406018e-08\n",
      "\n",
      "Epoch 2421/10000, Learning rate 1.0000000000000004e-08\n",
      "----------\n",
      "train MSELoss: 5.621597349579563e-08\n",
      "test MSELoss: 5.971335852450465e-08\n",
      "\n",
      "Early stopping: 2421th training complete in 1h 16m 41s\n",
      "----------\n",
      "Best train MSELoss: 5.62564217432282e-08\n",
      "Best test MSELoss: 5.971107910340834e-08\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "since = time.time()\n",
    "\n",
    "for epoch in range(last_epoch+1,num_epochs+1):   \n",
    "\n",
    "    if epoch%num_epochs_print == 0:\n",
    "        print()\n",
    "        print('Epoch {}/{}, Learning rate {}'.format(\n",
    "            epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "        print('-' * 10)\n",
    "\n",
    "    # Each epoch has a training and test phase\n",
    "    for phase in ['train', 'test']:\n",
    "        if phase == 'train':\n",
    "            encoder_v.train()  # Set model to training mode\n",
    "            decoder_v.train()  # Set model to training mode\n",
    "        else:\n",
    "            encoder_v.eval()   # Set model to evaluation mode\n",
    "            decoder_v.eval()   # Set model to evaluation mode\n",
    "            \n",
    "        running_loss = 0.0\n",
    "\n",
    "        # Iterate over data\n",
    "        for data, in data_loaders_v[phase]:\n",
    "            inputs = data.to(device)\n",
    "            targets = data.to(device)\n",
    "\n",
    "            if phase == 'train':\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                outputs = decoder_v(encoder_v(inputs))\n",
    "                loss = loss_func(outputs, targets)\n",
    "\n",
    "                # backward\n",
    "                loss.backward()\n",
    "\n",
    "                # optimize\n",
    "                optimizer.step()  \n",
    "\n",
    "                # add running loss\n",
    "                running_loss += loss.item()*inputs.shape[0]\n",
    "            else:\n",
    "                with torch.set_grad_enabled(False):\n",
    "                    outputs = decoder_v(encoder_v(inputs))\n",
    "                    running_loss += loss_func(outputs,targets).item()*inputs.shape[0]\n",
    "\n",
    "        # compute epoch loss\n",
    "        epoch_loss = running_loss / dataset_v_shapes[phase][0]\n",
    "        loss_hist[phase].append(epoch_loss)\n",
    "            \n",
    "        # update learning rate\n",
    "        if phase == 'train':\n",
    "            scheduler.step(epoch_loss)\n",
    "\n",
    "        if epoch%num_epochs_print == 0:\n",
    "            print('{} MSELoss: {}'.format(\n",
    "                phase, epoch_loss))\n",
    "\n",
    "    # deep copy the model\n",
    "    if round(loss_hist['test'][-1],10) < round(best_loss,10):\n",
    "        best_loss = loss_hist['test'][-1]\n",
    "        early_stop_counter = 1\n",
    "        best_encoder_v_wts = copy.deepcopy(encoder_v.state_dict())\n",
    "        best_decoder_v_wts = copy.deepcopy(decoder_v.state_dict())\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= early_stop_patience:  \n",
    "            break\n",
    "    \n",
    "    # save checkpoint every num_epoch_print\n",
    "    if epoch%num_epochs_print== 0:\n",
    "        torch.save({\n",
    "                    'epoch': epoch,\n",
    "                    'encoder_v_state_dict': encoder_v.state_dict(),\n",
    "                    'decoder_v_state_dict': decoder_v.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss_hist': loss_hist,\n",
    "                    'best_loss': best_loss,\n",
    "                    'early_stop_counter': early_stop_counter,\n",
    "                    'best_encoder_v_wts': best_encoder_v_wts,\n",
    "                    'best_decoder_v_wts': best_decoder_v_wts,\n",
    "                    }, PATH_v)        \n",
    "\n",
    "print()\n",
    "print('Epoch {}/{}, Learning rate {}'\\\n",
    "      .format(epoch, num_epochs, optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "print('-' * 10)\n",
    "print('train MSELoss: {}'.format(loss_hist['train'][-1]))\n",
    "print('test MSELoss: {}'.format(loss_hist['test'][-1]))\n",
    "\n",
    "time_elapsed = time.time() - since\n",
    "\n",
    "# load best model weights\n",
    "encoder_v.load_state_dict(best_encoder_v_wts)\n",
    "decoder_v.load_state_dict(best_decoder_v_wts)\n",
    "\n",
    "# compute best train MSELoss\n",
    "encoder_v.to('cpu').eval()\n",
    "decoder_v.to('cpu').eval()\n",
    "\n",
    "with torch.set_grad_enabled(False):\n",
    "    train_inputs = torch.tensor(data_v[train_ind])\n",
    "    train_targets = torch.tensor(data_v[train_ind])\n",
    "    train_outputs = decoder_v(encoder_v(train_inputs))\n",
    "    train_loss = loss_func(train_outputs,train_targets).item()\n",
    "\n",
    "# print out training time and best results\n",
    "print()\n",
    "if epoch < num_epochs:\n",
    "    print('Early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "else:\n",
    "    print('No early stopping: {}th training complete in {:.0f}h {:.0f}m {:.0f}s'\\\n",
    "          .format(epoch-last_epoch, time_elapsed // 3600, (time_elapsed % 3600) // 60, (time_elapsed % 3600) % 60))\n",
    "print('-' * 10)\n",
    "print('Best train MSELoss: {}'.format(train_loss))\n",
    "print('Best test MSELoss: {}'.format(best_loss))\n",
    "\n",
    "# # save models\n",
    "# print()\n",
    "# print(\"Saving after {}th training to\".format(epoch),file_name_AE_v)\n",
    "# torch.save((encoder_v,decoder_v),file_name_AE_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "checkpoint removed\n"
     ]
    }
   ],
   "source": [
    "# delete checkpoint\n",
    "try:\n",
    "    os.remove(PATH_v)\n",
    "    print()\n",
    "    print(\"checkpoint removed\")\n",
    "except:\n",
    "    print(\"no checkpoint exists\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot train and test loss\n",
    "plt.figure()\n",
    "plt.semilogy(loss_hist['train'])\n",
    "plt.semilogy(loss_hist['test'])\n",
    "plt.legend(['train','test'])\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load models\n",
    "# try:\n",
    "#     encoder_u,decoder_u = torch.load(file_name_AE_u,map_location='cpu')\n",
    "#     encoder_v,decoder_v = torch.load(file_name_AE_v,map_location='cpu')\n",
    "#     print(\"\\n--------model restored--------\\n\")\n",
    "# except:\n",
    "#     print(\"\\n--------model not restored--------\\n\")\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights and bias\n",
    "en_wu1_s=encoder_u.full[0].weight.detach().numpy().astype('float32')\n",
    "en_bu1=encoder_u.full[0].bias.detach().numpy().astype('float32')\n",
    "en_wu2=encoder_u.full[2].weight.detach().numpy().astype('float32')\n",
    "\n",
    "en_wv1_s=encoder_v.full[0].weight.detach().numpy().astype('float32')\n",
    "en_bv1=encoder_v.full[0].bias.detach().numpy().astype('float32')\n",
    "en_wv2=encoder_v.full[2].weight.detach().numpy().astype('float32')\n",
    "\n",
    "de_wu1=decoder_u.full[0].weight.detach().numpy().astype('float32')\n",
    "de_bu1=decoder_u.full[0].bias.detach().numpy().astype('float32')\n",
    "de_wu2_s=decoder_u.full[2].weight.detach().numpy().astype('float32')\n",
    "\n",
    "de_wv1=decoder_v.full[0].weight.detach().numpy().astype('float32')\n",
    "de_bv1=decoder_v.full[0].bias.detach().numpy().astype('float32')\n",
    "de_wv2_s=decoder_v.full[2].weight.detach().numpy().astype('float32')\n",
    "\n",
    "de_wu2_s_sp=sp.csr_matrix(de_wu2_s,dtype='float32')\n",
    "de_wv2_s_sp=sp.csr_matrix(de_wv2_s,dtype='float32')\n",
    "\n",
    "# rescale weights\n",
    "en_wu1=en_wu1_s*u_scale_reciprocal\n",
    "en_wv1=en_wv1_s*v_scale_reciprocal\n",
    "\n",
    "de_wu1T=de_wu1.T\n",
    "de_wv1T=de_wv1.T\n",
    "\n",
    "de_wu2T=u_scale*de_wu2_s.T\n",
    "de_wv2T=v_scale*de_wv2_s.T\n",
    "\n",
    "de_wu2=de_wu2T.T\n",
    "de_wv2=de_wv2T.T\n",
    "\n",
    "de_wu2_sp=sp.csr_matrix(de_wu2,dtype='float32')\n",
    "de_wv2_sp=sp.csr_matrix(de_wv2,dtype='float32')\n",
    "\n",
    "de_wu2T_sp=de_wu2_sp.T\n",
    "de_wv2T_sp=de_wv2_sp.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy version of AE\n",
    "def sigmoid_np(input):\n",
    "    return (1.0/(1.0+np.exp(-input))).astype('float32')\n",
    "\n",
    "def encoder_u_np_forward(x):\n",
    "    z1 = en_wu1.dot(x) + en_bu1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = en_wu2.dot(a1)   \n",
    "    return y\n",
    "\n",
    "def decoder_u_np_forward(x):\n",
    "    z1 = de_wu1.dot(x) + de_bu1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = de_wu2.dot(a1)  \n",
    "    return y\n",
    "\n",
    "def decoder_u_sp_forward(x):\n",
    "    z1 = de_wu1.dot(x) + de_bu1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = sp.csr_matrix.dot(de_wu2_sp,a1)\n",
    "    return y\n",
    "\n",
    "def encoder_v_np_forward(x):\n",
    "    z1 = en_wv1.dot(x) + en_bv1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = en_wv2.dot(a1)   \n",
    "    return y\n",
    "\n",
    "def decoder_v_np_forward(x):\n",
    "    z1 = de_wv1.dot(x) + de_bv1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = de_wv2.dot(a1)   \n",
    "    return y\n",
    "\n",
    "def decoder_v_sp_forward(x):\n",
    "    z1 = de_wv1.dot(x) + de_bv1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = sp.csr_matrix.dot(de_wv2_sp,a1)\n",
    "    return y\n",
    "\n",
    "def decoder_u_np_forward_backwardT(x):\n",
    "    z1 = de_wu1.dot(x) + de_bu1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = de_wu2.dot(a1)\n",
    "\n",
    "    dout = de_wu1T\n",
    "    dout = (a1*(1-a1))*dout\n",
    "    dydxT = dout.dot(de_wu2T)   \n",
    "    return y,dydxT\n",
    "\n",
    "def decoder_u_sp_forward_backwardT(x):\n",
    "    z1 = de_wu1.dot(x) + de_bu1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = sparse.csr_matrix.dot(de_wu2_sp,a1)\n",
    "\n",
    "    dout = de_wu1T\n",
    "    dout = (a1*(1-a1))*dout\n",
    "    dydxT = sp.csr_matrix.dot(dout,de_wu2T_sp)\n",
    "    return y,dydxT\n",
    "\n",
    "def decoder_v_np_forward_backwardT(x):\n",
    "    z1 = de_wv1.dot(x) + de_bv1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = de_wv2.dot(a1)\n",
    "\n",
    "    dout = de_wv1T\n",
    "    dout = (a1*(1-a1))*dout\n",
    "    dydxT = dout.dot(de_wv2T)   \n",
    "    return y,dydxT\n",
    "\n",
    "def decoder_v_sp_forward_backwardT(x):\n",
    "    z1 = de_wv1.dot(x) + de_bv1\n",
    "    a1 = sigmoid_np(z1)\n",
    "    y = sp.csr_matrix.dot(de_wv2_sp,a1)\n",
    "\n",
    "    dout = de_wv1T\n",
    "    dout = (a1*(1-a1))*dout\n",
    "    dydxT = sp.csr_matrix.dot(dout,de_wv2T_sp)\n",
    "    return y,dydxT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE u: 2.05885567e-08\n",
      "MSELoss of AE v: 1.79361990e-08\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss\n",
    "comp_orig_data_u=np.zeros((ndata,f))\n",
    "comp_orig_data_v=np.zeros((ndata,f))\n",
    "\n",
    "rest_orig_data_u=np.zeros(orig_data_u.shape)\n",
    "rest_orig_data_v=np.zeros(orig_data_u.shape)\n",
    "\n",
    "for k in range(ndata):\n",
    "    comp_orig_data_u[k]=encoder_u_np_forward(orig_data_u[k]-u_ref)\n",
    "    comp_orig_data_v[k]=encoder_v_np_forward(orig_data_v[k]-v_ref)\n",
    "    \n",
    "    rest_orig_data_u[k]=decoder_u_sp_forward(comp_orig_data_u[k]) + u_ref\n",
    "    rest_orig_data_v[k]=decoder_v_sp_forward(comp_orig_data_v[k]) + v_ref\n",
    "    \n",
    "print(\"MSELoss of AE u: {:.8e}\".format(np.linalg.norm(orig_data_u-rest_orig_data_u)**2/np.prod(orig_data_u.shape)))\n",
    "print(\"MSELoss of AE v: {:.8e}\".format(np.linalg.norm(orig_data_v-rest_orig_data_v)**2/np.prod(orig_data_v.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale AE\n",
    "en_weight_u_s=encoder_u.full[0].weight.data\n",
    "en_weight_u=en_weight_u_s*torch.tensor(u_scale_reciprocal)\n",
    "encoder_u.full[0].weight=nn.Parameter(en_weight_u)\n",
    "\n",
    "de_weight_u_s=decoder_u.full[2].weight.data\n",
    "de_weight_u=(torch.tensor(u_scale)*de_weight_u_s.T).T\n",
    "de_weight_u_mask=decoder_u.full[2].weight_mask.data\n",
    "prune.remove(decoder_u.full[2],'weight');\n",
    "decoder_u.full[2].weight=nn.Parameter(de_weight_u)\n",
    "prune.custom_from_mask(decoder_u.full[2], name='weight', mask=de_weight_u_mask);\n",
    "\n",
    "en_weight_v_s=encoder_v.full[0].weight.data\n",
    "en_weight_v=en_weight_v_s*torch.tensor(v_scale_reciprocal)\n",
    "encoder_v.full[0].weight=nn.Parameter(en_weight_v)\n",
    "\n",
    "de_weight_v_s=decoder_v.full[2].weight.data\n",
    "de_weight_v=(torch.tensor(v_scale)*de_weight_v_s.T).T\n",
    "de_weight_v_mask=decoder_v.full[2].weight_mask.data\n",
    "prune.remove(decoder_v.full[2],'weight');\n",
    "decoder_v.full[2].weight=nn.Parameter(de_weight_v)\n",
    "prune.custom_from_mask(decoder_v.full[2], name='weight', mask=de_weight_v_mask);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE u: 2.05879296e-08\n",
      "MSELoss of AE v: 1.79357773e-08\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss\n",
    "input_u=torch.tensor(orig_data_u-u_ref)\n",
    "target_u=decoder_u(encoder_u(input_u))\n",
    "\n",
    "input_v=torch.tensor(orig_data_v-v_ref)\n",
    "target_v=decoder_v(encoder_v(input_v))\n",
    "\n",
    "print(\"MSELoss of AE u: {:.8e}\".format(torch.nn.functional.mse_loss(input_u,target_u).detach().item()))\n",
    "print(\"MSELoss of AE v: {:.8e}\".format(torch.nn.functional.mse_loss(input_v,target_v).detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSELoss of AE u (predictive case): 3.66026889e-08\n",
      "MSELoss of AE v (predictive case): 3.12098543e-08\n"
     ]
    }
   ],
   "source": [
    "# compute MSELoss (predictive case)\n",
    "if Re==10000:\n",
    "    FOM_solution=pickle.load(open('./data/FOM_high_Re.p','rb'))\n",
    "elif Re==100:\n",
    "    FOM_solution=pickle.load(open('./data/FOM_loq_Re.p','rb'))\n",
    "else:\n",
    "    raise NameError('{} is given for Re, but it must be either 100 or 10000'.format(Re))\n",
    "    \n",
    "u_full=FOM_solution['u'].astype('float32')\n",
    "v_full=FOM_solution['v'].astype('float32')\n",
    "\n",
    "orig_data_u_FOM = u_full[:,free_raveled_indicies]\n",
    "orig_data_v_FOM = v_full[:,free_raveled_indicies]\n",
    "\n",
    "input_u_FOM=torch.tensor(orig_data_u_FOM-u_ref)\n",
    "target_u_FOM=decoder_u(encoder_u(input_u_FOM))\n",
    "\n",
    "input_v_FOM=torch.tensor(orig_data_v_FOM-v_ref)\n",
    "target_v_FOM=decoder_v(encoder_v(input_v_FOM))\n",
    "\n",
    "print(\"MSELoss of AE u (predictive case): {:.8e}\"\\\n",
    "      .format(torch.nn.functional.mse_loss(input_u_FOM,target_u_FOM).detach().item()))\n",
    "print(\"MSELoss of AE v (predictive case): {:.8e}\"\\\n",
    "      .format(torch.nn.functional.mse_loss(input_v_FOM,target_v_FOM).detach().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # generate mesh grid\n",
    "# [xv,yv]=np.meshgrid(np.linspace(0,1,nx),np.linspace(0,1,ny),indexing='xy')\n",
    "# x=xv.flatten()\n",
    "# y=yv.flatten()\n",
    "\n",
    "# x_free=x[free_raveled_indicies]\n",
    "# y_free=y[free_raveled_indicies]\n",
    "\n",
    "# k=-1\n",
    "\n",
    "# # plot origianl data\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_u[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_u[k].reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Original $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_v[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), orig_data_v[k].reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Original $v$')\n",
    "# plt.show()\n",
    "\n",
    "# # plot compressed data\n",
    "# plt.figure()\n",
    "# plt.plot(comp_orig_data_u[k])\n",
    "# plt.title('Compressed $u$')\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(comp_orig_data_v[k])\n",
    "# plt.title('Compressed $v$')\n",
    "# plt.show()\n",
    "\n",
    "# # plot restored data\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_orig_data_u[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_orig_data_u[k].reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Restored $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_orig_data_v[k].reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), rest_orig_data_v[k].reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Restored $v$')\n",
    "# plt.show()\n",
    "\n",
    "# # plot relative error\n",
    "# fig_u = plt.figure()\n",
    "# ax_u = Axes3D(fig_u)\n",
    "# ax_u.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), (orig_data_u[k]-rest_orig_data_u[k]).reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_u.view_init(elev=30,azim=30)\n",
    "# # ax_u = fig_u.gca()\n",
    "# # p_u=ax_u.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), (orig_data_u[k]-rest_orig_data_u[k]).reshape(ny-2,nx-2))\n",
    "# # cb_u=fig_u.colorbar(p_u,ax=ax_u)\n",
    "# ax_u.set_xlabel('$x_{free}$')\n",
    "# ax_u.set_ylabel('$y_{free}$')\n",
    "# plt.title('Difference $u$')\n",
    "# plt.show()\n",
    "\n",
    "# fig_v = plt.figure()\n",
    "# ax_v = Axes3D(fig_v)\n",
    "# ax_v.plot_surface(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), (orig_data_v[k]-rest_orig_data_v[k]).reshape(ny-2,nx-2),cmap=cm.viridis, rstride=1, cstride=1)\n",
    "# ax_v.view_init(elev=30,azim=60)\n",
    "# # ax_v = fig_v.gca()\n",
    "# # p_v=ax_v.pcolor(x_free.reshape(ny-2,nx-2), y_free.reshape(ny-2,nx-2), (orig_data_v[k]-rest_orig_data_v[k]).reshape(ny-2,nx-2))\n",
    "# # cb_v=fig_v.colorbar(p_v,ax=ax_v)\n",
    "# ax_v.set_xlabel('$x_{free}$')\n",
    "# ax_v.set_ylabel('$y_{free}$')\n",
    "# plt.title('Difference $v$')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save weights and references   \n",
    "AE={'en_wu1':en_wu1,'en_bu1':en_bu1,'en_wu2':en_wu2,\n",
    "    'de_wu1':de_wu1,'de_bu1':de_bu1,'de_wu2':de_wu2,\n",
    "    'de_wu1T':de_wu1T,'de_wu2T':de_wu2T,'de_wu2_sp':de_wu2_sp,'de_wu2T_sp':de_wu2T_sp,'u_ref':u_ref,\n",
    "    'en_wv1':en_wv1,'en_bv1':en_bv1,'en_wv2':en_wv2,\n",
    "    'de_wv1':de_wv1,'de_bv1':de_bv1,'de_wv2':de_wv2,\n",
    "    'de_wv1T':de_wv1T,'de_wv2T':de_wv2T,'de_wv2_sp':de_wv2_sp,'de_wv2T_sp':de_wv2T_sp,'v_ref':v_ref}\n",
    "\n",
    "pickle.dump(AE,open(file_name_AE,'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
